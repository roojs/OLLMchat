[
  {
    "name": "7shi/borea-phi-3.5-coding",
    "slug": "7shi/borea-phi-3.5-coding",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "3.8b-mini-instruct-q6_K",
        "size": "3.1GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 60
  },
  {
    "name": "7shi/borea-phi-3.5-common",
    "slug": "7shi/borea-phi-3.5-common",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "3.8b-mini-instruct-q6_K",
        "size": "3.1GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 23
  },
  {
    "name": "7shi/borea-phi-3.5-jp",
    "slug": "7shi/borea-phi-3.5-jp",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "3.8b-mini-instruct-q6_K",
        "size": "3.1GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 247
  },
  {
    "name": "clore/gpt-oss-20b-Q8_0",
    "slug": "clore/gpt-oss-20b-Q8_0",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 285
  },
  {
    "name": "cua/gpt-oss-edit",
    "slug": "cua/gpt-oss-edit",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "danielsheep/gpt-oss-20b-Unsloth",
    "slug": "danielsheep/gpt-oss-20b-Unsloth",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "UD-Q4_K_XL",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "UD-Q6_K_XL",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 1287
  },
  {
    "name": "deepseek-ocr",
    "slug": "deepseek-ocr",
    "description": "DeepSeek-OCR is a vision-language model that can perform token-efficient OCR.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.7GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "3b",
        "size": "6.7GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "3b-bf16",
        "size": "6.7GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": 81100
  },
  {
    "name": "deepseek-v3.1",
    "slug": "deepseek-v3.1",
    "description": "DeepSeek-V3.1-Terminus is a hybrid model that supports both thinking mode and non-thinking mode.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-cloud",
        "size": "-",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-terminus-q4_K_M",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-terminus-q8_0",
        "size": "713GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-terminus-fp16",
        "size": "1.3TB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-q8_0",
        "size": "713GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-fp16",
        "size": "1.3TB",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": 231100
  },
  {
    "name": "deepseek-v3.2",
    "slug": "deepseek-v3.2",
    "description": "DeepSeek-V3.2, a model that harmonizes high computational efficiency with superior reasoning and agent performance.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": 8591
  },
  {
    "name": "devstral-2",
    "slug": "devstral-2",
    "description": "123B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2512-q4_K_M",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2512-q8_0",
        "size": "133GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2512-fp16",
        "size": "250GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 25300
  },
  {
    "name": "devstral-small-2",
    "slug": "devstral-small-2",
    "description": "24B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "15GB",
        "context": "384K",
        "input": "Text, Image"
      },
      {
        "name": "24b",
        "size": "15GB",
        "context": "384K",
        "input": "Text, Image"
      },
      {
        "name": "24b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2512-q4_K_M",
        "size": "15GB",
        "context": "384K",
        "input": "Text, Image"
      },
      {
        "name": "24b-instruct-2512-q8_0",
        "size": "26GB",
        "context": "384K",
        "input": "Text, Image"
      },
      {
        "name": "24b-instruct-2512-fp16",
        "size": "48GB",
        "context": "384K",
        "input": "Text, Image"
      }
    ],
    "downloads": 61600
  },
  {
    "name": "embeddinggemma",
    "slug": "embeddinggemma",
    "description": "EmbeddingGemma is a 300M parameter embedding model from Google.",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "300m",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "300m-qat-q4_0",
        "size": "239MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "300m-qat-q8_0",
        "size": "338MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "300m-bf16",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 348100
  },
  {
    "name": "frob/minimax-m2.1",
    "slug": "frob/minimax-m2.1",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "138GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "230b-a10b-q4_K_M",
        "size": "138GB",
        "context": "192K",
        "input": "Text"
      }
    ],
    "downloads": 11
  },
  {
    "name": "functiongemma",
    "slug": "functiongemma",
    "description": "FunctionGemma is a specialized version of Google's Gemma 3 270M model fine-tuned explicitly for function calling.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "301MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "270m",
        "size": "301MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "270m-it-q8_0",
        "size": "301MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "270m-it-fp16",
        "size": "552MB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 16200
  },
  {
    "name": "gabegoodhart/minimax-m2",
    "slug": "gabegoodhart/minimax-m2",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "56GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "230b",
        "size": "56GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "230b-UD-TQ1_0",
        "size": "56GB",
        "context": "192K",
        "input": "Text"
      }
    ],
    "downloads": 136
  },
  {
    "name": "gabegoodhart/minimax-m2.1",
    "slug": "gabegoodhart/minimax-m2.1",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "68GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "229b-UD-TQ1_0",
        "size": "56GB",
        "context": "192K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "gemini-3-flash-preview",
    "slug": "gemini-3-flash-preview",
    "description": "Gemini 3 Flash offers frontier intelligence built for speed at a fraction of the cost.",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "-",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "cloud",
        "size": "-",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": 17300
  },
  {
    "name": "gemini-3-pro-preview",
    "slug": "gemini-3-pro-preview",
    "description": "Google's most intelligent model with SOTA reasoning and multimodal understanding, and powerful agentic and vibe coding capabilities.",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "-",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": 56700
  },
  {
    "name": "glm-4.7",
    "slug": "glm-4.7",
    "description": "Advancing the Coding Capability",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": 5667
  },
  {
    "name": "glm-4.7-flash",
    "slug": "glm-4.7-flash",
    "description": "As the strongest model in the 30B class, GLM-4.7-Flash offers a new option for lightweight deployment that balances performance and efficiency.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "q4_K_M",
        "size": "19GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "32GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "bf16",
        "size": "60GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "gpt-oss",
    "slug": "gpt-oss",
    "description": "OpenAIâ€™s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b",
        "size": "65GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-cloud",
        "size": "-",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b-cloud",
        "size": "-",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 5600000
  },
  {
    "name": "gpt-oss-safeguard",
    "slug": "gpt-oss-safeguard",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b",
        "size": "65GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 38800
  },
  {
    "name": "granite4",
    "slug": "granite4",
    "description": "Granite 4 features improved instruction following (IF) and tool-calling capabilities, making them more effective in enterprise applications.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "micro",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "350m",
        "size": "708MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "350m-h",
        "size": "366MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "350m-h-q8_0",
        "size": "366MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "350m-bf16",
        "size": "708MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-h",
        "size": "1.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "1b-h-q8_0",
        "size": "1.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "1b-bf16",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-h",
        "size": "1.9GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "7b-a1b-h",
        "size": "4.2GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "32b-a9b-h",
        "size": "19GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "micro-h",
        "size": "1.9GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "small-h",
        "size": "19GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-h",
        "size": "4.2GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": 382900
  },
  {
    "name": "gurubot/gpt-oss-derestricted",
    "slug": "gurubot/gpt-oss-derestricted",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "20b",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 1047
  },
  {
    "name": "haybu/gpt-oss-120b",
    "slug": "haybu/gpt-oss-120b",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "65GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 220
  },
  {
    "name": "huihui_ai/gpt-oss-abliterated",
    "slug": "huihui_ai/gpt-oss-abliterated",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b",
        "size": "88GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-mxfp4",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-v2-q3_K_M",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-v2-q4_K_M",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-v2-q8_0",
        "size": "22GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-v2-fp16",
        "size": "42GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-q3_K_M",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-q4_K_M",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-q8_0",
        "size": "22GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-fp16",
        "size": "42GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b-q3_K_M",
        "size": "71GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b-q4_K_M",
        "size": "88GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b-q8_0",
        "size": "124GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b-fp16",
        "size": "234GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 20800
  },
  {
    "name": "jan-fischer-haw/jinx-gpt-oss-20b",
    "slug": "jan-fischer-haw/jinx-gpt-oss-20b",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 228
  },
  {
    "name": "kimi-k2.5",
    "slug": "kimi-k2.5",
    "description": "Kimi K2.5 is an open-source, native multimodal agentic model that seamlessly integrates vision and language understanding with advanced agentic capabilities, instant and thinking modes, as well as conversational and agentic paradigms.",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "lfm2.5-thinking",
    "slug": "lfm2.5-thinking",
    "description": "LFM2.5 is a new family of hybrid models designed for on-device deployment.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "731MB",
        "context": "125K",
        "input": "Text"
      },
      {
        "name": "1.2b",
        "size": "731MB",
        "context": "125K",
        "input": "Text"
      },
      {
        "name": "1.2b-q4_K_M",
        "size": "731MB",
        "context": "125K",
        "input": "Text"
      },
      {
        "name": "1.2b-q8_0",
        "size": "1.2GB",
        "context": "125K",
        "input": "Text"
      },
      {
        "name": "1.2b-bf16",
        "size": "2.3GB",
        "context": "125K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "llamallamaduck/mtg-card-converter-14b-instruct-iMat_1",
    "slug": "llamallamaduck/mtg-card-converter-14b-instruct-iMat_1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q8_0",
        "size": "17GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "marlonbarriossolano/sati-ai-gpt-oss",
    "slug": "marlonbarriossolano/sati-ai-gpt-oss",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mashriram/gpt-oss-Regular",
    "slug": "mashriram/gpt-oss-Regular",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 714
  },
  {
    "name": "Maternion/LightOnOCR-2",
    "slug": "Maternion/LightOnOCR-2",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.5GB",
        "context": "16K",
        "input": "Text, Image"
      },
      {
        "name": "1b",
        "size": "1.5GB",
        "context": "16K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "mcgdj/gpt-oss-6.0b",
    "slug": "mcgdj/gpt-oss-6.0b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.6GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 538
  },
  {
    "name": "MichelRosselli/minimax-m2",
    "slug": "MichelRosselli/minimax-m2",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "138GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "q2_k",
        "size": "83GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "109GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "138GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "162GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "188GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "243GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "iq1_m",
        "size": "69GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "tq1_0",
        "size": "56GB",
        "context": "192K",
        "input": "Text"
      }
    ],
    "downloads": 299
  },
  {
    "name": "minimax-m2",
    "slug": "minimax-m2",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "200K",
        "input": "Text"
      }
    ],
    "downloads": 32800
  },
  {
    "name": "minimax-m2.1",
    "slug": "minimax-m2.1",
    "description": "Exceptional multilingual capabilities to elevate code engineering",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "200K",
        "input": "Text"
      }
    ],
    "downloads": 3626
  },
  {
    "name": "ministral-3",
    "slug": "ministral-3",
    "description": "The Ministral 3 family is designed for edge deployment, capable of running on a wide range of hardware.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "3b",
        "size": "3.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "6.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b",
        "size": "9.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "3b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-2512-q4_K_M",
        "size": "3.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "3b-instruct-2512-q8_0",
        "size": "4.5GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "3b-instruct-2512-fp16",
        "size": "7.7GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-2512-q4_K_M",
        "size": "6.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-2512-q8_0",
        "size": "9.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-2512-fp16",
        "size": "18GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "14b-instruct-2512-q4_K_M",
        "size": "9.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b-instruct-2512-q8_0",
        "size": "15GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b-instruct-2512-fp16",
        "size": "28GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": 167000
  },
  {
    "name": "mistral-large-3",
    "slug": "mistral-large-3",
    "description": "A general-purpose multimodal mixture-of-experts model for production-grade tasks and enterprise workloads.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "675b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 7083
  },
  {
    "name": "nemotron-3-nano",
    "slug": "nemotron-3-nano",
    "description": "Nemotron 3 Nano - A new Standard for Efficient, Open, and Intelligent Agentic Models",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "24GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "30b",
        "size": "24GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "30b-a3b-q4_K_M",
        "size": "24GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "30b-a3b-q8_0",
        "size": "34GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "30b-a3b-fp16",
        "size": "63GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "30b-cloud",
        "size": "-",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": 62600
  },
  {
    "name": "nomic-embed-text-v2-moe",
    "slug": "nomic-embed-text-v2-moe",
    "description": "nomic-embed-text-v2-moe is a multilingual MoE text embedding model that excels at multilingual retrieval.",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "958MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": 14300
  },
  {
    "name": "okamototk/gpt-oss-reasoning-high",
    "slug": "okamototk/gpt-oss-reasoning-high",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 122
  },
  {
    "name": "olmo-3",
    "slug": "olmo-3",
    "description": "Olmo is a series of Open language models designed to enable the science of language models. These models are pre-trained on the Dolma 3 dataset and post-trained on the Dolci datasets.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-instruct",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q4_K_M",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q8_0",
        "size": "7.8GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-fp16",
        "size": "15GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-think",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-think-q4_K_M",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-think-q8_0",
        "size": "7.8GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-think-fp16",
        "size": "15GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-q4_K_M",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-q8_0",
        "size": "34GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-fp16",
        "size": "64GB",
        "context": "64K",
        "input": "Text"
      }
    ],
    "downloads": 30800
  },
  {
    "name": "olmo-3.1",
    "slug": "olmo-3.1",
    "description": "Olmo is a series of Open language models designed to enable the science of language models. These models are pre-trained on the Dolma 3 dataset and post-trained on the Dolci datasets.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-instruct",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-instruct-q4_K_M",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-instruct-q8_0",
        "size": "34GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-instruct-fp16",
        "size": "64GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-q4_K_M",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-q8_0",
        "size": "34GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-fp16",
        "size": "64GB",
        "context": "64K",
        "input": "Text"
      }
    ],
    "downloads": 19200
  },
  {
    "name": "omkarjava0103/gpt-oss-mini",
    "slug": "omkarjava0103/gpt-oss-mini",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "omkar",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 257
  },
  {
    "name": "Omoeba/gpt-oss-coder",
    "slug": "Omoeba/gpt-oss-coder",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 971
  },
  {
    "name": "qwen3-embedding",
    "slug": "qwen3-embedding",
    "description": "Building upon the foundational models of the Qwen3 series, Qwen3 Embedding provides a comprehensive range of text embeddings models in various sizes",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "0.6b",
        "size": "639MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "4b",
        "size": "2.5GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.7GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "0.6b-q8_0",
        "size": "639MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "0.6b-fp16",
        "size": "1.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "4b-q4_K_M",
        "size": "2.5GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "4b-q8_0",
        "size": "4.3GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "4b-fp16",
        "size": "8.0GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M",
        "size": "4.7GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0",
        "size": "8.0GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-fp16",
        "size": "15GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": 226800
  },
  {
    "name": "qwen3-next",
    "slug": "qwen3-next",
    "description": "The first installment in the Qwen3-Next series with strong performance in terms of both parameter efficiency and inference speed.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-instruct-q4_K_M",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-instruct-q8_0",
        "size": "85GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-instruct-fp16",
        "size": "159GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking-q4_K_M",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking-q8_0",
        "size": "85GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking-fp16",
        "size": "159GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 225300
  },
  {
    "name": "qwen3-vl",
    "slug": "qwen3-vl",
    "description": "The most powerful vision-language model in the Qwen model family to date.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct-q4_K_M",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct-q8_0",
        "size": "2.6GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct-bf16",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking-q4_K_M",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking-q8_0",
        "size": "2.6GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking-bf16",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct-q4_K_M",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct-q8_0",
        "size": "5.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct-bf16",
        "size": "8.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking-q4_K_M",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking-q8_0",
        "size": "5.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking-bf16",
        "size": "8.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-q4_K_M",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-q8_0",
        "size": "9.8GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-bf16",
        "size": "18GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking-q4_K_M",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking-q8_0",
        "size": "9.8GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking-bf16",
        "size": "18GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct-q4_K_M",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct-q8_0",
        "size": "34GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct-bf16",
        "size": "62GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-thinking",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-thinking-q4_K_M",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-thinking-q8_0",
        "size": "34GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-thinking-bf16",
        "size": "62GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-q4_K_M",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-q8_0",
        "size": "36GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-bf16",
        "size": "67GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking-q4_K_M",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking-q8_0",
        "size": "36GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking-bf16",
        "size": "67GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-instruct",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-instruct-q4_K_M",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-instruct-q8_0",
        "size": "251GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-instruct-bf16",
        "size": "471GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-thinking",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-thinking-q4_K_M",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-thinking-q8_0",
        "size": "251GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-thinking-bf16",
        "size": "471GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "235b-instruct-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 907300
  },
  {
    "name": "Rishabhpb26/ChatPro-2-mini",
    "slug": "Rishabhpb26/ChatPro-2-mini",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "813MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 25
  },
  {
    "name": "rnj-1",
    "slug": "rnj-1",
    "description": "Rnj-1 is a family of 8B parameter open-weight, dense models trained from scratch by Essential AI, optimized for code and STEM with capabilities on par with SOTA open-weight models.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-cloud",
        "size": "-",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_K_M",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q8_0",
        "size": "8.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-fp16",
        "size": "17GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 20500
  },
  {
    "name": "second_constantine/gpt-oss-u",
    "slug": "second_constantine/gpt-oss-u",
    "description": "",
    "features": [
      "thinking"
    ],
    "tags": [
      {
        "name": "20b",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 26300
  },
  {
    "name": "slekrem/gpt-oss-claude-code-32k",
    "slug": "slekrem/gpt-oss-claude-code-32k",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "svjack/gpt-oss-20b-heretic",
    "slug": "svjack/gpt-oss-20b-heretic",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 340
  },
  {
    "name": "translategemma",
    "slug": "translategemma",
    "description": "A new collection of open translation models built on Gemma 3, helping people communicate across 55 languages.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b",
        "size": "17GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-it-q4_K_M",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-it-q8_0",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-it-bf16",
        "size": "8.6GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b-it-q4_K_M",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b-it-q8_0",
        "size": "13GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b-it-bf16",
        "size": "24GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-it-q4_K_M",
        "size": "17GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-it-q8_0",
        "size": "30GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-it-bf16",
        "size": "55GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  }
]