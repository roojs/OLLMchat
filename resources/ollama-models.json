[
  {
    "name": "0ssamaak0/xtuner-llava",
    "slug": "0ssamaak0/xtuner-llava",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "llama3-8b-v1.1-int4",
        "size": "5.5GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "llama3-8b-v1.1-f16",
        "size": "17GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "phi3-mini-int4",
        "size": "2.9GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "phi3-mini-f16",
        "size": "8.3GB",
        "context": "4K",
        "input": "Text, Image"
      }
    ],
    "downloads": 3279
  },
  {
    "name": "2002bona/bge-m3-korean",
    "slug": "2002bona/bge-m3-korean",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 52
  },
  {
    "name": "243260238/deepseek-r1-medical-demo",
    "slug": "243260238/deepseek-r1-medical-demo",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "1.5b",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "243260238/tangyanghong243260238-deepseek-r1",
    "slug": "243260238/tangyanghong243260238-deepseek-r1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "1.5b",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "7shi/borea-phi-3.5-coding",
    "slug": "7shi/borea-phi-3.5-coding",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "3.8b-mini-instruct-q6_K",
        "size": "3.1GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 60
  },
  {
    "name": "7shi/borea-phi-3.5-common",
    "slug": "7shi/borea-phi-3.5-common",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "3.8b-mini-instruct-q6_K",
        "size": "3.1GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 23
  },
  {
    "name": "7shi/borea-phi-3.5-jp",
    "slug": "7shi/borea-phi-3.5-jp",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "3.8b-mini-instruct-q6_K",
        "size": "3.1GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 247
  },
  {
    "name": "8b-wraith/deepseek-v3-0324",
    "slug": "8b-wraith/deepseek-v3-0324",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "289GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 1044
  },
  {
    "name": "a123/tiny-gpt",
    "slug": "a123/tiny-gpt",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.2GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 772
  },
  {
    "name": "aadi19/olympus-coder",
    "slug": "aadi19/olympus-coder",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.4GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": 104
  },
  {
    "name": "abhaymin/llava-llama3-int4_31",
    "slug": "abhaymin/llava-llama3-int4_31",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.5GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "abhaymin/llava-llama3-int5",
    "slug": "abhaymin/llava-llama3-int5",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.2GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "abhishek_sa_mm/mm-minicpm-v2",
    "slug": "abhishek_sa_mm/mm-minicpm-v2",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 19
  },
  {
    "name": "abmateen/glm-4.7cloud",
    "slug": "abmateen/glm-4.7cloud",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "270B",
        "context": "-",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "acidic/Qwen3-Coder-IQ2_XXS",
    "slug": "acidic/Qwen3-Coder-IQ2_XXS",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "10GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "adelnazmy2002/Qwen3-VL-8B-Instruct",
    "slug": "adelnazmy2002/Qwen3-VL-8B-Instruct",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "adijayainc/bhsa-dolphin-llama3",
    "slug": "adijayainc/bhsa-dolphin-llama3",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ahmadwaqar/mai-ui",
    "slug": "ahmadwaqar/mai-ui",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "18GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "ahmadwaqar/smolvlm2-2.2b-instruct",
    "slug": "ahmadwaqar/smolvlm2-2.2b-instruct",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.5GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "fp16",
        "size": "4.5GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "ahmadwaqar/smolvlm2-256m-video",
    "slug": "ahmadwaqar/smolvlm2-256m-video",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "q8_0",
        "size": "279MB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "fp16",
        "size": "518MB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "ahmadwaqar/smolvlm2-500m-video",
    "slug": "ahmadwaqar/smolvlm2-500m-video",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "546MB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q8",
        "size": "546MB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "fp16",
        "size": "1.0GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "ahmadwaqar/smolvlm2-agentic-gui",
    "slug": "ahmadwaqar/smolvlm2-agentic-gui",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.5GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q8_0",
        "size": "2.5GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "fp16",
        "size": "4.2GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "aia/dolphin-llama3.1",
    "slug": "aia/dolphin-llama3.1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "aia/Dolphin3.0-Mistral-24B",
    "slug": "aia/Dolphin3.0-Mistral-24B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q4_K_S",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 57
  },
  {
    "name": "aia/Dolphin3.0-R1-Mistral-24B",
    "slug": "aia/Dolphin3.0-R1-Mistral-24B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 612
  },
  {
    "name": "aia/GLM-4.7-Flash-REAP-23B-A3B-GGUF",
    "slug": "aia/GLM-4.7-Flash-REAP-23B-A3B-GGUF",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "14GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "aiasistentworld/Llama-3.1-8B-Instruct-STO-Master",
    "slug": "aiasistentworld/Llama-3.1-8B-Instruct-STO-Master",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "aiden_lu/minicpm-v2.6",
    "slug": "aiden_lu/minicpm-v2.6",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "5.7GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 31900
  },
  {
    "name": "aikid123/Qwen3-coder",
    "slug": "aikid123/Qwen3-coder",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.4GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "0.6b",
        "size": "523MB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "aimagelab/llava-more-8b",
    "slug": "aimagelab/llava-more-8b",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "17GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "akuldatta/mistral-nemo-instruct-12b",
    "slug": "akuldatta/mistral-nemo-instruct-12b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q5km",
        "size": "8.7GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 1701
  },
  {
    "name": "alibayram/gemma3n-tr",
    "slug": "alibayram/gemma3n-tr",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.2GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "alibayram/ministral-3b-instruct",
    "slug": "alibayram/ministral-3b-instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "AliBilge/Huihui-Devstral-Small-2-24B-Instruct-2512-abliterated",
    "slug": "AliBilge/Huihui-Devstral-Small-2-24B-Instruct-2512-abliterated",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "q2_k",
        "size": "8.9GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "q3_k_s",
        "size": "10GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "11GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "q3_k_l",
        "size": "12GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "q4_k_s",
        "size": "14GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "q4_k_m",
        "size": "14GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "q5_k_s",
        "size": "16GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "17GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "19GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "25GB",
        "context": "384K",
        "input": "Text"
      },
      {
        "name": "fp16",
        "size": "47GB",
        "context": "384K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "alibilge/Huihui-GLM-4.6V-Flash-abliterated",
    "slug": "alibilge/Huihui-GLM-4.6V-Flash-abliterated",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q2_k",
        "size": "4.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q3_k_s",
        "size": "4.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "5.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q3_k_l",
        "size": "5.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q4_k_s",
        "size": "5.8GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q4_k_m",
        "size": "6.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q5_k_s",
        "size": "6.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "7.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "8.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "10.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "fp16",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "alishendi/persian-embeddings",
    "slug": "alishendi/persian-embeddings",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.2GB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "alkindivv/Llama-3.2-1B-Indo",
    "slug": "alkindivv/Llama-3.2-1B-Indo",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "808MB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "allisterb/gemma3n_e4b_tools_test",
    "slug": "allisterb/gemma3n_e4b_tools_test",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.3GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "anarko/qwen3-coder-flash",
    "slug": "anarko/qwen3-coder-flash",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "18GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b",
        "size": "18GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "UD-Q4_K_XL",
        "size": "18GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "andersons_code/complete_finetuned_bge-m3",
    "slug": "andersons_code/complete_finetuned_bge-m3",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.3GB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "andrewmccall/gemma3-tools",
    "slug": "andrewmccall/gemma3-tools",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "angel7x/meddolphin",
    "slug": "angel7x/meddolphin",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 34
  },
  {
    "name": "anthony-maio/remnantinstruct-8b",
    "slug": "anthony-maio/remnantinstruct-8b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "5.0GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "apolos/smollm2-malatesta",
    "slug": "apolos/smollm2-malatesta",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "135m",
        "size": "271MB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "Aqirito/TinyLlama-1.1B-Chat-v1.0-KMSB-fine-tuned",
    "slug": "Aqirito/TinyLlama-1.1B-Chat-v1.0-KMSB-fine-tuned",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.2GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 59
  },
  {
    "name": "aratan/deepthought8b",
    "slug": "aratan/deepthought8b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "aratan/vision",
    "slug": "aratan/vision",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.5GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "aravhawk/glm-4.7-flash-q3_K_S",
    "slug": "aravhawk/glm-4.7-flash-q3_K_S",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "13GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "30b",
        "size": "13GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "aravhawk/qwen3-coder-q3_K_S",
    "slug": "aravhawk/qwen3-coder-q3_K_S",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "30b",
        "size": "13GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "artifish/llama3.2-uncensored",
    "slug": "artifish/llama3.2-uncensored",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.2GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 847600
  },
  {
    "name": "ArunKr/smollm2-135m",
    "slug": "ArunKr/smollm2-135m",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "271MB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "aseio8886/aseio-deepcoder1.5b",
    "slug": "aseio8886/aseio-deepcoder1.5b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "aseio8886/aseio-deepseek-coder6.7b",
    "slug": "aseio8886/aseio-deepseek-coder6.7b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.8GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "aseio8886/aseio-deepseek-coder7b",
    "slug": "aseio8886/aseio-deepseek-coder7b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "aseio8886/aseio-nomic-embed-text",
    "slug": "aseio8886/aseio-nomic-embed-text",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "274MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 9
  },
  {
    "name": "asilkan/qwen3-8b-record-matcher",
    "slug": "asilkan/qwen3-8b-record-matcher",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "asilkan/qwen3-record-matcher",
    "slug": "asilkan/qwen3-record-matcher",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.5GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "atlas/intersync-gemma-7b-instruct-function-calling",
    "slug": "atlas/intersync-gemma-7b-instruct-function-calling",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "5.0GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "B-A-M-N/qwen3-next-instruct-q4",
    "slug": "B-A-M-N/qwen3-next-instruct-q4",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "45GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "B-A-M-N/qwen3-next-instruct-q4_k_m",
    "slug": "B-A-M-N/qwen3-next-instruct-q4_k_m",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "48GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "B-A-M-N/qwen3-next-thinking-q4",
    "slug": "B-A-M-N/qwen3-next-thinking-q4",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "45GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "B-A-M-N/qwen3-next-thinking-q4_k_m",
    "slug": "B-A-M-N/qwen3-next-thinking-q4_k_m",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "48GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "bahtiyorovnozim/qwen3-vl-1-4b",
    "slug": "bahtiyorovnozim/qwen3-vl-1-4b",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "bahtiyorovnozim/qwen3-vl-1-8b",
    "slug": "bahtiyorovnozim/qwen3-vl-1-8b",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "bahtiyorovnozim/qwen3-vl-2-4b",
    "slug": "bahtiyorovnozim/qwen3-vl-2-4b",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "bahtiyorovnozim/qwen3-vl-2-8b",
    "slug": "bahtiyorovnozim/qwen3-vl-2-8b",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "bahtiyorovnozim/qwen3-vl-3-4b",
    "slug": "bahtiyorovnozim/qwen3-vl-3-4b",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "bahtiyorovnozim/qwen3-vl-3-8b",
    "slug": "bahtiyorovnozim/qwen3-vl-3-8b",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "bahtiyorovnozim/qwen3-vl-4-4b",
    "slug": "bahtiyorovnozim/qwen3-vl-4-4b",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "bahtiyorovnozim/qwen3-vl-4-8b",
    "slug": "bahtiyorovnozim/qwen3-vl-4-8b",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "bahtiyorovnozim/qwen3-vl-5-4b",
    "slug": "bahtiyorovnozim/qwen3-vl-5-4b",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "bahtiyorovnozim/qwen3-vl-5-8b",
    "slug": "bahtiyorovnozim/qwen3-vl-5-8b",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "bakllava",
    "slug": "bakllava",
    "description": "BakLLaVA is a multimodal model consisting of the Mistral 7B base model augmented with the LLaVA  architecture.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q2_K",
        "size": "3.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q3_K_S",
        "size": "3.8GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q3_K_M",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q3_K_L",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q4_0",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q4_1",
        "size": "5.2GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q4_K_S",
        "size": "4.8GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q4_K_M",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q5_0",
        "size": "5.6GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q5_1",
        "size": "6.1GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q5_K_S",
        "size": "5.6GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q5_K_M",
        "size": "5.8GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q6_K",
        "size": "6.6GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-q8_0",
        "size": "8.3GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1-fp16",
        "size": "15GB",
        "context": "32K",
        "input": "Text, Image"
      }
    ],
    "downloads": 399600
  },
  {
    "name": "bartk21/mistral-3-small-24b-q4-K-L",
    "slug": "bartk21/mistral-3-small-24b-q4-K-L",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "15GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "benedict/linkbricks-mistral-nemo-korean",
    "slug": "benedict/linkbricks-mistral-nemo-korean",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "12b",
        "size": "13GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 533
  },
  {
    "name": "bengt0/em_german_leo_mistral",
    "slug": "bengt0/em_german_leo_mistral",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q2_K",
        "size": "3.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q3_K_S",
        "size": "3.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q3_K_M",
        "size": "3.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q3_K_L",
        "size": "3.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q4_0",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q4_K_S",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q5_0",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "5.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "7.7GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "benzie/llava-phi-3",
    "slug": "benzie/llava-phi-3",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.9GB",
        "context": "4K",
        "input": "Text, Image"
      }
    ],
    "downloads": 5596
  },
  {
    "name": "bge-m3",
    "slug": "bge-m3",
    "description": "BGE-M3 is a new model from BAAI distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity.",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "567m",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "567m-fp16",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 3000000
  },
  {
    "name": "BiaoLuo/lca-bge-m3-ft",
    "slug": "BiaoLuo/lca-bge-m3-ft",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "BiaoLuo/lca-qwen3-embedding",
    "slug": "BiaoLuo/lca-qwen3-embedding",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "bigbug/minicpm-v2.5",
    "slug": "bigbug/minicpm-v2.5",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.0GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 2501
  },
  {
    "name": "bjoernb/gemma3n-e2b",
    "slug": "bjoernb/gemma3n-e2b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.6GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "bjoernb/gemma3n-e4b",
    "slug": "bjoernb/gemma3n-e4b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "bjoernb/qwen3-coder-30b-1m",
    "slug": "bjoernb/qwen3-coder-30b-1m",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "bkudler/llava-phi3",
    "slug": "bkudler/llava-phi3",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.9GB",
        "context": "4K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "BlackHillsInfoSec/llama-3.1-8b-abliterated",
    "slug": "BlackHillsInfoSec/llama-3.1-8b-abliterated",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "blaifa/Nanonets-OCR-s",
    "slug": "blaifa/Nanonets-OCR-s",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.6GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "3b-q8_0",
        "size": "4.6GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "blinky/voldemort-mini",
    "slug": "blinky/voldemort-mini",
    "description": "",
    "features": [
      "embedding",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "300m",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.7b",
        "size": "4.1GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "300m-bf16-embeddings",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "bobowg/mistral-large-3",
    "slug": "bobowg/mistral-large-3",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "-",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "bona/bge-m3-korean",
    "slug": "bona/bge-m3-korean",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 1926
  },
  {
    "name": "brnpistone/Qwen3-4B-AgentCoder-q5-k-m",
    "slug": "brnpistone/Qwen3-4B-AgentCoder-q5-k-m",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.9GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "brnpistone/Qwen3-4B-AgentCoder-q6-k",
    "slug": "brnpistone/Qwen3-4B-AgentCoder-q6-k",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "bsahane/DeepSeek-R1-Distill-Llama-8B",
    "slug": "bsahane/DeepSeek-R1-Distill-Llama-8B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q4_K_M_lms",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "bsahane/Mistral-Small-3.1",
    "slug": "bsahane/Mistral-Small-3.1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "24b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "call518/deepseek-r1-tool-calling",
    "slug": "call518/deepseek-r1-tool-calling",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "1.5b",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "cas/minicpm-3b-openhermes-2.5-v2",
    "slug": "cas/minicpm-3b-openhermes-2.5-v2",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 188
  },
  {
    "name": "cas/minicpm-3b-turangga-v3-ep50",
    "slug": "cas/minicpm-3b-turangga-v3-ep50",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.2GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 89
  },
  {
    "name": "cas/phi-3-mini-4k-instruct-llamafied-4q",
    "slug": "cas/phi-3-mini-4k-instruct-llamafied-4q",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.3GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "catbickerton/nomic-embed-text-cpu",
    "slug": "catbickerton/nomic-embed-text-cpu",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "274MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 54
  },
  {
    "name": "catsarethebest/llama3.2-4oClaude",
    "slug": "catsarethebest/llama3.2-4oClaude",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "o4-mini",
        "size": "2.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 1719
  },
  {
    "name": "charaf/bge-m3-f32",
    "slug": "charaf/bge-m3-f32",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.3GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 64
  },
  {
    "name": "charaf/dolphin-llama3.1",
    "slug": "charaf/dolphin-llama3.1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "8b-v2.9.4",
        "size": "32GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "chenzo/notConfucius.v2.llama3.1-8b",
    "slug": "chenzo/notConfucius.v2.llama3.1-8b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "chenzo/notConfucius.v2.qwen3-14b",
    "slug": "chenzo/notConfucius.v2.qwen3-14b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "16GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "childof7sins/llava-llama3-f16",
    "slug": "childof7sins/llava-llama3-f16",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "17GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "clore/deepseek-v3.1",
    "slug": "clore/deepseek-v3.1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "380GB",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "clore/gpt-oss-20b-Q8_0",
    "slug": "clore/gpt-oss-20b-Q8_0",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 285
  },
  {
    "name": "cnjack/mistral-samll-3.1",
    "slug": "cnjack/mistral-samll-3.1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "24b-it-q4_K_S",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "codegpt/deepseek-coder-1.3b-typescript",
    "slug": "codegpt/deepseek-coder-1.3b-typescript",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "1.4GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "f16",
        "size": "2.7GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "Cognaize/optimus-devstral-24b-xxl-v1.0.0",
    "slug": "Cognaize/optimus-devstral-24b-xxl-v1.0.0",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "Cognaize/optimus-devstral-small2-xxl-instruct-v1.0.0",
    "slug": "Cognaize/optimus-devstral-small2-xxl-instruct-v1.0.0",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "24b",
        "size": "15GB",
        "context": "384K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "CognitiveComputations/devstral-vision",
    "slug": "CognitiveComputations/devstral-vision",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "q3_K_M",
        "size": "12GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "CognitiveComputations/dolphin-llama3.1",
    "slug": "CognitiveComputations/dolphin-llama3.1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q2_K",
        "size": "3.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q3_K_S",
        "size": "3.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q3_K_M",
        "size": "4.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q3_K_L",
        "size": "4.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q4_0",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q4_K_S",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q5_0",
        "size": "5.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q5_K_S",
        "size": "5.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q5_K_M",
        "size": "5.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q6_K",
        "size": "6.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9.4-Q8_0",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 26900
  },
  {
    "name": "CognitiveComputations/dolphin-mistral-nemo",
    "slug": "CognitiveComputations/dolphin-mistral-nemo",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "v2.9.3",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q2_K",
        "size": "4.8GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q3_K_S",
        "size": "5.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q3_K_M",
        "size": "6.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q3_K_L",
        "size": "6.6GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q4_0",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q4_K_S",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q4_K_M",
        "size": "7.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q5_0",
        "size": "8.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q5_K_M",
        "size": "8.7GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q6_K",
        "size": "10GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-Q8_0",
        "size": "13GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-v2.9.3-F16",
        "size": "25GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 6891
  },
  {
    "name": "comptespgh/llama3.2-vision",
    "slug": "comptespgh/llama3.2-vision",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.8GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "creitin/mistral-nemo-think",
    "slug": "creitin/mistral-nemo-think",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "creitin/mistral-nemo-think-v0.2",
    "slug": "creitin/mistral-nemo-think-v0.2",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "crimeaisukraine/crimeaisukraine_dolphin_llama3_8b_q4_ks",
    "slug": "crimeaisukraine/crimeaisukraine_dolphin_llama3_8b_q4_ks",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "cua/gpt-oss-edit",
    "slug": "cua/gpt-oss-edit",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "cwchang/llama3-taide-lx-8b-chat-alpha1",
    "slug": "cwchang/llama3-taide-lx-8b-chat-alpha1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_k",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q3_k_s",
        "size": "3.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "4.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q3_k_l",
        "size": "4.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_0",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_1",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_k_s",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_k_m",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_0",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_1",
        "size": "6.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_k_s",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "8.5GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "cyberwald/llama-3.1-sauerkrautlm-8b-instruct",
    "slug": "cyberwald/llama-3.1-sauerkrautlm-8b-instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q4_0",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "5.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "6.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "dagbs/deepseek-coder-v2-lite-instruct",
    "slug": "dagbs/deepseek-coder-v2-lite-instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "10GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "iq3_m",
        "size": "7.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q4_k_l",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q5_k_l",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q6_k_l",
        "size": "15GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q8_0_l",
        "size": "17GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q2_k",
        "size": "6.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_s",
        "size": "7.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "8.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_l",
        "size": "8.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q4_k_s",
        "size": "9.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q4_k_m",
        "size": "10GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "q5_k_s",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "14GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "17GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq2_xs",
        "size": "6.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq2_s",
        "size": "6.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq2_m",
        "size": "6.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq3_xxs",
        "size": "7.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq3_xs",
        "size": "7.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq4_xs",
        "size": "8.6GB",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "dagbs/tinydolphin-2.8-1.1b",
    "slug": "dagbs/tinydolphin-2.8-1.1b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "668MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q2_k",
        "size": "432MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_s",
        "size": "499MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "548MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_l",
        "size": "592MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q4_k_s",
        "size": "640MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q4_k_m",
        "size": "668MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q5_k_s",
        "size": "766MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "903MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "1.2GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "danielsheep/gpt-oss-20b-Unsloth",
    "slug": "danielsheep/gpt-oss-20b-Unsloth",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "UD-Q4_K_XL",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "UD-Q6_K_XL",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 1287
  },
  {
    "name": "danielsheep/Qwen3-Coder-30B-A3B-Instruct-1M-Unsloth",
    "slug": "danielsheep/Qwen3-Coder-30B-A3B-Instruct-1M-Unsloth",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "18GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "UD-Q4_K_XL",
        "size": "18GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "UD-Q5_K_XL",
        "size": "22GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "UD-Q6_K_XL",
        "size": "26GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "UD-IQ3_XXS",
        "size": "13GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "datouxia/llama3-8b-chinese-chat-q8-v2",
    "slug": "datouxia/llama3-8b-chinese-chat-q8-v2",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.5GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "DC1LEX/nomic-embed-text-v1.5-multimodal",
    "slug": "DC1LEX/nomic-embed-text-v1.5-multimodal",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "274MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 2891
  },
  {
    "name": "deepcoder",
    "slug": "deepcoder",
    "description": "DeepCoder is a fully open-Source 14B coder model at O3-mini level, with a 1.5B version also available.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-preview-q4_K_M",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-preview-q8_0",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-preview-fp16",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-preview-q4_K_M",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-preview-q8_0",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-preview-fp16",
        "size": "30GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 501300
  },
  {
    "name": "deepscaler",
    "slug": "deepscaler",
    "description": "A fine-tuned version of Deepseek-R1-Distilled-Qwen-1.5B that surpasses the performance of OpenAIs o1-preview with just 1.5B parameters on popular math evaluations.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-preview-q4_K_M",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-preview-q8_0",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-preview-fp16",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 952100
  },
  {
    "name": "deepseek-coder",
    "slug": "deepseek-coder",
    "description": "DeepSeek Coder is a capable coding model trained on two trillion code and natural language tokens.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "base",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "instruct",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b",
        "size": "3.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b",
        "size": "19GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q2_K",
        "size": "632MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q3_K_S",
        "size": "659MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q3_K_M",
        "size": "705MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q3_K_L",
        "size": "745MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q4_0",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q4_1",
        "size": "856MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q4_K_S",
        "size": "815MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q4_K_M",
        "size": "874MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q5_0",
        "size": "936MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q5_1",
        "size": "1.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q5_K_S",
        "size": "953MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q5_K_M",
        "size": "1.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q6_K",
        "size": "1.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-q8_0",
        "size": "1.4GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-base-fp16",
        "size": "2.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q2_K",
        "size": "632MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q3_K_S",
        "size": "659MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q3_K_M",
        "size": "705MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q3_K_L",
        "size": "745MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q4_0",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q4_1",
        "size": "856MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q4_K_S",
        "size": "815MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q4_K_M",
        "size": "874MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q5_0",
        "size": "936MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q5_1",
        "size": "1.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q5_K_S",
        "size": "953MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q5_K_M",
        "size": "1.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q6_K",
        "size": "1.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-q8_0",
        "size": "1.4GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "1.3b-instruct-fp16",
        "size": "2.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base",
        "size": "3.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q2_K",
        "size": "2.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q3_K_S",
        "size": "3.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q3_K_M",
        "size": "3.3GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q3_K_L",
        "size": "3.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q4_0",
        "size": "3.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q4_1",
        "size": "4.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q4_K_S",
        "size": "3.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q4_K_M",
        "size": "4.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q5_0",
        "size": "4.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q5_1",
        "size": "5.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q5_K_S",
        "size": "4.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q5_K_M",
        "size": "4.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q6_K",
        "size": "5.5GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-q8_0",
        "size": "7.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-base-fp16",
        "size": "13GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct",
        "size": "3.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q2_K",
        "size": "2.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q3_K_S",
        "size": "3.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q3_K_M",
        "size": "3.3GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q3_K_L",
        "size": "3.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q4_0",
        "size": "3.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q4_1",
        "size": "4.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q4_K_S",
        "size": "3.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q4_K_M",
        "size": "4.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q5_0",
        "size": "4.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q5_1",
        "size": "5.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q5_K_S",
        "size": "4.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q5_K_M",
        "size": "4.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q6_K",
        "size": "5.5GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-q8_0",
        "size": "7.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b-instruct-fp16",
        "size": "13GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base",
        "size": "19GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q2_K",
        "size": "14GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q3_K_S",
        "size": "14GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q3_K_M",
        "size": "16GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q3_K_L",
        "size": "18GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q4_0",
        "size": "19GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q4_1",
        "size": "21GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q4_K_S",
        "size": "19GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q4_K_M",
        "size": "20GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q5_0",
        "size": "23GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q5_1",
        "size": "25GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q5_K_S",
        "size": "23GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q5_K_M",
        "size": "24GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q6_K",
        "size": "27GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-q8_0",
        "size": "35GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-base-fp16",
        "size": "67GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct",
        "size": "19GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q2_K",
        "size": "14GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q3_K_S",
        "size": "14GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q3_K_M",
        "size": "16GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q3_K_L",
        "size": "18GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q4_0",
        "size": "19GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q4_1",
        "size": "21GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q4_K_S",
        "size": "19GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q4_K_M",
        "size": "20GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q5_0",
        "size": "23GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q5_1",
        "size": "25GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q5_K_S",
        "size": "23GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q5_K_M",
        "size": "24GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q6_K",
        "size": "27GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-q8_0",
        "size": "35GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "33b-instruct-fp16",
        "size": "67GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": 2400000
  },
  {
    "name": "deepseek-coder-v2",
    "slug": "deepseek-coder-v2",
    "description": "An open-source Mixture-of-Experts code language model that achieves performance comparable to GPT4-Turbo in code-specific tasks.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "lite",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "16b",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "236b",
        "size": "133GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q2_K",
        "size": "6.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q3_K_S",
        "size": "7.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q3_K_M",
        "size": "8.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q3_K_L",
        "size": "8.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q4_0",
        "size": "8.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q4_1",
        "size": "9.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q4_K_S",
        "size": "9.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q4_K_M",
        "size": "10GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q5_0",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q5_1",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q5_K_S",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q5_K_M",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q6_K",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-q8_0",
        "size": "17GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-base-fp16",
        "size": "31GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q2_K",
        "size": "6.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q3_K_S",
        "size": "7.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q3_K_M",
        "size": "8.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q3_K_L",
        "size": "8.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q4_0",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q4_1",
        "size": "9.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q4_K_S",
        "size": "9.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q4_K_M",
        "size": "10GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q5_0",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q5_1",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q5_K_S",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q5_K_M",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q6_K",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-q8_0",
        "size": "17GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-instruct-fp16",
        "size": "31GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q2_K",
        "size": "86GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q3_K_S",
        "size": "102GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q3_K_M",
        "size": "113GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q3_K_L",
        "size": "122GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q4_0",
        "size": "133GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q4_1",
        "size": "148GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q4_K_S",
        "size": "134GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q4_K_M",
        "size": "142GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q5_0",
        "size": "162GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q5_1",
        "size": "177GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q5_K_S",
        "size": "162GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q5_K_M",
        "size": "167GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q6_K",
        "size": "194GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-q8_0",
        "size": "251GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-base-fp16",
        "size": "472GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q2_K",
        "size": "86GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q3_K_S",
        "size": "102GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q3_K_M",
        "size": "113GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q3_K_L",
        "size": "122GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q4_0",
        "size": "133GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q4_1",
        "size": "148GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q4_K_S",
        "size": "134GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q4_K_M",
        "size": "142GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q5_0",
        "size": "162GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q5_1",
        "size": "177GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q5_K_S",
        "size": "162GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q5_K_M",
        "size": "167GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q6_K",
        "size": "194GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-q8_0",
        "size": "251GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-instruct-fp16",
        "size": "472GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "deepseek-llm",
    "slug": "deepseek-llm",
    "description": "An advanced language model crafted with 2 trillion bilingual tokens.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b",
        "size": "38GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base",
        "size": "4.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q2_K",
        "size": "3.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q3_K_S",
        "size": "3.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q3_K_M",
        "size": "3.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q3_K_L",
        "size": "3.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q4_0",
        "size": "4.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q4_1",
        "size": "4.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q4_K_S",
        "size": "4.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q4_K_M",
        "size": "4.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q5_0",
        "size": "4.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q5_1",
        "size": "5.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q5_K_S",
        "size": "4.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q5_K_M",
        "size": "4.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q6_K",
        "size": "5.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-q8_0",
        "size": "7.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-base-fp16",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat",
        "size": "4.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q2_K",
        "size": "3.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q3_K_S",
        "size": "3.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q3_K_M",
        "size": "3.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q3_K_L",
        "size": "3.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q4_0",
        "size": "4.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q4_1",
        "size": "4.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q4_K_S",
        "size": "4.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q4_K_M",
        "size": "4.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q5_0",
        "size": "4.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q5_1",
        "size": "5.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q5_K_S",
        "size": "4.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q5_K_M",
        "size": "4.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q6_K",
        "size": "5.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q8_0",
        "size": "7.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-fp16",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base",
        "size": "38GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q2_K",
        "size": "28GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q3_K_S",
        "size": "29GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q3_K_M",
        "size": "33GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q3_K_L",
        "size": "36GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q4_0",
        "size": "38GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q4_1",
        "size": "42GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q4_K_S",
        "size": "38GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q4_K_M",
        "size": "40GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q5_0",
        "size": "46GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q5_1",
        "size": "51GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q5_K_S",
        "size": "46GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q5_K_M",
        "size": "48GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q6_K",
        "size": "55GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-q8_0",
        "size": "72GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-base-fp16",
        "size": "135GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat",
        "size": "38GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q2_K",
        "size": "28GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q3_K_S",
        "size": "29GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q3_K_M",
        "size": "33GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q3_K_L",
        "size": "36GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q4_0",
        "size": "38GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q4_1",
        "size": "42GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q4_K_S",
        "size": "38GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q4_K_M",
        "size": "40GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q5_0",
        "size": "46GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q5_1",
        "size": "51GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-q5_K_S",
        "size": "46GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "67b-chat-fp16",
        "size": "135GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 284400
  },
  {
    "name": "deepseek-ocr",
    "slug": "deepseek-ocr",
    "description": "DeepSeek-OCR is a vision-language model that can perform token-efficient OCR.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.7GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "3b",
        "size": "6.7GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "3b-bf16",
        "size": "6.7GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": 81100
  },
  {
    "name": "deepseek-r1",
    "slug": "deepseek-r1",
    "description": "DeepSeek's first-generation of reasoning models with comparable performance to OpenAI-o1, including six dense models distilled from DeepSeek-R1 based on Llama and Qwen.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "5.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "671b",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "1.5b-qwen-distill-q4_K_M",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-qwen-distill-q8_0",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-qwen-distill-fp16",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-qwen-distill-q4_K_M",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-qwen-distill-q8_0",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-qwen-distill-fp16",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-0528-qwen3-q4_K_M",
        "size": "5.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-0528-qwen3-q8_0",
        "size": "8.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-0528-qwen3-fp16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama-distill-q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama-distill-q8_0",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama-distill-fp16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-qwen-distill-q4_K_M",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-qwen-distill-q8_0",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-qwen-distill-fp16",
        "size": "30GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-qwen-distill-q4_K_M",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-qwen-distill-q8_0",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-qwen-distill-fp16",
        "size": "66GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-llama-distill-q4_K_M",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-llama-distill-q8_0",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-llama-distill-fp16",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "671b-0528-q4_K_M",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-0528-q8_0",
        "size": "713GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-0528-fp16",
        "size": "1.3TB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-q4_K_M",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-q8_0",
        "size": "713GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-fp16",
        "size": "1.3TB",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": 75400000
  },
  {
    "name": "deepseek-v2",
    "slug": "deepseek-v2",
    "description": "A strong, economical, and efficient Mixture-of-Experts language model.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "lite",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "16b",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "236b",
        "size": "133GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q2_K",
        "size": "6.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q3_K_S",
        "size": "7.5GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q3_K_M",
        "size": "8.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q3_K_L",
        "size": "8.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q4_0",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q4_1",
        "size": "9.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q4_K_S",
        "size": "9.5GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q4_K_M",
        "size": "10GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q5_0",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q5_1",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q5_K_S",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q5_K_M",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q6_K",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-q8_0",
        "size": "17GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "16b-lite-chat-fp16",
        "size": "31GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q2_K",
        "size": "86GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q3_K_S",
        "size": "102GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q3_K_M",
        "size": "113GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q3_K_L",
        "size": "122GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q4_0",
        "size": "133GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q4_1",
        "size": "148GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q4_K_S",
        "size": "134GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q4_K_M",
        "size": "142GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q5_0",
        "size": "162GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q5_1",
        "size": "177GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q5_K_S",
        "size": "162GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q5_K_M",
        "size": "167GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q6_K",
        "size": "194GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-q8_0",
        "size": "251GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-chat-fp16",
        "size": "472GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "deepseek-v2.5",
    "slug": "deepseek-v2.5",
    "description": "An upgraded version of DeekSeek-V2  that integrates the general and coding abilities of both DeepSeek-V2-Chat and DeepSeek-Coder-V2-Instruct.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "133GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b",
        "size": "133GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-q4_0",
        "size": "133GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-q4_1",
        "size": "148GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-q5_0",
        "size": "162GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-q5_1",
        "size": "177GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "236b-q8_0",
        "size": "251GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "deepseek-v3",
    "slug": "deepseek-v3",
    "description": "A strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-q4_K_M",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-q8_0",
        "size": "713GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b-fp16",
        "size": "1.3TB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 3100000
  },
  {
    "name": "deepseek-v3.1",
    "slug": "deepseek-v3.1",
    "description": "DeepSeek-V3.1-Terminus is a hybrid model that supports both thinking mode and non-thinking mode.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-cloud",
        "size": "-",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-terminus-q4_K_M",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-terminus-q8_0",
        "size": "713GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-terminus-fp16",
        "size": "1.3TB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-q8_0",
        "size": "713GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-fp16",
        "size": "1.3TB",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": 231100
  },
  {
    "name": "deepseek-v3.2",
    "slug": "deepseek-v3.2",
    "description": "DeepSeek-V3.2, a model that harmonizes high computational efficiency with superior reasoning and agent performance.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": 8591
  },
  {
    "name": "Definity/granite-embedding-278m-multilingual-Q8_0",
    "slug": "Definity/granite-embedding-278m-multilingual-Q8_0",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "303MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "demonbyron/embeddinggemma-300m-lawvault",
    "slug": "demonbyron/embeddinggemma-300m-lawvault",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "dengcao/EmbeddingGemma",
    "slug": "dengcao/EmbeddingGemma",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "300m",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "dengcao/Qwen3-Embedding-0.6B",
    "slug": "dengcao/Qwen3-Embedding-0.6B",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "Q8_0",
        "size": "639MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "F16",
        "size": "1.2GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 35400
  },
  {
    "name": "dengcao/Qwen3-Embedding-4B",
    "slug": "dengcao/Qwen3-Embedding-4B",
    "description": "",
    "features": [
      "embedding",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "2.5GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "2.9GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "4.3GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "F16",
        "size": "8.0GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": 17700
  },
  {
    "name": "dengcao/Qwen3-Embedding-8B",
    "slug": "dengcao/Qwen3-Embedding-8B",
    "description": "",
    "features": [
      "embedding",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "4.7GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "5.4GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "8.0GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "F16",
        "size": "15GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": 31100
  },
  {
    "name": "denisavetisyan/Qwen3-Embedding-8B",
    "slug": "denisavetisyan/Qwen3-Embedding-8B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.0GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "deterf/Jenna",
    "slug": "deterf/Jenna",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "devstral",
    "slug": "devstral",
    "description": "Devstral: the best open source model for coding agents",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b-small-2505-q4_K_M",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b-small-2505-q8_0",
        "size": "25GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b-small-2505-fp16",
        "size": "47GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 590600
  },
  {
    "name": "devstral-2",
    "slug": "devstral-2",
    "description": "123B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2512-q4_K_M",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2512-q8_0",
        "size": "133GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2512-fp16",
        "size": "250GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 25300
  },
  {
    "name": "devstral-small-2",
    "slug": "devstral-small-2",
    "description": "24B model that excels at using tools to explore codebases, editing multiple files and power software engineering agents.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "15GB",
        "context": "384K",
        "input": "Text, Image"
      },
      {
        "name": "24b",
        "size": "15GB",
        "context": "384K",
        "input": "Text, Image"
      },
      {
        "name": "24b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2512-q4_K_M",
        "size": "15GB",
        "context": "384K",
        "input": "Text, Image"
      },
      {
        "name": "24b-instruct-2512-q8_0",
        "size": "26GB",
        "context": "384K",
        "input": "Text, Image"
      },
      {
        "name": "24b-instruct-2512-fp16",
        "size": "48GB",
        "context": "384K",
        "input": "Text, Image"
      }
    ],
    "downloads": 61600
  },
  {
    "name": "dfebrero/mradermacher-mistral-small-3.1-24b-instruct-2503-jackterated-hf-i1-GGUF",
    "slug": "dfebrero/mradermacher-mistral-small-3.1-24b-instruct-2503-jackterated-hf-i1-GGUF",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "djdeniro/msmall-3.1-q6",
    "slug": "djdeniro/msmall-3.1-q6",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "doitmagic/glm-4.6v-flash",
    "slug": "doitmagic/glm-4.6v-flash",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q4",
        "size": "6.2GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "dojw/deepseek-r1-dis-llama8b-medicine-ctx32k",
    "slug": "dojw/deepseek-r1-dis-llama8b-medicine-ctx32k",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.7GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "dolphin-llama3",
    "slug": "dolphin-llama3",
    "description": "Dolphin 2.9 is a new model with 8B and 70B sizes by Eric Hartford based on Llama 3 that has a variety of instruction, conversational, and coding skills.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "v2.9",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-256k",
        "size": "4.7GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9",
        "size": "4.7GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q2_K",
        "size": "3.2GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q3_K_S",
        "size": "3.7GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q3_K_M",
        "size": "4.0GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q3_K_L",
        "size": "4.3GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q4_0",
        "size": "4.7GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q4_1",
        "size": "5.1GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q4_K_S",
        "size": "4.7GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q4_K_M",
        "size": "4.9GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q5_0",
        "size": "5.6GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q5_1",
        "size": "6.1GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q5_K_S",
        "size": "5.6GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q5_K_M",
        "size": "5.7GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q6_K",
        "size": "6.6GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-q8_0",
        "size": "8.5GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-256k-v2.9-fp16",
        "size": "16GB",
        "context": "250K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q2_K",
        "size": "3.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q3_K_S",
        "size": "3.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q3_K_M",
        "size": "4.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q3_K_L",
        "size": "4.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q4_0",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q4_1",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q4_K_S",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q4_K_M",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q5_0",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q5_1",
        "size": "6.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q5_K_S",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q5_K_M",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q6_K",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-q8_0",
        "size": "8.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v2.9-fp16",
        "size": "16GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q2_K",
        "size": "26GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q3_K_S",
        "size": "31GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q3_K_M",
        "size": "34GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q3_K_L",
        "size": "37GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q4_0",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q4_1",
        "size": "44GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q4_K_S",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q4_K_M",
        "size": "43GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q5_0",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q5_1",
        "size": "53GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q5_K_S",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q5_K_M",
        "size": "50GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q6_K",
        "size": "58GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-q8_0",
        "size": "75GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v2.9-fp16",
        "size": "141GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 704500
  },
  {
    "name": "dolphin3",
    "slug": "dolphin3",
    "description": "Dolphin 3.0 Llama 3.1 8B  is the next generation of the Dolphin series of instruct-tuned models designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama3.1-q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama3.1-q8_0",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama3.1-fp16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 3600000
  },
  {
    "name": "doomgrave/granite3.3",
    "slug": "doomgrave/granite3.3",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q2_K_L",
        "size": "3.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q3_K_S",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "dougstrouth/blog_assistant",
    "slug": "dougstrouth/blog_assistant",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "dreamingBumblebee/qwen2.5vl-3b-qlora-ko-1.5k",
    "slug": "dreamingBumblebee/qwen2.5vl-3b-qlora-ko-1.5k",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "dreamingBumblebee/qwen2.5vl-3b-qlora-ko-1.5k-llm-q4_k_m",
    "slug": "dreamingBumblebee/qwen2.5vl-3b-qlora-ko-1.5k-llm-q4_k_m",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "dreamingBumblebee/qwen2.5vl-3b-qlora-ko-1.5k_q4_k_m",
    "slug": "dreamingBumblebee/qwen2.5vl-3b-qlora-ko-1.5k_q4_k_m",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "Drews54/llama3.2-vision-abliterated",
    "slug": "Drews54/llama3.2-vision-abliterated",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "11b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 71400
  },
  {
    "name": "drivedenpadev/deepseek-v3.2",
    "slug": "drivedenpadev/deepseek-v3.2",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "duckyblender/caveman-llama3",
    "slug": "duckyblender/caveman-llama3",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_K_M",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "elyor/nomic-embed-text-long",
    "slug": "elyor/nomic-embed-text-long",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "274MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 15
  },
  {
    "name": "embeddinggemma",
    "slug": "embeddinggemma",
    "description": "EmbeddingGemma is a 300M parameter embedding model from Google.",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "300m",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "300m-qat-q4_0",
        "size": "239MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "300m-qat-q8_0",
        "size": "338MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "300m-bf16",
        "size": "622MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 348100
  },
  {
    "name": "EntropyYue/longwriter-glm4",
    "slug": "EntropyYue/longwriter-glm4",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "9b",
        "size": "5.5GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "epk2112/dolphin-llama3-mod-8192",
    "slug": "epk2112/dolphin-llama3-mod-8192",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "eramax/llama-3-8b-instruct-coder-v2",
    "slug": "eramax/llama-3-8b-instruct-coder-v2",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q5_k_m",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "eramax/openhands-lm-32b-v0.1",
    "slug": "eramax/openhands-lm-32b-v0.1",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "q4_K_M",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "eramax/stable-code-3b",
    "slug": "eramax/stable-code-3b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q5",
        "size": "2.0GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "EricLu/Mistral-Small-3.1-Q4_K_M",
    "slug": "EricLu/Mistral-Small-3.1-Q4_K_M",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "erukude/multiagent-orchestrator",
    "slug": "erukude/multiagent-orchestrator",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "1b",
        "size": "1.4GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "2.2GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "etangaming123/KAngel",
    "slug": "etangaming123/KAngel",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "exaone-deep",
    "slug": "exaone-deep",
    "description": "EXAONE Deep exhibits superior capabilities in various reasoning tasks including math and coding benchmarks, ranging from 2.4B to 32B parameters developed and released by LG AI Research.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "2.4b",
        "size": "1.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7.8b",
        "size": "4.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "19GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "2.4b-q4_K_M",
        "size": "1.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "2.4b-q8_0",
        "size": "2.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "2.4b-fp16",
        "size": "5.3GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7.8b-q4_K_M",
        "size": "4.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7.8b-q8_0",
        "size": "8.3GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7.8b-fp16",
        "size": "16GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M",
        "size": "19GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0",
        "size": "34GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-fp16",
        "size": "64GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "exaone3.5",
    "slug": "exaone3.5",
    "description": "EXAONE 3.5 is a collection of instruction-tuned bilingual (English and Korean) generative models ranging from 2.4B to 32B parameters, developed and released by LG AI Research.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "2.4b",
        "size": "1.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7.8b",
        "size": "4.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "19GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "2.4b-instruct-q4_K_M",
        "size": "1.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "2.4b-instruct-q8_0",
        "size": "2.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "2.4b-instruct-fp16",
        "size": "5.3GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7.8b-instruct-q4_K_M",
        "size": "4.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7.8b-instruct-q8_0",
        "size": "8.3GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7.8b-instruct-fp16",
        "size": "16GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-instruct-q4_K_M",
        "size": "19GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-instruct-q8_0",
        "size": "34GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-instruct-fp16",
        "size": "64GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 169100
  },
  {
    "name": "ExpedientFalcon/qwen2.5-coder-3b-instruct-q6_k",
    "slug": "ExpedientFalcon/qwen2.5-coder-3b-instruct-q6_k",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.8GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ExpedientFalcon/qwen3-1.7b-autocomplete",
    "slug": "ExpedientFalcon/qwen3-1.7b-autocomplete",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.4GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ExpedientFalcon/qwen3-14b-agent-m2max",
    "slug": "ExpedientFalcon/qwen3-14b-agent-m2max",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "9.3GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ExpedientFalcon/qwen3-32b-agent",
    "slug": "ExpedientFalcon/qwen3-32b-agent",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "20GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ExpedientFalcon/qwen3-4b-agent",
    "slug": "ExpedientFalcon/qwen3-4b-agent",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.6GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ExpedientFalcon/Qwen3-4B-UD-Q5_K_XL",
    "slug": "ExpedientFalcon/Qwen3-4B-UD-Q5_K_XL",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.9GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ExpedientFalcon/qwen3-embedding",
    "slug": "ExpedientFalcon/qwen3-embedding",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "0.6b-q8_0",
        "size": "639MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "4b-q4_k_m",
        "size": "2.5GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-q5_k_m",
        "size": "5.4GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0",
        "size": "8.0GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ExpedientFalcon/qwen3-reranker",
    "slug": "ExpedientFalcon/qwen3-reranker",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "0.6b-q4_k_m",
        "size": "396MB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "0.6b-q8_0",
        "size": "639MB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "4b-q4_k_m",
        "size": "2.5GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "4b-q5_k_m",
        "size": "2.9GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0",
        "size": "8.7GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "fackingamatherae/Deepseek_Llama_4",
    "slug": "fackingamatherae/Deepseek_Llama_4",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "42GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "falcon",
    "slug": "falcon",
    "description": "A large language model built by the Technology Innovation Institute (TII) for use in summarization, text generation, and chat bots.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "instruct",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "text",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b",
        "size": "24GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "180b",
        "size": "101GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-instruct",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q4_0",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q4_1",
        "size": "4.6GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q5_0",
        "size": "5.1GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q5_1",
        "size": "5.5GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q8_0",
        "size": "7.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-fp16",
        "size": "14GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-text",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-text-q4_0",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-text-q4_1",
        "size": "4.6GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-text-q5_0",
        "size": "5.1GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-text-q5_1",
        "size": "5.5GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-text-q8_0",
        "size": "7.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-text-fp16",
        "size": "14GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-instruct",
        "size": "24GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-instruct-q4_0",
        "size": "24GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-instruct-q4_1",
        "size": "26GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-instruct-q5_0",
        "size": "29GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-instruct-q5_1",
        "size": "32GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-instruct-q8_0",
        "size": "44GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-instruct-fp16",
        "size": "84GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-text",
        "size": "24GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-text-q4_0",
        "size": "24GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-text-q4_1",
        "size": "26GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-text-q5_0",
        "size": "29GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-text-q5_1",
        "size": "32GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-text-q8_0",
        "size": "44GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "40b-text-fp16",
        "size": "84GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "180b-chat",
        "size": "101GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "180b-chat-q4_0",
        "size": "101GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "180b-text",
        "size": "101GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "180b-text-q4_0",
        "size": "101GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 284700
  },
  {
    "name": "falcon2",
    "slug": "falcon2",
    "description": "Falcon2 is an 11B parameters causal decoder-only model built by TII and trained over 5T tokens.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "6.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b",
        "size": "6.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q2_K",
        "size": "4.3GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q3_K_S",
        "size": "4.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q3_K_M",
        "size": "5.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q3_K_L",
        "size": "5.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q4_0",
        "size": "6.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q4_1",
        "size": "7.1GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q4_K_S",
        "size": "6.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q4_K_M",
        "size": "6.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q5_0",
        "size": "7.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q5_1",
        "size": "8.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q5_K_S",
        "size": "7.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q5_K_M",
        "size": "8.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q6_K",
        "size": "9.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-q8_0",
        "size": "12GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "11b-fp16",
        "size": "22GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "falcon3",
    "slug": "falcon3",
    "description": "A family of efficient AI models under 10B parameters performant in science, math, and coding through innovative training techniques.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b",
        "size": "1.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "2.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "10b",
        "size": "6.3GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q4_K_M",
        "size": "1.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q8_0",
        "size": "1.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-fp16",
        "size": "3.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q4_K_M",
        "size": "2.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q8_0",
        "size": "3.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-fp16",
        "size": "6.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q4_K_M",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q8_0",
        "size": "7.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-fp16",
        "size": "15GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "10b-instruct-q4_K_M",
        "size": "6.3GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "10b-instruct-q8_0",
        "size": "11GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "10b-instruct-fp16",
        "size": "21GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "fervent_mcclintock/deepseek-r1-0528-qwen3-8b",
    "slug": "fervent_mcclintock/deepseek-r1-0528-qwen3-8b",
    "description": "",
    "features": [
      "thinking"
    ],
    "tags": [
      {
        "name": "Q4_K_XL",
        "size": "5.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "6.7GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "firefunction-v2",
    "slug": "firefunction-v2",
    "description": "An open weights function calling model based on Llama 3, competitive with GPT-4o function calling capabilities.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q2_K",
        "size": "26GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q3_K_S",
        "size": "31GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q3_K_M",
        "size": "34GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q3_K_L",
        "size": "37GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q4_0",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q4_1",
        "size": "44GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_S",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M",
        "size": "43GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q5_0",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q5_1",
        "size": "53GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q5_K_S",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q5_K_M",
        "size": "50GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q6_K",
        "size": "58GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0",
        "size": "75GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-fp16",
        "size": "141GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 86200
  },
  {
    "name": "flori/llama3.1-abliterated",
    "slug": "flori/llama3.1-abliterated",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "bf16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "fomenks/devstral-small_cline_roocode-64k",
    "slug": "fomenks/devstral-small_cline_roocode-64k",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "25GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "fredrezones55/Mistral-Small-3.1",
    "slug": "fredrezones55/Mistral-Small-3.1",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "Q3_K_M",
        "size": "11GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "fredrezones55/mistral3-unsloth",
    "slug": "fredrezones55/mistral3-unsloth",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "frizynn/qwen3-think-235B-A22B-2507-2bit-UD-Q2_K_XL",
    "slug": "frizynn/qwen3-think-235B-A22B-2507-2bit-UD-Q2_K_XL",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "frob/glm-4.7",
    "slug": "frob/glm-4.7",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "216GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "358b-a32b-q4_K_M",
        "size": "216GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "frob/KaLM-Embedding-Gemma3-12B-2511",
    "slug": "frob/KaLM-Embedding-Gemma3-12B-2511",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "24GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "frob/minimax-m2.1",
    "slug": "frob/minimax-m2.1",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "138GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "230b-a10b-q4_K_M",
        "size": "138GB",
        "context": "192K",
        "input": "Text"
      }
    ],
    "downloads": 11
  },
  {
    "name": "functiongemma",
    "slug": "functiongemma",
    "description": "FunctionGemma is a specialized version of Google's Gemma 3 270M model fine-tuned explicitly for function calling.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "301MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "270m",
        "size": "301MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "270m-it-q8_0",
        "size": "301MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "270m-it-fp16",
        "size": "552MB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 16200
  },
  {
    "name": "fzkun/deepseek-r1-medical",
    "slug": "fzkun/deepseek-r1-medical",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "8b",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "gabegoodhart/granite4-preview",
    "slug": "gabegoodhart/granite4-preview",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "tiny",
        "size": "4.0GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "gabegoodhart/minimax-m2",
    "slug": "gabegoodhart/minimax-m2",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "56GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "230b",
        "size": "56GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "230b-UD-TQ1_0",
        "size": "56GB",
        "context": "192K",
        "input": "Text"
      }
    ],
    "downloads": 136
  },
  {
    "name": "gabegoodhart/minimax-m2.1",
    "slug": "gabegoodhart/minimax-m2.1",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "68GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "229b-UD-TQ1_0",
        "size": "56GB",
        "context": "192K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "GandalfBaum/deepseek_r1-claude",
    "slug": "GandalfBaum/deepseek_r1-claude",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "GandalfBaum/deepseek_r1-claude3.7",
    "slug": "GandalfBaum/deepseek_r1-claude3.7",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 5055
  },
  {
    "name": "GandalfBaum/llama3.1-claude3.7",
    "slug": "GandalfBaum/llama3.1-claude3.7",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 3110
  },
  {
    "name": "GandalfBaum/llama3.2-claude3.7",
    "slug": "GandalfBaum/llama3.2-claude3.7",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 6266
  },
  {
    "name": "Gapsar/mistral_small-IQ3_M",
    "slug": "Gapsar/mistral_small-IQ3_M",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "11GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "gdisney/deepseek-coder-uncensored",
    "slug": "gdisney/deepseek-coder-uncensored",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "gdisney/mistral-large-uncensored",
    "slug": "gdisney/mistral-large-uncensored",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "69GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "gdisney/mistral-nemo-uncensored",
    "slug": "gdisney/mistral-nemo-uncensored",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 1519
  },
  {
    "name": "gemini-3-flash-preview",
    "slug": "gemini-3-flash-preview",
    "description": "Gemini 3 Flash offers frontier intelligence built for speed at a fraction of the cost.",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "-",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "cloud",
        "size": "-",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": 17300
  },
  {
    "name": "gemini-3-pro-preview",
    "slug": "gemini-3-pro-preview",
    "description": "Google's most intelligent model with SOTA reasoning and multimodal understanding, and powerful agentic and vibe coding capabilities.",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "-",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": 56700
  },
  {
    "name": "gemma3",
    "slug": "gemma3",
    "description": "The current, most capable model that runs on a single GPU.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "270m",
        "size": "292MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b",
        "size": "815MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "4b",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b",
        "size": "17GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "270m-it-qat",
        "size": "241MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "270m-it-q8_0",
        "size": "292MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "270m-it-fp16",
        "size": "543MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "270m-it-bf16",
        "size": "543MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-it-qat",
        "size": "1.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-it-q4_K_M",
        "size": "815MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-it-q8_0",
        "size": "1.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-it-fp16",
        "size": "2.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "4b-cloud",
        "size": "-",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "4b-it-qat",
        "size": "4.0GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-it-q4_K_M",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-it-q8_0",
        "size": "5.0GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-it-fp16",
        "size": "8.6GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b-cloud",
        "size": "-",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "12b-it-qat",
        "size": "8.9GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b-it-q4_K_M",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b-it-q8_0",
        "size": "13GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b-it-fp16",
        "size": "24GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-cloud",
        "size": "-",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "27b-it-qat",
        "size": "18GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-it-q4_K_M",
        "size": "17GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-it-q8_0",
        "size": "30GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-it-fp16",
        "size": "55GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": 29100000
  },
  {
    "name": "gemma3n",
    "slug": "gemma3n",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "e2b",
        "size": "5.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "e4b",
        "size": "7.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "e2b-it-q4_K_M",
        "size": "5.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "e2b-it-q8_0",
        "size": "6.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "e2b-it-fp16",
        "size": "8.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "e4b-it-q4_K_M",
        "size": "7.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "e4b-it-q8_0",
        "size": "9.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "e4b-it-fp16",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 977300
  },
  {
    "name": "GFalcon-UA/dolphin3-llama3.1",
    "slug": "GFalcon-UA/dolphin3-llama3.1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 319
  },
  {
    "name": "GFalcon-UA/dolphin3-mistral",
    "slug": "GFalcon-UA/dolphin3-mistral",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "13GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 156
  },
  {
    "name": "GFalcon-UA/dolphin3-r1-mistral",
    "slug": "GFalcon-UA/dolphin3-r1-mistral",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "13GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 790
  },
  {
    "name": "GFalcon-UA/nous-hermes-2-vision",
    "slug": "GFalcon-UA/nous-hermes-2-vision",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "GFalcon-UA/ReaderLM-v2",
    "slug": "GFalcon-UA/ReaderLM-v2",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q8",
        "size": "1.9GB",
        "context": "500K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ghyghoo8/minicpm-llama3-2_5",
    "slug": "ghyghoo8/minicpm-llama3-2_5",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "8b",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 449
  },
  {
    "name": "glm-4.6",
    "slug": "glm-4.6",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": 39700
  },
  {
    "name": "glm-4.7",
    "slug": "glm-4.7",
    "description": "Advancing the Coding Capability",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": 5667
  },
  {
    "name": "glm-4.7-flash",
    "slug": "glm-4.7-flash",
    "description": "As the strongest model in the 30B class, GLM-4.7-Flash offers a new option for lightweight deployment that balances performance and efficiency.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "q4_K_M",
        "size": "19GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "32GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "bf16",
        "size": "60GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "glm4",
    "slug": "glm4",
    "description": "A strong multi-lingual general language model with competitive performance to Llama 3.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "5.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b",
        "size": "5.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q2_K",
        "size": "4.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q3_K_S",
        "size": "4.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q3_K_M",
        "size": "5.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q3_K_L",
        "size": "5.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q4_0",
        "size": "5.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q4_1",
        "size": "6.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q4_K_S",
        "size": "5.8GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q4_K_M",
        "size": "6.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q5_0",
        "size": "6.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q5_1",
        "size": "7.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q5_K_S",
        "size": "6.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q5_K_M",
        "size": "7.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q6_K",
        "size": "8.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-q8_0",
        "size": "10.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-chat-fp16",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "9b-text-q2_K",
        "size": "4.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q3_K_S",
        "size": "4.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q3_K_M",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q3_K_L",
        "size": "5.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q4_0",
        "size": "5.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q4_1",
        "size": "6.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q4_K_S",
        "size": "5.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q4_K_M",
        "size": "6.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q5_0",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q5_1",
        "size": "7.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q5_K_S",
        "size": "6.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q5_K_M",
        "size": "7.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q6_K",
        "size": "8.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-q8_0",
        "size": "10.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b-text-fp16",
        "size": "19GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 224600
  },
  {
    "name": "goekdenizguelmez/Gabliterated-Qwen3",
    "slug": "goekdenizguelmez/Gabliterated-Qwen3",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-sky-high-hermes",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-sky-high-hermes-q4_k_m",
        "size": "2.5GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-sky-high-hermes-q5_k_m",
        "size": "2.9GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-sky-high-hermes-q6_k",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-sky-high-hermes-q8_0",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-thinking",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "thinking-4b-q4_k_m",
        "size": "2.5GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "thinking-4b-q5_k_m",
        "size": "2.9GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "thinking-4b-q6_k",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "thinking-4b-q8_0",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "goonsai/gemma3-4b-gab",
    "slug": "goonsai/gemma3-4b-gab",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.0GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "q8_0",
        "size": "5.0GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "f16",
        "size": "8.6GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "gpt-oss",
    "slug": "gpt-oss",
    "description": "OpenAIs open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b",
        "size": "65GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-cloud",
        "size": "-",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b-cloud",
        "size": "-",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 5600000
  },
  {
    "name": "gpt-oss-safeguard",
    "slug": "gpt-oss-safeguard",
    "description": "gpt-oss-safeguard-20b and gpt-oss-safeguard-120b are safety reasoning models built-upon gpt-oss",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b",
        "size": "65GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 38800
  },
  {
    "name": "granite-embedding",
    "slug": "granite-embedding",
    "description": "The IBM Granite Embedding 30M and 278M models models are text-only dense biencoder embedding models, with 30M available in English only and 278M serving multilingual use cases.",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "63MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "30m",
        "size": "63MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "278m",
        "size": "563MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "30m-en",
        "size": "63MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "30m-en-fp16",
        "size": "63MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "278m-fp16",
        "size": "563MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": 156600
  },
  {
    "name": "granite3.2",
    "slug": "granite3.2",
    "description": "Granite-3.2 is a family of long-context AI models from IBM Granite fine-tuned for thinking capabilities.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "2b",
        "size": "1.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "2b-instruct-q4_K_M",
        "size": "1.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "2b-instruct-q8_0",
        "size": "2.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "2b-instruct-fp16",
        "size": "5.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q8_0",
        "size": "8.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-fp16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "granite3.2-vision",
    "slug": "granite3.2-vision",
    "description": "A compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.4GB",
        "context": "16K",
        "input": "Text, Image"
      },
      {
        "name": "2b",
        "size": "2.4GB",
        "context": "16K",
        "input": "Text, Image"
      },
      {
        "name": "2b-q4_K_M",
        "size": "2.4GB",
        "context": "16K",
        "input": "Text, Image"
      },
      {
        "name": "2b-q8_0",
        "size": "3.6GB",
        "context": "16K",
        "input": "Text, Image"
      },
      {
        "name": "2b-fp16",
        "size": "6.0GB",
        "context": "16K",
        "input": "Text, Image"
      }
    ],
    "downloads": 609100
  },
  {
    "name": "granite4",
    "slug": "granite4",
    "description": "Granite 4 features improved instruction following (IF) and tool-calling capabilities, making them more effective in enterprise applications.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "micro",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "350m",
        "size": "708MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "350m-h",
        "size": "366MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "350m-h-q8_0",
        "size": "366MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "350m-bf16",
        "size": "708MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-h",
        "size": "1.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "1b-h-q8_0",
        "size": "1.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "1b-bf16",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-h",
        "size": "1.9GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "7b-a1b-h",
        "size": "4.2GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "32b-a9b-h",
        "size": "19GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "micro-h",
        "size": "1.9GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "small-h",
        "size": "19GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-h",
        "size": "4.2GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": 382900
  },
  {
    "name": "gurubot/gpt-oss-derestricted",
    "slug": "gurubot/gpt-oss-derestricted",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "20b",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 1047
  },
  {
    "name": "haghiri/DeepSeek-V3-0324",
    "slug": "haghiri/DeepSeek-V3-0324",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "IQ1_S",
        "size": "140GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 1360
  },
  {
    "name": "hamidakach/nomic-embed-text-v1.5-GGUF",
    "slug": "hamidakach/nomic-embed-text-v1.5-GGUF",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "81MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 106
  },
  {
    "name": "HammerAI/mistral-nemo-celeste-v1.9",
    "slug": "HammerAI/mistral-nemo-celeste-v1.9",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-q4_K_M",
        "size": "7.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-q5_K_M",
        "size": "8.7GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-q6_K",
        "size": "10GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-q8_0",
        "size": "13GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 2839
  },
  {
    "name": "HammerAI/mistral-nemo-uncensored",
    "slug": "HammerAI/mistral-nemo-uncensored",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-q4_0",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 2898
  },
  {
    "name": "HammerAI/openbmb-minicpm-llama3-v-2_5",
    "slug": "HammerAI/openbmb-minicpm-llama3-v-2_5",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M",
        "size": "6.0GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 2512
  },
  {
    "name": "happyaiuser/llama3.2-1b-finetome",
    "slug": "happyaiuser/llama3.2-1b-finetome",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.3GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "haybu/gpt-oss-120b",
    "slug": "haybu/gpt-oss-120b",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "65GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 220
  },
  {
    "name": "haybu/granite-embedding-278m",
    "slug": "haybu/granite-embedding-278m",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "563MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "haybu/mxbai-embed-large-latest",
    "slug": "haybu/mxbai-embed-large-latest",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "670MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": 183
  },
  {
    "name": "heavylildude/magnus-supernova",
    "slug": "heavylildude/magnus-supernova",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "heemang0826/gemma3n-e2b-clonnie",
    "slug": "heemang0826/gemma3n-e2b-clonnie",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "5.6GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "heemang0826/gemma3n-e4b-clonnie",
    "slug": "heemang0826/gemma3n-e4b-clonnie",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "hellord/mxbai-embed-large-v1",
    "slug": "hellord/mxbai-embed-large-v1",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "f16",
        "size": "670MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": 77700
  },
  {
    "name": "hhao/openbmb-minicpm-llama3-v-2_5",
    "slug": "hhao/openbmb-minicpm-llama3-v-2_5",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "IQ3_M",
        "size": "4.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q2_K",
        "size": "4.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q3_K_M",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_K_M",
        "size": "6.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_K_S",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "9.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "fp16",
        "size": "17GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 45000
  },
  {
    "name": "huihui_ai/deepscaler-abliterated",
    "slug": "huihui_ai/deepscaler-abliterated",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b",
        "size": "7.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-fp32",
        "size": "7.1GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/deepseek-v3",
    "slug": "huihui_ai/deepseek-v3",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "671b-q3_K",
        "size": "319GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b-q2_K",
        "size": "244GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/deepseek-v3-abliterated",
    "slug": "huihui_ai/deepseek-v3-abliterated",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "404GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b",
        "size": "404GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b-Q2_K",
        "size": "244GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b-Q3_K_M",
        "size": "319GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b-q4_K_M",
        "size": "404GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 2912
  },
  {
    "name": "huihui_ai/deepseek-v3-pruned",
    "slug": "huihui_ai/deepseek-v3-pruned",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "257GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "411b",
        "size": "257GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "411b-coder-0324",
        "size": "257GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "411b-coder-0324-q4_K_M",
        "size": "257GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "411b-coder-q4_K_M",
        "size": "257GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 1277
  },
  {
    "name": "huihui_ai/deepseek-v3.1",
    "slug": "huihui_ai/deepseek-v3.1",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "671b",
        "size": "244GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-Q3_K",
        "size": "319GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-Q2_K",
        "size": "244GB",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": 94
  },
  {
    "name": "huihui_ai/devstral-2-abliterated",
    "slug": "huihui_ai/devstral-2-abliterated",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-instruct",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2512",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2512-q4_K_M",
        "size": "75GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/devstral-abliterated",
    "slug": "huihui_ai/devstral-abliterated",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b-small-2505",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b-small-2505-q4_K_M",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b-small-2505-q8_0",
        "size": "25GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b-small-2505-fp16",
        "size": "47GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/dolphin3-abliterated",
    "slug": "huihui_ai/dolphin3-abliterated",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama3.1-q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama3.1-q8_0",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama3.1-fp16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 24400
  },
  {
    "name": "huihui_ai/dolphin3-r1-abliterated",
    "slug": "huihui_ai/dolphin3-r1-abliterated",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-mistral",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-mistral-q2_K",
        "size": "8.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-mistral-q3_K_M",
        "size": "11GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-mistral-q4_K_M",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-mistral-q5_K_M",
        "size": "17GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-mistral-q6_K",
        "size": "19GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-mistral-q8_0",
        "size": "25GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-mistral-fp16",
        "size": "47GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 1836
  },
  {
    "name": "huihui_ai/falcon3-abliterated",
    "slug": "huihui_ai/falcon3-abliterated",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b",
        "size": "1.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "2.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "10b",
        "size": "6.3GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-instruct",
        "size": "1.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q4_K_M",
        "size": "1.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q8_0",
        "size": "1.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-fp16",
        "size": "3.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "3b-instruct",
        "size": "2.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q4_K_M",
        "size": "2.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q8_0",
        "size": "3.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-fp16",
        "size": "6.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q4_K_M",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q8_0",
        "size": "7.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-fp16",
        "size": "15GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "10b-instruct",
        "size": "6.3GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "10b-instruct-q4_K_M",
        "size": "6.3GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "10b-instruct-q8_0",
        "size": "11GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "10b-instruct-fp16",
        "size": "21GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/gemma3n-abliterated",
    "slug": "huihui_ai/gemma3n-abliterated",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "e2b-fp16",
        "size": "8.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "e4b-fp16",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 15500
  },
  {
    "name": "huihui_ai/glm-4.7-abliterated",
    "slug": "huihui_ai/glm-4.7-abliterated",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "358b-q2_K",
        "size": "131GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/glm-4.7-flash-abliterated",
    "slug": "huihui_ai/glm-4.7-flash-abliterated",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "q4_K",
        "size": "19GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "q4_K_S",
        "size": "17GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "32GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "bf16",
        "size": "60GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/glm4.6-abliterated",
    "slug": "huihui_ai/glm4.6-abliterated",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "215GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "357b",
        "size": "215GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "357b-q3_K_M",
        "size": "170GB",
        "context": "198K",
        "input": "Text"
      },
      {
        "name": "357b-q4_K_M",
        "size": "215GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/gpt-oss-abliterated",
    "slug": "huihui_ai/gpt-oss-abliterated",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b",
        "size": "88GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-mxfp4",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-v2-q3_K_M",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-v2-q4_K_M",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-v2-q8_0",
        "size": "22GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-v2-fp16",
        "size": "42GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-q3_K_M",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-q4_K_M",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-q8_0",
        "size": "22GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b-fp16",
        "size": "42GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b-q3_K_M",
        "size": "71GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b-q4_K_M",
        "size": "88GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b-q8_0",
        "size": "124GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "120b-fp16",
        "size": "234GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 20800
  },
  {
    "name": "huihui_ai/granite3.2-vision-abliterated",
    "slug": "huihui_ai/granite3.2-vision-abliterated",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.4GB",
        "context": "16K",
        "input": "Text, Image"
      },
      {
        "name": "2b",
        "size": "2.4GB",
        "context": "16K",
        "input": "Text, Image"
      },
      {
        "name": "2b-q4_K_M",
        "size": "2.4GB",
        "context": "16K",
        "input": "Text, Image"
      },
      {
        "name": "2b-q8_0",
        "size": "3.6GB",
        "context": "16K",
        "input": "Text, Image"
      },
      {
        "name": "2b-fp16",
        "size": "6.0GB",
        "context": "16K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/kimi-k2",
    "slug": "huihui_ai/kimi-k2",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "373GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1026b",
        "size": "373GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1026b-instruct-Q2_K",
        "size": "373GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1026b-Q2_K",
        "size": "373GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/llama3.3-abliterated",
    "slug": "huihui_ai/llama3.3-abliterated",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q2_K",
        "size": "26GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_M",
        "size": "34GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_K_M",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_K_M",
        "size": "50GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q6_K",
        "size": "58GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q8_0",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-fp16",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 24100
  },
  {
    "name": "huihui_ai/llama3.3-abliterated-ft",
    "slug": "huihui_ai/llama3.3-abliterated-ft",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-fp16",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 1320
  },
  {
    "name": "huihui_ai/magistral-abliterated",
    "slug": "huihui_ai/magistral-abliterated",
    "description": "",
    "features": [
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "24b",
        "size": "14GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "24b-small-2506",
        "size": "14GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "24b-small-2506-q4_K_M",
        "size": "14GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "24b-small-2506-q8_0",
        "size": "25GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "24b-small-2506-fp16",
        "size": "47GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/mistral-small-abliterated",
    "slug": "huihui_ai/mistral-small-abliterated",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501-q2_K",
        "size": "8.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501-q3_K_M",
        "size": "11GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501-q4_K_M",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501-q5_K_M",
        "size": "17GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501-q6_K",
        "size": "19GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501-q8_0",
        "size": "25GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501-fp16",
        "size": "47GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/openthinker-abliterated",
    "slug": "huihui_ai/openthinker-abliterated",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0",
        "size": "8.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-fp16",
        "size": "15GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0",
        "size": "35GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-fp16",
        "size": "66GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/qwen2.5-vl-abliterated",
    "slug": "huihui_ai/qwen2.5-vl-abliterated",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.0GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "3b",
        "size": "3.2GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "7b",
        "size": "6.0GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b",
        "size": "21GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "3b-instruct",
        "size": "3.2GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "3b-instruct-q4_K_M",
        "size": "3.2GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "3b-instruct-q8_0",
        "size": "4.6GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "3b-instruct-fp16",
        "size": "7.5GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "7b-instruct",
        "size": "6.0GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "7b-instruct-q4_K_M",
        "size": "6.0GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "7b-instruct-q8_0",
        "size": "9.4GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "7b-instruct-fp16",
        "size": "17GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct",
        "size": "21GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-q4_K_M",
        "size": "21GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-q8_0",
        "size": "36GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-fp16",
        "size": "67GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/qwen3-next-abliterated",
    "slug": "huihui_ai/qwen3-next-abliterated",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "48GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b",
        "size": "48GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-instruct",
        "size": "48GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-instruct-q4_K_M",
        "size": "48GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-instruct-q8_0",
        "size": "85GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-instruct-fp16",
        "size": "159GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking",
        "size": "48GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking-q4_K_M",
        "size": "48GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking-q8_0",
        "size": "85GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking-fp16",
        "size": "159GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/qwen3-vl-abliterated",
    "slug": "huihui_ai/qwen3-vl-abliterated",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct-q4_K_M",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct-q8_0",
        "size": "2.6GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct-fp16",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking-q4_K_M",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking-q8_0",
        "size": "2.6GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking-fp16",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-q4_K_M",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-q8_0",
        "size": "2.6GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-fp16",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct-q4_K_M",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct-q8_0",
        "size": "5.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct-fp16",
        "size": "8.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking-q4_K_M",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking-q8_0",
        "size": "5.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking-fp16",
        "size": "8.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-q4_K_M",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-q8_0",
        "size": "9.8GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-fp16",
        "size": "18GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking-q4_K_M",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking-q8_0",
        "size": "9.8GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking-fp16",
        "size": "18GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct-q4_K_M",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct-q8_0",
        "size": "34GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct-fp16",
        "size": "62GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-Thinking",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-Thinking-v2",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-Thinking-q4_K_M",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-Thinking-v2-q4_K_M",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-Thinking-q8_0",
        "size": "34GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-Thinking-v2-q8_0",
        "size": "34GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-Thinking-fp16",
        "size": "62GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-Thinking-v2-fp16",
        "size": "62GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-q4_K_M",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-q8_0",
        "size": "36GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-fp16",
        "size": "67GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking-q4_K_M",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking-q8_0",
        "size": "36GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking-fp16",
        "size": "67GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": 29000
  },
  {
    "name": "huihui_ai/s1-abliterated",
    "slug": "huihui_ai/s1-abliterated",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q2_K",
        "size": "12GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q3_K_M",
        "size": "16GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q5_K_M",
        "size": "23GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q6_K",
        "size": "27GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0",
        "size": "35GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-fp16",
        "size": "66GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "huihui_ai/tinyr1-abliterated",
    "slug": "huihui_ai/tinyr1-abliterated",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-preview",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-preview-q4_K_M",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-preview-q8_0",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-preview-fp16",
        "size": "66GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "Huzderu/deepseek-r1-671b-1.73bit",
    "slug": "Huzderu/deepseek-r1-671b-1.73bit",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "169GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 26700
  },
  {
    "name": "Huzderu/deepseek-r1-671b-2.22bit",
    "slug": "Huzderu/deepseek-r1-671b-2.22bit",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "196GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 5867
  },
  {
    "name": "Huzderu/deepseek-r1-671b-2.51bit",
    "slug": "Huzderu/deepseek-r1-671b-2.51bit",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "227GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 60500
  },
  {
    "name": "i82blikeu/gemma-3n-E4B-it-GGUF",
    "slug": "i82blikeu/gemma-3n-E4B-it-GGUF",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q3_K_M",
        "size": "3.7GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "i82blikeu/gemma3n7GB",
    "slug": "i82blikeu/gemma3n7GB",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ibm/granite4.0-preview",
    "slug": "ibm/granite4.0-preview",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "tiny",
        "size": "4.0GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q2_K",
        "size": "2.5GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q3_K_S",
        "size": "2.9GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q3_K_M",
        "size": "3.2GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q3_K_L",
        "size": "3.4GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q4_0",
        "size": "3.8GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q4_1",
        "size": "4.2GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q4_K_S",
        "size": "3.8GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q4_K_M",
        "size": "4.1GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q5_0",
        "size": "4.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q5_1",
        "size": "5.0GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q5_K_S",
        "size": "4.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q5_K_M",
        "size": "4.7GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q6_K",
        "size": "5.5GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-q8_0",
        "size": "7.1GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-base-f16",
        "size": "13GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q2_K",
        "size": "2.5GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q3_K_S",
        "size": "2.9GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q3_K_M",
        "size": "3.2GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q3_K_L",
        "size": "3.4GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q4_0",
        "size": "3.8GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q4_1",
        "size": "4.2GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q4_K_S",
        "size": "3.8GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q4_K_M",
        "size": "4.0GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q5_0",
        "size": "4.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q5_1",
        "size": "5.0GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q5_K_S",
        "size": "4.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q5_K_M",
        "size": "4.7GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q6_K",
        "size": "5.5GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-q8_0",
        "size": "7.1GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "tiny-instruct-f16",
        "size": "13GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ifioravanti/lwm",
    "slug": "ifioravanti/lwm",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.8GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "3.8GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "7b-1m",
        "size": "3.8GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "7b-1m-text-chat",
        "size": "3.8GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "7b-1m-text-chat-q4_0",
        "size": "3.8GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "7b-1m-text-chat-q5_k_m",
        "size": "4.8GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "7b-1m-text-chat-q8_0",
        "size": "7.2GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "imac/gemma-2-9b-it-function-calling",
    "slug": "imac/gemma-2-9b-it-function-calling",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q6_k",
        "size": "7.6GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "impactframes/dolphin_llama3_omost",
    "slug": "impactframes/dolphin_llama3_omost",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "infinitestack/tinyllama-sugarcane",
    "slug": "infinitestack/tinyllama-sugarcane",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.2GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 72
  },
  {
    "name": "ingu627/Qwen2.5-VL-7B-Instruct-Q5_K_M",
    "slug": "ingu627/Qwen2.5-VL-7B-Instruct-Q5_K_M",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "5.4GB",
        "context": "125K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "inke/Qwen3-Embedding-0.6B",
    "slug": "inke/Qwen3-Embedding-0.6B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "inke/Qwen3-Embedding-8B",
    "slug": "inke/Qwen3-Embedding-8B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "5.4GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "instructlab/granite-7b-lab",
    "slug": "instructlab/granite-7b-lab",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "iradukundadev/finetuned-deepseek-r1_7b",
    "slug": "iradukundadev/finetuned-deepseek-r1_7b",
    "description": "",
    "features": [
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ishumilin/deepseek-r1-coder-tools",
    "slug": "ishumilin/deepseek-r1-coder-tools",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "1.5b",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b",
        "size": "30GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "66GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 556200
  },
  {
    "name": "ishumilin/deepseek-r1-coder-tools-tuned",
    "slug": "ishumilin/deepseek-r1-coder-tools-tuned",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "1.5b",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b",
        "size": "30GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "66GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "itbaaN/tinyllama-philosopher",
    "slug": "itbaaN/tinyllama-philosopher",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "jace-ai/SmolLM2-German-Instruct",
    "slug": "jace-ai/SmolLM2-German-Instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "360m",
        "size": "820MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-q4_k_m",
        "size": "303MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-q8_0",
        "size": "437MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-bf16",
        "size": "820MB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "jacksonrezende/Aurora-Mistral-Large3-675B-Cloud",
    "slug": "jacksonrezende/Aurora-Mistral-Large3-675B-Cloud",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.5kB",
        "context": "-",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "jan-fischer-haw/jinx-gpt-oss-20b",
    "slug": "jan-fischer-haw/jinx-gpt-oss-20b",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 228
  },
  {
    "name": "jaro/llama32_datafusion",
    "slug": "jaro/llama32_datafusion",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 7
  },
  {
    "name": "jayeshpandit2480/gemma3-UNCENSORED",
    "slug": "jayeshpandit2480/gemma3-UNCENSORED",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "1b",
        "size": "815MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "4b",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "jayeshpandit2480/granite4-UNCENSORED",
    "slug": "jayeshpandit2480/granite4-UNCENSORED",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "jefferyb/granite",
    "slug": "jefferyb/granite",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-lab-Q4_K_M",
        "size": "4.1GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "jeffgreen311/eve-qwen2.5-vl-7b-fineweb-oracle",
    "slug": "jeffgreen311/eve-qwen2.5-vl-7b-fineweb-oracle",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "6.2GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "jewelzufo/granite-4.0-h-350m-base-GGUF",
    "slug": "jewelzufo/granite-4.0-h-350m-base-GGUF",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q4_1",
        "size": "232MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "223MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "252MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "366MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "BF16",
        "size": "685MB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "jewelzufo/granite-4.0-h-350m-rpi5-sentiment-analysis",
    "slug": "jewelzufo/granite-4.0-h-350m-rpi5-sentiment-analysis",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "223MB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "jewelzufo/unsloth_granite-4.0-h-350m-GGUF",
    "slug": "jewelzufo/unsloth_granite-4.0-h-350m-GGUF",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "223MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q3_K_XL",
        "size": "191MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q4_K_XL",
        "size": "225MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q5_K_XL",
        "size": "253MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q6_K_XL",
        "size": "311MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q8_K_XL",
        "size": "461MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q3_K_M",
        "size": "189MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "223MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "252MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "284MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "IQ3_XXS",
        "size": "160MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "IQ4_XS",
        "size": "208MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "IQ4_NL",
        "size": "216MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "BF16",
        "size": "685MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Base-Q6_K",
        "size": "284MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Base-Q8_0",
        "size": "366MB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "JLR145/francois",
    "slug": "JLR145/francois",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.2GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "jmcastagnetto/deepseek-r1-distill-llama-8b",
    "slug": "jmcastagnetto/deepseek-r1-distill-llama-8b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "joeAI/phi3.5",
    "slug": "joeAI/phi3.5",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.4GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 281
  },
  {
    "name": "JollyLlama/Mistral-Small-3.1-24B",
    "slug": "JollyLlama/Mistral-Small-3.1-24B",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "Q4_K_S",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "18GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "joreilly86/structural_llama_3.0",
    "slug": "joreilly86/structural_llama_3.0",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "jotschi/dolphin-mistral-24b",
    "slug": "jotschi/dolphin-mistral-24b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "24b-instruct-q5_0",
        "size": "16GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-q8_0",
        "size": "25GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-fp16",
        "size": "47GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 193
  },
  {
    "name": "jshargo/gemma-3N-finetune-4B",
    "slug": "jshargo/gemma-3N-finetune-4B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.4GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "justinledwards/mistral-small-3.1-Q6_K",
    "slug": "justinledwards/mistral-small-3.1-Q6_K",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "k----n/Qwen3-Embedding-0.6B-F16",
    "slug": "k----n/Qwen3-Embedding-0.6B-F16",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "KaLM-Embedding/KaLM-Embedding-Gemma3-12B-2511",
    "slug": "KaLM-Embedding/KaLM-Embedding-Gemma3-12B-2511",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "24GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "kamesh6592/aj-tinyllama",
    "slug": "kamesh6592/aj-tinyllama",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "638MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "Karlo-Andric/Karlo-mxbai-embed-large",
    "slug": "Karlo-Andric/Karlo-mxbai-embed-large",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "670MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": 11
  },
  {
    "name": "Kathashke/KPA",
    "slug": "Kathashke/KPA",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "kelvi23/axum-caller-3.3-latest",
    "slug": "kelvi23/axum-caller-3.3-latest",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "kerncore/llama3.3-70b-q4_K_M",
    "slug": "kerncore/llama3.3-70b-q4_K_M",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "kimi-k2.5",
    "slug": "kimi-k2.5",
    "description": "Kimi K2.5 is an open-source, native multimodal agentic model that seamlessly integrates vision and language understanding with advanced agentic capabilities, instant and thinking modes, as well as conversational and agentic paradigms.",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "kiwi_kiwi/qwen2.5_vl_a",
    "slug": "kiwi_kiwi/qwen2.5_vl_a",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "3b",
        "size": "1.9GB",
        "context": "125K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "koesn/dolphin-llama3-8b",
    "slug": "koesn/dolphin-llama3-8b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q4_0",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "koesn/mistral-7b-instruct",
    "slug": "koesn/mistral-7b-instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q4_0",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "5.9GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "kollcn/llama3-8b-chinese-chat-f16-v2",
    "slug": "kollcn/llama3-8b-chinese-chat-f16-v2",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "16GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "kongxiangyiren/Neko-Chat",
    "slug": "kongxiangyiren/Neko-Chat",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "krith/mistral-large-instruct-2407",
    "slug": "krith/mistral-large-instruct-2407",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "IQ3_M",
        "size": "55GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ1_M",
        "size": "28GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ2_XXS",
        "size": "32GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ2_XS",
        "size": "36GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ2_M",
        "size": "42GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ3_XXS",
        "size": "47GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ4_XS",
        "size": "65GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "krith/mistral-nemo-instruct-2407-abliterated",
    "slug": "krith/mistral-nemo-instruct-2407-abliterated",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "IQ3_M",
        "size": "5.7GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "IQ3_XS",
        "size": "5.3GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "IQ3_S",
        "size": "5.6GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "IQ4_XS",
        "size": "6.8GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 491
  },
  {
    "name": "krory/gemma3-12b-amoral",
    "slug": "krory/gemma3-12b-amoral",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "sober",
        "size": "9.7GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "kwangsuklee/SEOKDONG-llama3.1_korean_Q5_K_M",
    "slug": "kwangsuklee/SEOKDONG-llama3.1_korean_Q5_K_M",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.7GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "l284190056/Qwen3-Embedding-8B-f16",
    "slug": "l284190056/Qwen3-Embedding-8B-f16",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "15GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "lastmass/llama3.2-chinese",
    "slug": "lastmass/llama3.2-chinese",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.2GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "LDqs/llama-3.1-8b-instruct-ayq-int4-16k-20240827",
    "slug": "LDqs/llama-3.1-8b-instruct-ayq-int4-16k-20240827",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "leonvanbokhorst/deepseek-r1-overthinking",
    "slug": "leonvanbokhorst/deepseek-r1-overthinking",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "LESSTHANSUPER/DARK_PLANET_REBEL_FURY-Llama3-25b",
    "slug": "LESSTHANSUPER/DARK_PLANET_REBEL_FURY-Llama3-25b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "Q3_K_S",
        "size": "11GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q4_K_S",
        "size": "14GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "18GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "20GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "IQ2_XXS",
        "size": "6.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "IQ3_S",
        "size": "11GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "IQ4_XS",
        "size": "13GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "LESSTHANSUPER/DARKEST_UNIVERSE-Mistral_Nemo-29b",
    "slug": "LESSTHANSUPER/DARKEST_UNIVERSE-Mistral_Nemo-29b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "Q2_K",
        "size": "11GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "Q3_K_S",
        "size": "13GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "Q3_K_M",
        "size": "14GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "Q4_K_S",
        "size": "17GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "Q5_K_S",
        "size": "20GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "IQ3_XXS",
        "size": "11GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "IQ3_S",
        "size": "13GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "IQ4_XS",
        "size": "16GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 665
  },
  {
    "name": "LESSTHANSUPER/MAGNUM_V4-Mistral_Small",
    "slug": "LESSTHANSUPER/MAGNUM_V4-Mistral_Small",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "12b_IQ4_XS",
        "size": "6.7GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b_Q4_K_S",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b_Q5_K_M",
        "size": "8.7GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b_Q6_K",
        "size": "10GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "22b_IQ4_XS",
        "size": "12GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "22b_Q4_K_M",
        "size": "13GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "27b_IQ3_M",
        "size": "12GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "27b_IQ3_S",
        "size": "12GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "27b_IQ3_XS",
        "size": "12GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "27b_IQ3_XXS",
        "size": "11GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "27b_IQ4_XS",
        "size": "15GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "27b_Q2_K",
        "size": "10GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "27b_Q3_K_L",
        "size": "15GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "27b_Q3_K_M",
        "size": "13GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "27b_Q3_K_S",
        "size": "12GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "27b_Q4_K_S",
        "size": "16GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "27b_Q5_K_S",
        "size": "19GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b_IQ2_S",
        "size": "3.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b_IQ3_S",
        "size": "4.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b_IQ3_XXS",
        "size": "3.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b_IQ4_XS",
        "size": "5.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b_Q2_K",
        "size": "3.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b_Q3_K_L",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b_Q4_K_S",
        "size": "5.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b_Q5_K_M",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "9b_Q6_K",
        "size": "7.6GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "LESSTHANSUPER/MARS-Gemma3-28b",
    "slug": "LESSTHANSUPER/MARS-Gemma3-28b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "Q2_K",
        "size": "11GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q2_K_S",
        "size": "10GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q3_K_S",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q3_K_M",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "17GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ3_XXS",
        "size": "11GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ3_S",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ4_XS",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "LESSTHANSUPER/THE_OMEGA_DIRECTIVE-Mistral_Small3.2-24b",
    "slug": "LESSTHANSUPER/THE_OMEGA_DIRECTIVE-Mistral_Small3.2-24b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "Q3_K_S",
        "size": "10GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_K_S",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "17GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ2_XXS",
        "size": "6.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ3_XXS",
        "size": "9.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ3_S",
        "size": "10GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ4_XS",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "LESSTHANSUPER/WEIRD_COMPOUND-Mistral_Small3.2-24b",
    "slug": "LESSTHANSUPER/WEIRD_COMPOUND-Mistral_Small3.2-24b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "Q3_K_S",
        "size": "10GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_K_S",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "17GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "25GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ2_XXS",
        "size": "6.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ2_XS",
        "size": "7.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ3_XXS",
        "size": "9.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ3_S",
        "size": "10GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ4_XS",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "lfm2.5-thinking",
    "slug": "lfm2.5-thinking",
    "description": "LFM2.5 is a new family of hybrid models designed for on-device deployment.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "731MB",
        "context": "125K",
        "input": "Text"
      },
      {
        "name": "1.2b",
        "size": "731MB",
        "context": "125K",
        "input": "Text"
      },
      {
        "name": "1.2b-q4_K_M",
        "size": "731MB",
        "context": "125K",
        "input": "Text"
      },
      {
        "name": "1.2b-q8_0",
        "size": "1.2GB",
        "context": "125K",
        "input": "Text"
      },
      {
        "name": "1.2b-bf16",
        "size": "2.3GB",
        "context": "125K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "lgkt/llama3-chinese-alpaca",
    "slug": "lgkt/llama3-chinese-alpaca",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "lingyezhixing/Granite4-H-tiny-UD",
    "slug": "lingyezhixing/Granite4-H-tiny-UD",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "Q4_K_XL",
        "size": "4.1GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "Q5_K_XL",
        "size": "5.0GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "llama-guard3",
    "slug": "llama-guard3",
    "description": "Llama Guard 3 is a series of models fine-tuned for content safety classification of LLM inputs and responses.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b",
        "size": "1.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q2_K",
        "size": "667MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q3_K_S",
        "size": "755MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q3_K_M",
        "size": "804MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q3_K_L",
        "size": "845MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q4_0",
        "size": "919MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q4_1",
        "size": "996MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q4_K_S",
        "size": "923MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q4_K_M",
        "size": "955MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q5_0",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q5_1",
        "size": "1.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q5_K_S",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q5_K_M",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q6_K",
        "size": "1.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-q8_0",
        "size": "1.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-fp16",
        "size": "3.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q2_K",
        "size": "3.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q3_K_S",
        "size": "3.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q3_K_M",
        "size": "4.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q3_K_L",
        "size": "4.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_0",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_1",
        "size": "5.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_S",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q5_0",
        "size": "5.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q5_1",
        "size": "6.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q5_K_S",
        "size": "5.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q5_K_M",
        "size": "5.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q6_K",
        "size": "6.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-fp16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 166700
  },
  {
    "name": "llama2-chinese",
    "slug": "llama2-chinese",
    "description": "Llama 2 based model fine tuned to improve Chinese dialogue ability.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q2_K",
        "size": "2.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q3_K_S",
        "size": "2.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q3_K_M",
        "size": "3.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q3_K_L",
        "size": "3.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q4_0",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q4_1",
        "size": "4.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q4_K_S",
        "size": "3.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q4_K_M",
        "size": "4.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q5_0",
        "size": "4.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q5_1",
        "size": "5.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q5_K_S",
        "size": "4.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q5_K_M",
        "size": "4.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q6_K",
        "size": "5.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-q8_0",
        "size": "7.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-chat-fp16",
        "size": "13GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q2_K",
        "size": "5.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q3_K_S",
        "size": "5.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q3_K_M",
        "size": "6.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q3_K_L",
        "size": "6.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q4_0",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q4_1",
        "size": "8.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q4_K_S",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q4_K_M",
        "size": "7.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q5_0",
        "size": "9.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q5_1",
        "size": "9.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q5_K_S",
        "size": "9.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q5_K_M",
        "size": "9.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q6_K",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-q8_0",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-chat-fp16",
        "size": "26GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 235800
  },
  {
    "name": "llama3",
    "slug": "llama3",
    "description": "Meta Llama 3: The most capable openly available LLM to date",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "instruct",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "text",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q2_K",
        "size": "3.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q3_K_S",
        "size": "3.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q3_K_M",
        "size": "4.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q3_K_L",
        "size": "4.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_0",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_1",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_K_S",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_K_M",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q5_0",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q5_1",
        "size": "6.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q5_K_S",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q5_K_M",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q6_K",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q8_0",
        "size": "8.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-fp16",
        "size": "16GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q2_K",
        "size": "3.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q3_K_S",
        "size": "3.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q3_K_M",
        "size": "4.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q3_K_L",
        "size": "4.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q4_0",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q4_1",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q4_K_S",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q4_K_M",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q5_0",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q5_1",
        "size": "6.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q5_K_S",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q5_K_M",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q6_K",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-q8_0",
        "size": "8.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-text-fp16",
        "size": "16GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q2_K",
        "size": "26GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_S",
        "size": "31GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_M",
        "size": "34GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_L",
        "size": "37GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_0",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_1",
        "size": "44GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_K_S",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_K_M",
        "size": "43GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_0",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_1",
        "size": "53GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_K_S",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_K_M",
        "size": "50GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q6_K",
        "size": "58GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q8_0",
        "size": "75GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-fp16",
        "size": "141GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q2_K",
        "size": "26GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q3_K_S",
        "size": "31GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q3_K_M",
        "size": "34GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q3_K_L",
        "size": "37GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q4_0",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q4_1",
        "size": "44GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q4_K_S",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q4_K_M",
        "size": "43GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q5_0",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q5_1",
        "size": "53GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q5_K_S",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q5_K_M",
        "size": "50GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q6_K",
        "size": "58GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-q8_0",
        "size": "75GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-text-fp16",
        "size": "141GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 13200000
  },
  {
    "name": "llama3-chatqa",
    "slug": "llama3-chatqa",
    "description": "A model from NVIDIA based on Llama 3 that excels at conversational question answering (QA) and retrieval-augmented generation (RAG).",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q2_K",
        "size": "3.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q3_K_S",
        "size": "3.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q3_K_M",
        "size": "4.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q3_K_L",
        "size": "4.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q4_0",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q4_1",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q4_K_S",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q4_K_M",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q5_0",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q5_1",
        "size": "6.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q5_K_S",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q5_K_M",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q6_K",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-q8_0",
        "size": "8.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-v1.5-fp16",
        "size": "16GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q2_K",
        "size": "26GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q3_K_S",
        "size": "31GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q3_K_M",
        "size": "34GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q3_K_L",
        "size": "37GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q4_0",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q4_1",
        "size": "44GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q4_K_S",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q4_K_M",
        "size": "43GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q5_0",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q5_1",
        "size": "53GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q5_K_S",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q5_K_M",
        "size": "50GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q6_K",
        "size": "58GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-q8_0",
        "size": "75GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-v1.5-fp16",
        "size": "141GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 200800
  },
  {
    "name": "llama3-gradient",
    "slug": "llama3-gradient",
    "description": "This model extends LLama-3 8B's context length from 8k to over 1m tokens.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "instruct",
        "size": "4.7GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "1048k",
        "size": "4.7GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.7GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "40GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q2_K",
        "size": "3.2GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q3_K_S",
        "size": "3.7GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q3_K_M",
        "size": "4.0GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q3_K_L",
        "size": "4.3GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q4_0",
        "size": "4.7GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q4_1",
        "size": "5.1GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q4_K_S",
        "size": "4.7GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q4_K_M",
        "size": "4.9GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q5_0",
        "size": "5.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q5_1",
        "size": "6.1GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q5_K_S",
        "size": "5.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q5_K_M",
        "size": "5.7GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q6_K",
        "size": "6.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-q8_0",
        "size": "8.5GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "8b-instruct-1048k-fp16",
        "size": "16GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q2_K",
        "size": "26GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q3_K_S",
        "size": "31GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q3_K_M",
        "size": "34GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q3_K_L",
        "size": "37GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q4_0",
        "size": "40GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q4_1",
        "size": "44GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q4_K_S",
        "size": "40GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q4_K_M",
        "size": "43GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q5_0",
        "size": "49GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q5_1",
        "size": "53GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q5_K_S",
        "size": "49GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q5_K_M",
        "size": "50GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q6_K",
        "size": "58GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-q8_0",
        "size": "75GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "70b-instruct-1048k-fp16",
        "size": "141GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": 173000
  },
  {
    "name": "llama3-groq-tool-use",
    "slug": "llama3-groq-tool-use",
    "description": "A series of models from Groq that represent a significant advancement in open-source AI capabilities for tool use/function calling.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q2_K",
        "size": "3.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q3_K_S",
        "size": "3.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q3_K_M",
        "size": "4.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q3_K_L",
        "size": "4.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q4_0",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q4_1",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_S",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q5_0",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q5_1",
        "size": "6.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q5_K_S",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q5_K_M",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q6_K",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0",
        "size": "8.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "8b-fp16",
        "size": "16GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q2_K",
        "size": "26GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q3_K_S",
        "size": "31GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q3_K_M",
        "size": "34GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q3_K_L",
        "size": "37GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q4_0",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q4_1",
        "size": "44GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_S",
        "size": "40GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M",
        "size": "43GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q5_0",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q5_1",
        "size": "53GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q5_K_S",
        "size": "49GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q5_K_M",
        "size": "50GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q6_K",
        "size": "58GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0",
        "size": "75GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b-fp16",
        "size": "141GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 172000
  },
  {
    "name": "llama3.1",
    "slug": "llama3.1",
    "description": "Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b",
        "size": "243GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q2_K",
        "size": "3.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q3_K_S",
        "size": "3.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q3_K_M",
        "size": "4.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q3_K_L",
        "size": "4.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_0",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_1",
        "size": "5.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_K_S",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q5_0",
        "size": "5.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q5_1",
        "size": "6.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q5_K_S",
        "size": "5.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q5_K_M",
        "size": "5.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q6_K",
        "size": "6.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q8_0",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-fp16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q2_K",
        "size": "3.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q3_K_S",
        "size": "3.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q3_K_M",
        "size": "4.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q3_K_L",
        "size": "4.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q4_0",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q4_1",
        "size": "5.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q4_K_S",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q5_0",
        "size": "5.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q5_1",
        "size": "6.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q5_K_S",
        "size": "5.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q5_K_M",
        "size": "5.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q6_K",
        "size": "6.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-q8_0",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-text-fp16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q2_K",
        "size": "26GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_S",
        "size": "31GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_M",
        "size": "34GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_L",
        "size": "37GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_0",
        "size": "40GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_K_S",
        "size": "40GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_K_M",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_0",
        "size": "49GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_1",
        "size": "53GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_K_S",
        "size": "49GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_K_M",
        "size": "50GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q6_K",
        "size": "58GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q8_0",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-fp16",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q2_K",
        "size": "26GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q3_K_S",
        "size": "31GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q3_K_M",
        "size": "34GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q3_K_L",
        "size": "37GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q4_0",
        "size": "40GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q4_1",
        "size": "44GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q4_K_S",
        "size": "40GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q4_K_M",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q5_0",
        "size": "49GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q5_1",
        "size": "53GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q5_K_S",
        "size": "49GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q5_K_M",
        "size": "50GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q6_K",
        "size": "58GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-q8_0",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-text-fp16",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q2_K",
        "size": "149GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q3_K_S",
        "size": "175GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q3_K_M",
        "size": "195GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q3_K_L",
        "size": "213GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q4_0",
        "size": "229GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q4_1",
        "size": "254GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q4_K_S",
        "size": "231GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q4_K_M",
        "size": "243GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q5_0",
        "size": "279GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q5_1",
        "size": "305GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q5_K_S",
        "size": "279GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q5_K_M",
        "size": "287GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q6_K",
        "size": "333GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-q8_0",
        "size": "431GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-instruct-fp16",
        "size": "812GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q2_K",
        "size": "149GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q3_K_S",
        "size": "175GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q3_K_M",
        "size": "195GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q3_K_L",
        "size": "213GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q4_0",
        "size": "229GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q4_1",
        "size": "254GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q4_K_S",
        "size": "231GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q4_K_M",
        "size": "243GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q5_0",
        "size": "279GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q5_1",
        "size": "305GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q5_K_S",
        "size": "279GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q5_K_M",
        "size": "287GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q6_K",
        "size": "333GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-q8_0",
        "size": "431GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "405b-text-fp16",
        "size": "812GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 108200000
  },
  {
    "name": "llama3.2",
    "slug": "llama3.2",
    "description": "Meta's Llama 3.2 goes small with 1B and 3B models.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b",
        "size": "1.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q2_K",
        "size": "581MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q3_K_S",
        "size": "642MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q3_K_M",
        "size": "691MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q3_K_L",
        "size": "733MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q4_0",
        "size": "771MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q4_1",
        "size": "832MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q4_K_S",
        "size": "776MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q4_K_M",
        "size": "808MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q5_0",
        "size": "893MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q5_1",
        "size": "953MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q5_K_S",
        "size": "893MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q5_K_M",
        "size": "912MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q6_K",
        "size": "1.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-q8_0",
        "size": "1.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-instruct-fp16",
        "size": "2.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q2_K",
        "size": "581MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q3_K_S",
        "size": "642MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q3_K_M",
        "size": "691MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q3_K_L",
        "size": "733MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q4_0",
        "size": "771MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q4_1",
        "size": "832MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q4_K_S",
        "size": "776MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q4_K_M",
        "size": "808MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q5_0",
        "size": "893MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q5_1",
        "size": "953MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q5_K_S",
        "size": "893MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q5_K_M",
        "size": "912MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q6_K",
        "size": "1.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-q8_0",
        "size": "1.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-text-fp16",
        "size": "2.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q2_K",
        "size": "1.4GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q3_K_S",
        "size": "1.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q3_K_M",
        "size": "1.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q3_K_L",
        "size": "1.8GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q4_0",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q4_1",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q4_K_S",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q4_K_M",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q5_0",
        "size": "2.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q5_1",
        "size": "2.4GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q5_K_S",
        "size": "2.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q5_K_M",
        "size": "2.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q6_K",
        "size": "2.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q8_0",
        "size": "3.4GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-fp16",
        "size": "6.4GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q2_K",
        "size": "1.4GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q3_K_S",
        "size": "1.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q3_K_M",
        "size": "1.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q3_K_L",
        "size": "1.8GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q4_0",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q4_1",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q4_K_S",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q4_K_M",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q5_0",
        "size": "2.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q5_1",
        "size": "2.4GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q5_K_S",
        "size": "2.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q5_K_M",
        "size": "2.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q6_K",
        "size": "2.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-q8_0",
        "size": "3.4GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-text-fp16",
        "size": "6.4GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 51400000
  },
  {
    "name": "llama3.2-vision",
    "slug": "llama3.2-vision",
    "description": "Llama 3.2 Vision is a collection of instruction-tuned image reasoning generative models in 11B and 90B sizes.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.8GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "11b",
        "size": "7.8GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "90b",
        "size": "55GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "11b-instruct-q4_K_M",
        "size": "7.8GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "11b-instruct-q8_0",
        "size": "12GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "11b-instruct-fp16",
        "size": "21GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "90b-instruct-q4_K_M",
        "size": "55GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "90b-instruct-q8_0",
        "size": "95GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "90b-instruct-fp16",
        "size": "177GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": 3500000
  },
  {
    "name": "llama3.3",
    "slug": "llama3.3",
    "description": "New state of the art 70B model. Llama 3.3 70B offers similar performance compared to the Llama 3.1 405B model.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q2_K",
        "size": "26GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_S",
        "size": "31GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_M",
        "size": "34GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_0",
        "size": "40GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_K_S",
        "size": "40GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_K_M",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_0",
        "size": "49GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_1",
        "size": "53GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_K_M",
        "size": "50GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q6_K",
        "size": "58GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q8_0",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-fp16",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 2900000
  },
  {
    "name": "llamallamaduck/mtg-card-converter-14b-instruct-iMat_1",
    "slug": "llamallamaduck/mtg-card-converter-14b-instruct-iMat_1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q8_0",
        "size": "17GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "llava",
    "slug": "llava",
    "description": " LLaVA is a novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding. Updated to version 1.6.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "v1.6",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "13b",
        "size": "8.0GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "34b",
        "size": "20GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q2_K",
        "size": "3.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q3_K_S",
        "size": "3.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q3_K_M",
        "size": "3.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q3_K_L",
        "size": "4.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q4_0",
        "size": "4.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q4_1",
        "size": "4.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q4_K_S",
        "size": "4.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q4_K_M",
        "size": "4.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q5_0",
        "size": "5.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q5_1",
        "size": "5.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q5_K_S",
        "size": "5.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q5_K_M",
        "size": "5.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q6_K",
        "size": "6.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-q8_0",
        "size": "7.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.5-fp16",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q2_K",
        "size": "3.3GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q3_K_S",
        "size": "3.8GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q3_K_M",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q3_K_L",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q4_0",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q4_1",
        "size": "5.2GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q4_K_S",
        "size": "4.8GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q4_K_M",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q5_0",
        "size": "5.6GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q5_1",
        "size": "6.1GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q5_K_S",
        "size": "5.6GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q5_K_M",
        "size": "5.8GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q6_K",
        "size": "6.6GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-q8_0",
        "size": "8.3GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-mistral-fp16",
        "size": "15GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "7b-v1.6-vicuna-q2_K",
        "size": "3.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q3_K_S",
        "size": "3.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q3_K_M",
        "size": "3.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q3_K_L",
        "size": "4.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q4_0",
        "size": "4.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q4_1",
        "size": "4.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q4_K_S",
        "size": "4.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q4_K_M",
        "size": "4.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q5_0",
        "size": "5.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q5_1",
        "size": "5.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q5_K_S",
        "size": "5.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q5_K_M",
        "size": "5.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q6_K",
        "size": "6.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-q8_0",
        "size": "7.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v1.6-vicuna-fp16",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q2_K",
        "size": "6.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q3_K_S",
        "size": "6.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q3_K_M",
        "size": "7.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q3_K_L",
        "size": "7.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q4_0",
        "size": "8.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q4_1",
        "size": "8.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q4_K_S",
        "size": "8.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q4_K_M",
        "size": "8.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q5_0",
        "size": "9.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q5_1",
        "size": "10GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q5_K_S",
        "size": "9.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q5_K_M",
        "size": "9.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q6_K",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-q8_0",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.5-fp16",
        "size": "27GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v1.6",
        "size": "8.0GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q2_K",
        "size": "5.5GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q3_K_S",
        "size": "6.3GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q3_K_M",
        "size": "7.0GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q3_K_L",
        "size": "7.6GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q4_0",
        "size": "8.0GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q4_1",
        "size": "8.8GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q4_K_S",
        "size": "8.1GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q4_K_M",
        "size": "8.5GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q5_0",
        "size": "9.6GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q5_1",
        "size": "10GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q5_K_S",
        "size": "9.6GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q5_K_M",
        "size": "9.9GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q6_K",
        "size": "11GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-q8_0",
        "size": "14GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "13b-v1.6-vicuna-fp16",
        "size": "27GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "34b-v1.6",
        "size": "20GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q2_K",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q3_K_S",
        "size": "16GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q3_K_M",
        "size": "17GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q3_K_L",
        "size": "19GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q4_0",
        "size": "20GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q4_1",
        "size": "22GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q4_K_S",
        "size": "20GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q4_K_M",
        "size": "21GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q5_0",
        "size": "24GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q5_1",
        "size": "27GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q5_K_S",
        "size": "24GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q5_K_M",
        "size": "25GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q6_K",
        "size": "29GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-q8_0",
        "size": "37GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "34b-v1.6-fp16",
        "size": "69GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 12300000
  },
  {
    "name": "llava-llama3",
    "slug": "llava-llama3",
    "description": "A LLaVA model fine-tuned from Llama 3 Instruct with better scores in several benchmarks.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.5GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "5.5GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "8b-v1.1-q4_0",
        "size": "5.5GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "8b-v1.1-fp16",
        "size": "17GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": 2100000
  },
  {
    "name": "llava-phi3",
    "slug": "llava-phi3",
    "description": "A new small LLaVA model fine-tuned from Phi 3 Mini.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.9GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "3.8b",
        "size": "2.9GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "3.8b-mini-q4_0",
        "size": "2.9GB",
        "context": "4K",
        "input": "Text, Image"
      },
      {
        "name": "3.8b-mini-fp16",
        "size": "8.3GB",
        "context": "4K",
        "input": "Text, Image"
      }
    ],
    "downloads": 165000
  },
  {
    "name": "lordoliver/DeepSeek-V3-0324",
    "slug": "lordoliver/DeepSeek-V3-0324",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "713GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b",
        "size": "713GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b-q4_k_m",
        "size": "404GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b-q8_0",
        "size": "713GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 607
  },
  {
    "name": "LoTUs5494/mistral-small-3.1",
    "slug": "LoTUs5494/mistral-small-3.1",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_K_L",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2503-iq4_NL",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "lucas2024/mistral-nemo-japanese-instruct-2408",
    "slug": "lucas2024/mistral-nemo-japanese-instruct-2408",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q8_0",
        "size": "13GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 594
  },
  {
    "name": "lucataco/deepseek-v3-64k",
    "slug": "lucataco/deepseek-v3-64k",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "lukehinds/tinyllama-test",
    "slug": "lukehinds/tinyllama-test",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "638MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "lwk/v3",
    "slug": "lwk/v3",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 809
  },
  {
    "name": "MadMind/Qwen3-Embedding-8B-GGUF-Q4_K_M",
    "slug": "MadMind/Qwen3-Embedding-8B-GGUF-Q4_K_M",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "magistral",
    "slug": "magistral",
    "description": "Magistral is a small, efficient reasoning model with 24B parameters.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "39K",
        "input": "Text"
      },
      {
        "name": "24b",
        "size": "14GB",
        "context": "39K",
        "input": "Text"
      },
      {
        "name": "24b-small-2506-q4_K_M",
        "size": "14GB",
        "context": "39K",
        "input": "Text"
      },
      {
        "name": "24b-small-2506-q8_0",
        "size": "25GB",
        "context": "39K",
        "input": "Text"
      },
      {
        "name": "24b-small-2506-fp16",
        "size": "47GB",
        "context": "39K",
        "input": "Text"
      }
    ],
    "downloads": 889400
  },
  {
    "name": "Malicus7862/deepseekcoder-6.7b-jarvis-gguf",
    "slug": "Malicus7862/deepseekcoder-6.7b-jarvis-gguf",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mangiucugna/bakllava-1",
    "slug": "mangiucugna/bakllava-1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mannix/deepseek-coder-v2-lite-instruct",
    "slug": "mannix/deepseek-coder-v2-lite-instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q2_k",
        "size": "6.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_s",
        "size": "7.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "8.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_l",
        "size": "8.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q4_0",
        "size": "8.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q4_1",
        "size": "9.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q4_k_s",
        "size": "9.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q4_k_m",
        "size": "10GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q5_0",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q5_1",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q5_k_s",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "17GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq2_xs",
        "size": "6.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq2_s",
        "size": "6.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq3_xxs",
        "size": "7.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq3_xs",
        "size": "7.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq3_s",
        "size": "7.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq4_xs",
        "size": "8.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "iq4_nl",
        "size": "8.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "fp16",
        "size": "31GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mannix/deepseek-v2-lite-instruct",
    "slug": "mannix/deepseek-v2-lite-instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "9.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_s",
        "size": "7.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "8.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q4_1",
        "size": "9.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q5_1",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "17GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mannix/dolphin-2.9-llama3-8b",
    "slug": "mannix/dolphin-2.9-llama3-8b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mannix/llama-3.3",
    "slug": "mannix/llama-3.3",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "40GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "iq2_xxs",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "iq2_xs",
        "size": "21GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "iq2_s",
        "size": "22GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "iq3_xxs",
        "size": "27GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "iq3_xs",
        "size": "29GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "iq3_s",
        "size": "31GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "iq4_xs",
        "size": "38GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "iq4_nl",
        "size": "40GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mannix/llama3-8b-ablitered-v3",
    "slug": "mannix/llama3-8b-ablitered-v3",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q2_k",
        "size": "3.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q3_k_s",
        "size": "3.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "4.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q3_k_l",
        "size": "4.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_0",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_1",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_k_s",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_k_m",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_0",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_1",
        "size": "6.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_k_s",
        "size": "5.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "5.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "6.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "8.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "iq2_xxs",
        "size": "2.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "iq2_xs",
        "size": "2.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "iq2_s",
        "size": "2.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "iq3_xxs",
        "size": "3.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "iq3_s",
        "size": "3.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "iq4_xs",
        "size": "4.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "iq4_nl",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "fp16",
        "size": "16GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "mix-fp16-q6_k",
        "size": "7.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "mix-fp16-q8_0",
        "size": "9.5GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mantisec/magistral-devstral-fused-roocode",
    "slug": "mantisec/magistral-devstral-fused-roocode",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "32b-q6-32k",
        "size": "29GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "manutic/nomic-embed-code",
    "slug": "manutic/nomic-embed-code",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-Q4_K_M",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0",
        "size": "7.5GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 4162
  },
  {
    "name": "Maoyue/mistral-nemo-instruct-2407",
    "slug": "Maoyue/mistral-nemo-instruct-2407",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 1831
  },
  {
    "name": "Maoyue/mistral-nemo-minitron-8b-instruct",
    "slug": "Maoyue/mistral-nemo-minitron-8b-instruct",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "marco/em_german_mistral_v01",
    "slug": "marco/em_german_mistral_v01",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "marksverdhei/normistral",
    "slug": "marksverdhei/normistral",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "11b",
        "size": "6.9GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "marlonbarriossolano/sati-ai-gpt-oss",
    "slug": "marlonbarriossolano/sati-ai-gpt-oss",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MartinRizzo/Ayla-Light-v2",
    "slug": "MartinRizzo/Ayla-Light-v2",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "12b-q4_K_M",
        "size": "7.5GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 3293
  },
  {
    "name": "maryasov/mistral-nemo-cline",
    "slug": "maryasov/mistral-nemo-cline",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "12b-instruct-2407-q2_K",
        "size": "4.8GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 404
  },
  {
    "name": "mashriram/gemma3nTools",
    "slug": "mashriram/gemma3nTools",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "e2b",
        "size": "5.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "e4b",
        "size": "7.5GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mashriram/gpt-oss-Regular",
    "slug": "mashriram/gpt-oss-Regular",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 714
  },
  {
    "name": "Maternion/LightOnOCR-2",
    "slug": "Maternion/LightOnOCR-2",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.5GB",
        "context": "16K",
        "input": "Text, Image"
      },
      {
        "name": "1b",
        "size": "1.5GB",
        "context": "16K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "mathstral",
    "slug": "mathstral",
    "description": "Mathtral: a 7B model designed for math reasoning and scientific discovery by Mistral AI.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q2_K",
        "size": "2.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q3_K_S",
        "size": "3.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q3_K_M",
        "size": "3.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q3_K_L",
        "size": "3.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_0",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_1",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_K_S",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_K_M",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_0",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_1",
        "size": "5.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_K_S",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_K_M",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q6_K",
        "size": "5.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q8_0",
        "size": "7.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-fp16",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 107600
  },
  {
    "name": "maxiweissenbacher/sauerkrautlm-mistral-nemo-12b-instruct-tool-support",
    "slug": "maxiweissenbacher/sauerkrautlm-mistral-nemo-12b-instruct-tool-support",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "fp16",
        "size": "25GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mbenhamd/qwen2.5-14b-instruct-cline-128k-q8_0",
    "slug": "mbenhamd/qwen2.5-14b-instruct-cline-128k-q8_0",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "35GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mbenhamd/qwen2.5-7b-instruct-cline-128k-q8_0",
    "slug": "mbenhamd/qwen2.5-7b-instruct-cline-128k-q8_0",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "8.1GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mcgdj/gpt-oss-6.0b",
    "slug": "mcgdj/gpt-oss-6.0b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.6GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 538
  },
  {
    "name": "mdq100/Gemma3-Instruct-Abliterated",
    "slug": "mdq100/Gemma3-Instruct-Abliterated",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "12b",
        "size": "7.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "27b",
        "size": "17GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": 7895
  },
  {
    "name": "mdq100/Qwen3-Coder-30B-A3B-Instruct",
    "slug": "mdq100/Qwen3-Coder-30B-A3B-Instruct",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "30b",
        "size": "18GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MedAIBase/Qwen3-VL-Embedding",
    "slug": "MedAIBase/Qwen3-VL-Embedding",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "2b",
        "size": "3.4GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "2b-q8_0",
        "size": "1.8GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "2b-fp16",
        "size": "3.4GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MedAIBase/Qwen3-VL-Reranker",
    "slug": "MedAIBase/Qwen3-VL-Reranker",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "2b",
        "size": "3.4GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "2b-q8_0",
        "size": "1.8GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "2b-fp16",
        "size": "3.4GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "meditron",
    "slug": "meditron",
    "description": "Open-source medical large language model adapted from Llama 2 to the medical domain.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "3.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "39GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-q2_K",
        "size": "2.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q3_K_S",
        "size": "2.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q3_K_M",
        "size": "3.3GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q3_K_L",
        "size": "3.6GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q4_0",
        "size": "3.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q4_1",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_S",
        "size": "3.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M",
        "size": "4.1GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q5_0",
        "size": "4.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q5_1",
        "size": "5.1GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q5_K_S",
        "size": "4.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q5_K_M",
        "size": "4.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q6_K",
        "size": "5.5GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0",
        "size": "7.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-fp16",
        "size": "13GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "70b-q4_0",
        "size": "39GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-q4_1",
        "size": "43GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_S",
        "size": "39GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-q5_1",
        "size": "52GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 152200
  },
  {
    "name": "mervinpraison/llama3.3-70B-harupfall",
    "slug": "mervinpraison/llama3.3-70B-harupfall",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "70b",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MFDoom/deepseek-coder-v2-tool-calling",
    "slug": "MFDoom/deepseek-coder-v2-tool-calling",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "16b",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "236b",
        "size": "133GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MFDoom/deepseek-r1-tool-calling",
    "slug": "MFDoom/deepseek-r1-tool-calling",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "671b",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "1.5b-qwen-distill-q4_K_M",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-qwen-distill-q8_0",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-qwen-distill-fp16",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-qwen-distill-q4_K_M",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-qwen-distill-q8_0",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-qwen-distill-fp16",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama-distill-q4_K_M",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama-distill-q8_0",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-llama-distill-fp16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-qwen-distill-q4_K_M",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-qwen-distill-q8_0",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-qwen-distill-fp16",
        "size": "30GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-qwen-distill-q4_K_M",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-qwen-distill-q8_0",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-qwen-distill-fp16",
        "size": "66GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-llama-distill-q4_K_M",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-llama-distill-q8_0",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-llama-distill-fp16",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 26800
  },
  {
    "name": "MFDoom/deepseek-v2-tool-calling",
    "slug": "MFDoom/deepseek-v2-tool-calling",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "16b",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "236b",
        "size": "133GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MFDoom/deepseek-v3-tool-calling",
    "slug": "MFDoom/deepseek-v3-tool-calling",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b",
        "size": "404GB",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": 903
  },
  {
    "name": "MHKetbi/allenai_OLMo2-0325-32B-Instruct",
    "slug": "MHKetbi/allenai_OLMo2-0325-32B-Instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q5_K_S",
        "size": "22GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "34GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 194
  },
  {
    "name": "MHKetbi/DeepScaleR-1.5B-Preview",
    "slug": "MHKetbi/DeepScaleR-1.5B-Preview",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.6GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MHKetbi/DeepSeek-R1-Distill-Llama-3.1-16.5B-Brainstorm",
    "slug": "MHKetbi/DeepSeek-R1-Distill-Llama-3.1-16.5B-Brainstorm",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "33GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q4_K_S",
        "size": "9.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q6_K",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "18GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MHKetbi/DeepSeek-R1-Distill-Llama-8B-NexaQuant",
    "slug": "MHKetbi/DeepSeek-R1-Distill-Llama-8B-NexaQuant",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "5.3GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MHKetbi/Mistral-Small3.1-24B-Instruct-2503",
    "slug": "MHKetbi/Mistral-Small3.1-24B-Instruct-2503",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "47GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q2_K_L",
        "size": "9.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q4_K_L",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q5_K_L",
        "size": "17GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q6_K_L",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q3_K_L",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "25GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MHKetbi/OpenThinker-32B",
    "slug": "MHKetbi/OpenThinker-32B",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "66GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "q4_K_S",
        "size": "19GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "q6_K",
        "size": "27GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "35GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MHKetbi/s1.1-32B",
    "slug": "MHKetbi/s1.1-32B",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "66GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "q4_K_S",
        "size": "19GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "q6_K",
        "size": "27GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "35GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MHKetbi/Unsloth-Phi-4-mini-instruct",
    "slug": "MHKetbi/Unsloth-Phi-4-mini-instruct",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "4.1GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "michaelneale/deepseek-r1-goose",
    "slug": "michaelneale/deepseek-r1-goose",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 5253
  },
  {
    "name": "michaelneale/qwen3-coder",
    "slug": "michaelneale/qwen3-coder",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "64k",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MichelRosselli/minimax-m2",
    "slug": "MichelRosselli/minimax-m2",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "138GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "q2_k",
        "size": "83GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "109GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "138GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "162GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "188GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "243GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "iq1_m",
        "size": "69GB",
        "context": "192K",
        "input": "Text"
      },
      {
        "name": "tq1_0",
        "size": "56GB",
        "context": "192K",
        "input": "Text"
      }
    ],
    "downloads": 299
  },
  {
    "name": "mikepfunk28/deepseekq3_agent",
    "slug": "mikepfunk28/deepseekq3_agent",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.2GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mikgr/doctype-classifier-vl",
    "slug": "mikgr/doctype-classifier-vl",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.2GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "v1.0",
        "size": "3.2GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "milkey/deepseek-v2.5-1210",
    "slug": "milkey/deepseek-v2.5-1210",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "IQ1_S",
        "size": "47GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "IQ1_M",
        "size": "53GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "IQ2_XXS",
        "size": "62GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "milkey/deepseek-v3-UD",
    "slug": "milkey/deepseek-v3-UD",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "IQ1_S",
        "size": "140GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "IQ1_M",
        "size": "155GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "IQ2_XXS",
        "size": "196GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 2033
  },
  {
    "name": "milkey/gte",
    "slug": "milkey/gte",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "base-zh-f16",
        "size": "204MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "large-zh-f16",
        "size": "650MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "milkey/Simplescaling-S1",
    "slug": "milkey/Simplescaling-S1",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32B-Q4_K_M",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32B-IQ2_S",
        "size": "10GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "minicpm-v",
    "slug": "minicpm-v",
    "description": "A series of multimodal LLMs (MLLMs) designed for vision-language understanding.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q2_K",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q3_K_S",
        "size": "4.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q3_K_M",
        "size": "4.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q3_K_L",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q4_0",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q4_1",
        "size": "5.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q4_K_S",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q4_K_M",
        "size": "5.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q5_0",
        "size": "6.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q5_1",
        "size": "6.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q5_K_S",
        "size": "6.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q5_K_M",
        "size": "6.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q6_K",
        "size": "7.3GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-q8_0",
        "size": "9.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-2.6-fp16",
        "size": "16GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 4400000
  },
  {
    "name": "minimax-m2",
    "slug": "minimax-m2",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "200K",
        "input": "Text"
      }
    ],
    "downloads": 32800
  },
  {
    "name": "minimax-m2.1",
    "slug": "minimax-m2.1",
    "description": "Exceptional multilingual capabilities to elevate code engineering",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "cloud",
        "size": "-",
        "context": "200K",
        "input": "Text"
      }
    ],
    "downloads": 3626
  },
  {
    "name": "ministral-3",
    "slug": "ministral-3",
    "description": "The Ministral 3 family is designed for edge deployment, capable of running on a wide range of hardware.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "3b",
        "size": "3.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "6.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b",
        "size": "9.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "3b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-2512-q4_K_M",
        "size": "3.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "3b-instruct-2512-q8_0",
        "size": "4.5GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "3b-instruct-2512-fp16",
        "size": "7.7GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-2512-q4_K_M",
        "size": "6.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-2512-q8_0",
        "size": "9.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-2512-fp16",
        "size": "18GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "14b-instruct-2512-q4_K_M",
        "size": "9.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b-instruct-2512-q8_0",
        "size": "15GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b-instruct-2512-fp16",
        "size": "28GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": 167000
  },
  {
    "name": "mirage335/Devstral-Small-2507-virtuoso",
    "slug": "mirage335/Devstral-Small-2507-virtuoso",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mirage335/Magistral-Small-2506-virtuoso",
    "slug": "mirage335/Magistral-Small-2506-virtuoso",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "9.4GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mirage335/Mistral-Small-3_2-24B-Instruct-2506-virtuoso",
    "slug": "mirage335/Mistral-Small-3_2-24B-Instruct-2506-virtuoso",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "9.4GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mirage335/Nemotron-3-Nano-30B-A3B-virtuoso",
    "slug": "mirage335/Nemotron-3-Nano-30B-A3B-virtuoso",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "18GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mirage335/Qwen3-Coder-30b-virtuoso",
    "slug": "mirage335/Qwen3-Coder-30b-virtuoso",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mistral-large",
    "slug": "mistral-large",
    "description": "Mistral Large 2 is Mistral's new flagship model that is significantly more capable in code generation, mathematics, and reasoning with 128k context window and support for dozens of languages.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "73GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b",
        "size": "73GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q2_K",
        "size": "45GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q3_K_S",
        "size": "53GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q3_K_M",
        "size": "59GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q3_K_L",
        "size": "65GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q4_0",
        "size": "69GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q4_1",
        "size": "77GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q4_K_S",
        "size": "70GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q4_K_M",
        "size": "73GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q5_0",
        "size": "84GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q5_1",
        "size": "92GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q5_K_S",
        "size": "84GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q5_K_M",
        "size": "86GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q6_K",
        "size": "101GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-q8_0",
        "size": "130GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2407-fp16",
        "size": "245GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q2_K",
        "size": "45GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q3_K_S",
        "size": "53GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q3_K_M",
        "size": "59GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q3_K_L",
        "size": "65GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q4_0",
        "size": "69GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q4_1",
        "size": "77GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q4_K_S",
        "size": "70GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q4_K_M",
        "size": "73GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q5_0",
        "size": "84GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q5_1",
        "size": "92GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q5_K_S",
        "size": "84GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q5_K_M",
        "size": "86GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q6_K",
        "size": "101GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-q8_0",
        "size": "130GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "123b-instruct-2411-fp16",
        "size": "245GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 346500
  },
  {
    "name": "mistral-large-3",
    "slug": "mistral-large-3",
    "description": "A general-purpose multimodal mixture-of-experts model for production-grade tasks and enterprise workloads.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "675b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 7083
  },
  {
    "name": "mistral-nemo",
    "slug": "mistral-nemo",
    "description": "A state-of-the-art 12B model with 128k context length, built by Mistral AI in collaboration with NVIDIA.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q2_K",
        "size": "4.8GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q3_K_S",
        "size": "5.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q3_K_M",
        "size": "6.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q3_K_L",
        "size": "6.6GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q4_0",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q4_1",
        "size": "7.8GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q4_K_S",
        "size": "7.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q4_K_M",
        "size": "7.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q5_0",
        "size": "8.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q5_1",
        "size": "9.2GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q5_K_S",
        "size": "8.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q5_K_M",
        "size": "8.7GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q6_K",
        "size": "10GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-q8_0",
        "size": "13GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b-instruct-2407-fp16",
        "size": "25GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 3100000
  },
  {
    "name": "mistral-small",
    "slug": "mistral-small",
    "description": "Mistral Small 3 sets a new benchmark in the small Large Language Models category below 70B.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "22b",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q2_K",
        "size": "8.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q3_K_S",
        "size": "9.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q3_K_M",
        "size": "11GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q3_K_L",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q4_0",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q4_1",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q4_K_S",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q4_K_M",
        "size": "13GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q5_0",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q5_1",
        "size": "17GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q5_K_S",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q5_K_M",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q6_K",
        "size": "18GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-q8_0",
        "size": "24GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "22b-instruct-2409-fp16",
        "size": "44GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501-q4_K_M",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501-q8_0",
        "size": "25GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "24b-instruct-2501-fp16",
        "size": "47GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 2200000
  },
  {
    "name": "mistral-small3.1",
    "slug": "mistral-small3.1",
    "description": "Building upon Mistral Small 3, Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-instruct-2503-q4_K_M",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-instruct-2503-q8_0",
        "size": "26GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-instruct-2503-fp16",
        "size": "48GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": 479900
  },
  {
    "name": "mistral-small3.2",
    "slug": "mistral-small3.2",
    "description": "An update to Mistral Small that improves on function calling, instruction following, and less repetition errors.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-instruct-2506-q4_K_M",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-instruct-2506-q8_0",
        "size": "26GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-instruct-2506-fp16",
        "size": "48GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": 1000000
  },
  {
    "name": "mistrallite",
    "slug": "mistrallite",
    "description": "MistralLite is a fine-tuned model based on Mistral with enhanced capabilities of processing long contexts.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q2_K",
        "size": "3.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q3_K_S",
        "size": "3.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q3_K_M",
        "size": "3.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q3_K_L",
        "size": "3.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_0",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_1",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_K_S",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_K_M",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_0",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_1",
        "size": "5.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_K_S",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_K_M",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q6_K",
        "size": "5.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q8_0",
        "size": "7.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-fp16",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 95000
  },
  {
    "name": "mitoza/Qwen3-Embedding-0.6B",
    "slug": "mitoza/Qwen3-Embedding-0.6B",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "639MB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mo7art/DeepSeek-V3-0324",
    "slug": "mo7art/DeepSeek-V3-0324",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "407GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 229
  },
  {
    "name": "mrasif/deepseek-coder",
    "slug": "mrasif/deepseek-coder",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "1.3b",
        "size": "776MB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "6.7b",
        "size": "3.8GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mrasif/functiongemma-270m-it-GGUF-F16",
    "slug": "mrasif/functiongemma-270m-it-GGUF-F16",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "543MB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MrScratchcat22/GLM-4.7-Flash-REAP-23B-A3B",
    "slug": "MrScratchcat22/GLM-4.7-Flash-REAP-23B-A3B",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MrScratchcat22/Magistral-Small-2509",
    "slug": "MrScratchcat22/Magistral-Small-2509",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "MrScratchcat22/Ministral-3-Reasoning",
    "slug": "MrScratchcat22/Ministral-3-Reasoning",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "3b",
        "size": "3.0GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b",
        "size": "9.1GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "muideen/mistral-small-3.1-q4",
    "slug": "muideen/mistral-small-3.1-q4",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "muratkazanc/llama3.2-1b-dlp",
    "slug": "muratkazanc/llama3.2-1b-dlp",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "808MB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mxbai-embed-large",
    "slug": "mxbai-embed-large",
    "description": "State-of-the-art large embedding model from mixedbread.ai",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "670MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "v1",
        "size": "670MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "335m",
        "size": "670MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "335m-v1-fp16",
        "size": "670MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": 6100000
  },
  {
    "name": "mychen76/deepcoder_cline_rootcode",
    "slug": "mychen76/deepcoder_cline_rootcode",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "14b",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mychen76/deepseek_r1_cline_roocode",
    "slug": "mychen76/deepseek_r1_cline_roocode",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "32b",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "mychen76/devstral-small_cline_roocode",
    "slug": "mychen76/devstral-small_cline_roocode",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "Q4",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "nchapman/dolphin3.0-llama3",
    "slug": "nchapman/dolphin3.0-llama3",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b",
        "size": "808MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 1141
  },
  {
    "name": "nchapman/dolphin3.0-qwen2.5",
    "slug": "nchapman/dolphin3.0-qwen2.5",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "0.5b",
        "size": "398MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1.5b",
        "size": "986MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "1.9GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 790
  },
  {
    "name": "nchapman/mistral-small-instruct-2409-abliterated",
    "slug": "nchapman/mistral-small-instruct-2409-abliterated",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "13GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "nchapman/mn-12b-mag-mell-r1",
    "slug": "nchapman/mn-12b-mag-mell-r1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "12b",
        "size": "7.5GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 2265
  },
  {
    "name": "ndanhbfkt/llama318b",
    "slug": "ndanhbfkt/llama318b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ndanhbfkt/llama321b",
    "slug": "ndanhbfkt/llama321b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.3GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "Nehc/Qwen3-Coder",
    "slug": "Nehc/Qwen3-Coder",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "290GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "480b",
        "size": "290GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "290GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "neilpontecorvo/deepseek-r1",
    "slug": "neilpontecorvo/deepseek-r1",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "nemotron",
    "slug": "nemotron",
    "description": "Llama-3.1-Nemotron-70B-Instruct is a large language model customized by NVIDIA to improve the helpfulness of LLM generated responses to user queries.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q2_K",
        "size": "26GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_S",
        "size": "31GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_M",
        "size": "34GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q3_K_L",
        "size": "37GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_0",
        "size": "40GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_1",
        "size": "44GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_K_S",
        "size": "40GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q4_K_M",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_0",
        "size": "49GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_1",
        "size": "53GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_K_S",
        "size": "49GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q5_K_M",
        "size": "50GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q6_K",
        "size": "58GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-q8_0",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-instruct-fp16",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 139400
  },
  {
    "name": "nemotron-3-nano",
    "slug": "nemotron-3-nano",
    "description": "Nemotron 3 Nano - A new Standard for Efficient, Open, and Intelligent Agentic Models",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "24GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "30b",
        "size": "24GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "30b-a3b-q4_K_M",
        "size": "24GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "30b-a3b-q8_0",
        "size": "34GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "30b-a3b-fp16",
        "size": "63GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "30b-cloud",
        "size": "-",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": 62600
  },
  {
    "name": "networkjohnny/deepseek-coder-v2-lite-base-q4_k_m-gguf",
    "slug": "networkjohnny/deepseek-coder-v2-lite-base-q4_k_m-gguf",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "NeuralNexusLab/StarGem",
    "slug": "NeuralNexusLab/StarGem",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "241MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "270m",
        "size": "241MB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "nlemberski/tinyllama-kubectl-8bit",
    "slug": "nlemberski/tinyllama-kubectl-8bit",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 56
  },
  {
    "name": "nomic-embed-text",
    "slug": "nomic-embed-text",
    "description": "A high-performing open embedding model with a large token context window.",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "274MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "v1.5",
        "size": "274MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "137m-v1.5-fp16",
        "size": "274MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 48900000
  },
  {
    "name": "nomic-embed-text-v2-moe",
    "slug": "nomic-embed-text-v2-moe",
    "description": "nomic-embed-text-v2-moe is a multilingual MoE text embedding model that excels at multilingual retrieval.",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "958MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": 14300
  },
  {
    "name": "novaforgeai/deepseek-coder",
    "slug": "novaforgeai/deepseek-coder",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "6.7b-optimized",
        "size": "3.8GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "novaforgeai/llama3.2",
    "slug": "novaforgeai/llama3.2",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "3b-optimized",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "novaforgeai/qwen2.5",
    "slug": "novaforgeai/qwen2.5",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "3b-optimized",
        "size": "1.9GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "novaforgeai/starcoder2",
    "slug": "novaforgeai/starcoder2",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "3b-optimized",
        "size": "1.7GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "nsheth/llava-llama-3-8b-v1_1-int4",
    "slug": "nsheth/llava-llama-3-8b-v1_1-int4",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.5GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "okamototk/gpt-oss-reasoning-high",
    "slug": "okamototk/gpt-oss-reasoning-high",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 122
  },
  {
    "name": "olmo-3",
    "slug": "olmo-3",
    "description": "Olmo is a series of Open language models designed to enable the science of language models. These models are pre-trained on the Dolma 3 dataset and post-trained on the Dolci datasets.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-instruct",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q4_K_M",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q8_0",
        "size": "7.8GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-fp16",
        "size": "15GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-think",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-think-q4_K_M",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-think-q8_0",
        "size": "7.8GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "7b-think-fp16",
        "size": "15GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-q4_K_M",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-q8_0",
        "size": "34GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-fp16",
        "size": "64GB",
        "context": "64K",
        "input": "Text"
      }
    ],
    "downloads": 30800
  },
  {
    "name": "olmo-3.1",
    "slug": "olmo-3.1",
    "description": "Olmo is a series of Open language models designed to enable the science of language models. These models are pre-trained on the Dolma 3 dataset and post-trained on the Dolci datasets.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-instruct",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-instruct-q4_K_M",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-instruct-q8_0",
        "size": "34GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-instruct-fp16",
        "size": "64GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-q4_K_M",
        "size": "19GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-q8_0",
        "size": "34GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "32b-think-fp16",
        "size": "64GB",
        "context": "64K",
        "input": "Text"
      }
    ],
    "downloads": 19200
  },
  {
    "name": "omercelik/mistral-small-coder",
    "slug": "omercelik/mistral-small-coder",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "omercelik/openhands-lm",
    "slug": "omercelik/openhands-lm",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 832
  },
  {
    "name": "omkarjava0103/gpt-oss-mini",
    "slug": "omkarjava0103/gpt-oss-mini",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "omkar",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 257
  },
  {
    "name": "Omoeba/devstral-small-2507-coder",
    "slug": "Omoeba/devstral-small-2507-coder",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "Omoeba/gpt-oss-coder",
    "slug": "Omoeba/gpt-oss-coder",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 971
  },
  {
    "name": "Omoeba/qwen3-coder-128k",
    "slug": "Omoeba/qwen3-coder-128k",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "30b",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "Omoeba/qwen3-coder-max",
    "slug": "Omoeba/qwen3-coder-max",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "30b",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ondersut/qwen3-match-q4km",
    "slug": "ondersut/qwen3-match-q4km",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.5GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "openbmb/minicpm-o2.6",
    "slug": "openbmb/minicpm-o2.6",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_0",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_1",
        "size": "5.9GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_K_S",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_K_M",
        "size": "5.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_0",
        "size": "6.4GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_1",
        "size": "6.8GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_K_S",
        "size": "6.4GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_K_M",
        "size": "6.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q6_K",
        "size": "7.3GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q8_0",
        "size": "9.1GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "f16",
        "size": "16GB",
        "context": "32K",
        "input": "Text, Image"
      }
    ],
    "downloads": 19800
  },
  {
    "name": "openbmb/minicpm-v2.5",
    "slug": "openbmb/minicpm-v2.5",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.8GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "5.8GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q4_0",
        "size": "5.8GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q4_1",
        "size": "6.2GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q4_K_S",
        "size": "5.8GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q4_K_M",
        "size": "6.0GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q5_0",
        "size": "6.7GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q5_1",
        "size": "7.2GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q5_K_S",
        "size": "6.7GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q5_K_M",
        "size": "6.8GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q6_K",
        "size": "7.7GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "q8_0",
        "size": "9.6GB",
        "context": "8K",
        "input": "Text, Image"
      },
      {
        "name": "f16",
        "size": "17GB",
        "context": "8K",
        "input": "Text, Image"
      }
    ],
    "downloads": 236
  },
  {
    "name": "openbmb/minicpm-v2.6",
    "slug": "openbmb/minicpm-v2.6",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_0",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_1",
        "size": "5.9GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_K_S",
        "size": "5.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_K_M",
        "size": "5.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_0",
        "size": "6.4GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_K_S",
        "size": "6.4GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_K_M",
        "size": "6.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q6_K",
        "size": "7.3GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q8_0",
        "size": "9.1GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "f16",
        "size": "16GB",
        "context": "32K",
        "input": "Text, Image"
      }
    ],
    "downloads": 1354
  },
  {
    "name": "openbmb/minicpm-v4",
    "slug": "openbmb/minicpm-v4",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.0GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "4b",
        "size": "3.0GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_0",
        "size": "3.0GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_1",
        "size": "3.3GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q4_K_S",
        "size": "3.1GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_0",
        "size": "3.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_1",
        "size": "3.7GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_K_S",
        "size": "3.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q5_K_M",
        "size": "3.5GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q6_K",
        "size": "3.9GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "q8_0",
        "size": "4.8GB",
        "context": "32K",
        "input": "Text, Image"
      },
      {
        "name": "f16",
        "size": "8.2GB",
        "context": "32K",
        "input": "Text, Image"
      }
    ],
    "downloads": 804
  },
  {
    "name": "openbmb/minicpm-v4.5",
    "slug": "openbmb/minicpm-v4.5",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.9GB",
        "context": "40K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "5.9GB",
        "context": "40K",
        "input": "Text, Image"
      },
      {
        "name": "q4_0",
        "size": "5.9GB",
        "context": "40K",
        "input": "Text, Image"
      },
      {
        "name": "q4_1",
        "size": "6.3GB",
        "context": "40K",
        "input": "Text, Image"
      },
      {
        "name": "q4_K_S",
        "size": "5.9GB",
        "context": "40K",
        "input": "Text, Image"
      },
      {
        "name": "q4_K_M",
        "size": "6.1GB",
        "context": "40K",
        "input": "Text, Image"
      },
      {
        "name": "q5_0",
        "size": "6.8GB",
        "context": "40K",
        "input": "Text, Image"
      },
      {
        "name": "q5_1",
        "size": "7.3GB",
        "context": "40K",
        "input": "Text, Image"
      },
      {
        "name": "q5_K_M",
        "size": "6.9GB",
        "context": "40K",
        "input": "Text, Image"
      },
      {
        "name": "q6_K",
        "size": "7.8GB",
        "context": "40K",
        "input": "Text, Image"
      },
      {
        "name": "q8_0",
        "size": "9.8GB",
        "context": "40K",
        "input": "Text, Image"
      }
    ],
    "downloads": 8711
  },
  {
    "name": "openchat",
    "slug": "openchat",
    "description": "A family of open-source models trained on a wide variety of data, surpassing ChatGPT on various benchmarks. Updated to version 3.5-0106.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q2_K",
        "size": "3.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q2_K",
        "size": "3.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q3_K_S",
        "size": "3.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q3_K_S",
        "size": "3.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q3_K_M",
        "size": "3.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q3_K_M",
        "size": "3.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q3_K_L",
        "size": "3.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q3_K_L",
        "size": "3.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q4_0",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q4_0",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q4_1",
        "size": "4.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q4_1",
        "size": "4.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q4_K_S",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q4_K_S",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q4_K_M",
        "size": "4.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q4_K_M",
        "size": "4.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q5_0",
        "size": "5.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q5_0",
        "size": "5.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q5_1",
        "size": "5.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q5_1",
        "size": "5.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q5_K_S",
        "size": "5.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q5_K_M",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q6_K",
        "size": "5.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-q8_0",
        "size": "7.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-0106-fp16",
        "size": "14GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q2_K",
        "size": "3.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q3_K_S",
        "size": "3.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q3_K_M",
        "size": "3.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q3_K_L",
        "size": "3.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q4_0",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q4_1",
        "size": "4.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q4_K_S",
        "size": "4.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q4_K_M",
        "size": "4.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q5_0",
        "size": "5.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q5_1",
        "size": "5.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q5_K_S",
        "size": "5.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q5_K_S",
        "size": "5.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q5_K_M",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q5_K_M",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q6_K",
        "size": "5.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q6_K",
        "size": "5.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-q8_0",
        "size": "7.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-q8_0",
        "size": "7.7GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-1210-fp16",
        "size": "14GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "7b-v3.5-fp16",
        "size": "14GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "openthinker",
    "slug": "openthinker",
    "description": "A fully open-source family of reasoning models built using a dataset derived by distilling DeepSeek-R1.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q4_K_M",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q8_0",
        "size": "8.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v2-fp16",
        "size": "15GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0",
        "size": "8.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-fp16",
        "size": "15GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-v2-q4_K_M",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-v2-q8_0",
        "size": "35GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-v2-fp16",
        "size": "66GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0",
        "size": "35GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-fp16",
        "size": "66GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 658000
  },
  {
    "name": "orca-mini",
    "slug": "orca-mini",
    "description": "A general-purpose model ranging from 3 billion parameters to 70 billion, suitable for entry-level hardware.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "2.0GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "39GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q4_0",
        "size": "2.0GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "3b-q4_1",
        "size": "2.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "3b-q5_0",
        "size": "2.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "3b-q5_1",
        "size": "2.6GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "3b-q8_0",
        "size": "3.6GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "3b-fp16",
        "size": "6.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q2_K",
        "size": "2.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q3_K_S",
        "size": "2.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q3_K_M",
        "size": "3.3GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q3_K_L",
        "size": "3.6GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q4_0",
        "size": "3.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q4_1",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q4_K_S",
        "size": "3.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q4_K_M",
        "size": "4.1GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q5_0",
        "size": "4.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q5_1",
        "size": "5.1GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q5_K_S",
        "size": "4.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q5_K_M",
        "size": "4.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q6_K",
        "size": "5.5GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-q8_0",
        "size": "7.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v2-fp16",
        "size": "13GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-v3",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q2_K",
        "size": "2.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q3_K_S",
        "size": "2.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q3_K_M",
        "size": "3.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q3_K_L",
        "size": "3.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q4_0",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q4_1",
        "size": "4.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q4_K_S",
        "size": "3.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q4_K_M",
        "size": "4.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q5_0",
        "size": "4.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q5_1",
        "size": "5.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q5_K_S",
        "size": "4.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q5_K_M",
        "size": "4.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q6_K",
        "size": "5.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-q8_0",
        "size": "7.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v3-fp16",
        "size": "13GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-q2_K",
        "size": "2.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q3_K_S",
        "size": "2.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q3_K_M",
        "size": "3.3GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q3_K_L",
        "size": "3.6GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q4_0",
        "size": "3.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q4_1",
        "size": "4.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_S",
        "size": "3.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M",
        "size": "4.1GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q5_0",
        "size": "4.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q5_1",
        "size": "5.1GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q5_K_S",
        "size": "4.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q5_K_M",
        "size": "4.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q6_K",
        "size": "5.5GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0",
        "size": "7.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "7b-fp16",
        "size": "13GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q2_K",
        "size": "5.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q3_K_S",
        "size": "5.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q3_K_M",
        "size": "6.3GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q3_K_L",
        "size": "6.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q4_0",
        "size": "7.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q4_1",
        "size": "8.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q4_K_S",
        "size": "7.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q4_K_M",
        "size": "7.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q5_0",
        "size": "9.0GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q5_1",
        "size": "9.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q5_K_S",
        "size": "9.0GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q5_K_M",
        "size": "9.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q6_K",
        "size": "11GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-q8_0",
        "size": "14GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v2-fp16",
        "size": "26GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-v3",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q2_K",
        "size": "5.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q3_K_S",
        "size": "5.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q3_K_M",
        "size": "6.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q3_K_L",
        "size": "6.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q4_0",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q4_1",
        "size": "8.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q4_K_S",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q4_K_M",
        "size": "7.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q5_0",
        "size": "9.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q5_1",
        "size": "9.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q5_K_S",
        "size": "9.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q5_K_M",
        "size": "9.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q6_K",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-q8_0",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v3-fp16",
        "size": "26GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-q2_K",
        "size": "5.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q3_K_S",
        "size": "5.7GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q3_K_M",
        "size": "6.3GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q3_K_L",
        "size": "6.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q4_0",
        "size": "7.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q4_1",
        "size": "8.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q4_K_S",
        "size": "7.4GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q4_K_M",
        "size": "7.9GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q5_0",
        "size": "9.0GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q5_1",
        "size": "9.8GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q5_K_S",
        "size": "9.0GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q5_K_M",
        "size": "9.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q6_K",
        "size": "11GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-q8_0",
        "size": "14GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "13b-fp16",
        "size": "26GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "70b-v3",
        "size": "39GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q2_K",
        "size": "29GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q3_K_S",
        "size": "30GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q3_K_M",
        "size": "33GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q3_K_L",
        "size": "36GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q4_0",
        "size": "39GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q4_1",
        "size": "43GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q4_K_S",
        "size": "39GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q4_K_M",
        "size": "41GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q5_0",
        "size": "47GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q5_1",
        "size": "52GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q5_K_S",
        "size": "47GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q5_K_M",
        "size": "49GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q6_K",
        "size": "57GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-q8_0",
        "size": "73GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v3-fp16",
        "size": "138GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "org/deepseek-v3-fast",
    "slug": "org/deepseek-v3-fast",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "244GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "Q2_K_L",
        "size": "244GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "Q2_K_XS",
        "size": "221GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "404GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 90
  },
  {
    "name": "oscar_while/Magistral-Small-2509-32K-GPU",
    "slug": "oscar_while/Magistral-Small-2509-32K-GPU",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "16GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "oscar_while/Magistral-Small-2509-F16-mmproj",
    "slug": "oscar_while/Magistral-Small-2509-F16-mmproj",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "oscar_while/Magistral-Small-2509-F32-mmproj",
    "slug": "oscar_while/Magistral-Small-2509-F32-mmproj",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "16GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "oscar_while/Magistral-Small-2509-hybrid-32K-GPU",
    "slug": "oscar_while/Magistral-Small-2509-hybrid-32K-GPU",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "Q4_K_M",
        "size": "16GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "oscar_while/qwen2.5vl_tools",
    "slug": "oscar_while/qwen2.5vl_tools",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "7b-q8_0",
        "size": "9.4GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b-q4_K_M",
        "size": "21GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "OussamaELALLAM/AtlasMed-R1",
    "slug": "OussamaELALLAM/AtlasMed-R1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "pacozaa/tinyllama-alpaca-lora",
    "slug": "pacozaa/tinyllama-alpaca-lora",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "739MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 306
  },
  {
    "name": "parthsareen/qwen3-coder-tools",
    "slug": "parthsareen/qwen3-coder-tools",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "path-gossip-skirt/DeepScaleR-1.5B-Q4KM0217",
    "slug": "path-gossip-skirt/DeepScaleR-1.5B-Q4KM0217",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "pdevine/deepseek-v3.1",
    "slug": "pdevine/deepseek-v3.1",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "671b-cloud",
        "size": "-",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "671b-turbo",
        "size": "242B",
        "context": "-",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "pedrovillalobos/mxbai-embed-large-no-gpu",
    "slug": "pedrovillalobos/mxbai-embed-large-no-gpu",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "670MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": 166
  },
  {
    "name": "pedrovillalobos/nomic-embed-text-no-gpu",
    "slug": "pedrovillalobos/nomic-embed-text-no-gpu",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "274MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 20
  },
  {
    "name": "phuzzy/minecraft",
    "slug": "phuzzy/minecraft",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 427
  },
  {
    "name": "PhysicsObsession/blaze",
    "slug": "PhysicsObsession/blaze",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.3GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "PolyoxyDev/granite4-macos-micro",
    "slug": "PolyoxyDev/granite4-macos-micro",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "PolyoxyDev/granite4-obsidian-tiny-h",
    "slug": "PolyoxyDev/granite4-obsidian-tiny-h",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.2GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "rhel10",
        "size": "4.2GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "PolyoxyDev/granite4-rhel-tiny-h",
    "slug": "PolyoxyDev/granite4-rhel-tiny-h",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.2GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "psychopenguin0001/ServiceNow-AI_Apriel-1.6-15b-Thinker-IQ3_M",
    "slug": "psychopenguin0001/ServiceNow-AI_Apriel-1.6-15b-Thinker-IQ3_M",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "6.7GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "qooba/qwen3-coder-30b-a3b-instruct",
    "slug": "qooba/qwen3-coder-30b-a3b-instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q3_k_m",
        "size": "15GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "qwen2.5vl",
    "slug": "qwen2.5vl",
    "description": "Flagship vision-language model of Qwen and also a significant leap from the previous Qwen2-VL.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.0GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "3b",
        "size": "3.2GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "7b",
        "size": "6.0GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b",
        "size": "21GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "72b",
        "size": "49GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "3b-q4_K_M",
        "size": "3.2GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "3b-q8_0",
        "size": "4.6GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "3b-fp16",
        "size": "7.5GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "7b-q4_K_M",
        "size": "6.0GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "7b-q8_0",
        "size": "9.4GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "7b-fp16",
        "size": "17GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b-q4_K_M",
        "size": "21GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b-q8_0",
        "size": "36GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b-fp16",
        "size": "67GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "72b-q4_K_M",
        "size": "49GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "72b-q8_0",
        "size": "79GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "72b-fp16",
        "size": "147GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": 1100000
  },
  {
    "name": "qwen3",
    "slug": "qwen3",
    "description": "Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.2GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "0.6b",
        "size": "523MB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "1.7b",
        "size": "1.4GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "4b",
        "size": "2.5GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "5.2GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "14b",
        "size": "9.3GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "30b",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "20GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "235b",
        "size": "142GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "0.6b-q4_K_M",
        "size": "523MB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "0.6b-q8_0",
        "size": "832MB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "0.6b-fp16",
        "size": "1.5GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "1.7b-q4_K_M",
        "size": "1.4GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "1.7b-q8_0",
        "size": "2.2GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "1.7b-fp16",
        "size": "4.1GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "4b-instruct",
        "size": "2.5GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-instruct-2507-q4_K_M",
        "size": "2.5GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-instruct-2507-q8_0",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-instruct-2507-fp16",
        "size": "8.1GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-thinking",
        "size": "2.5GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-thinking-2507-q4_K_M",
        "size": "2.5GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-thinking-2507-q8_0",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-thinking-2507-fp16",
        "size": "8.1GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b-q4_K_M",
        "size": "2.6GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "4b-q8_0",
        "size": "4.4GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "4b-fp16",
        "size": "8.1GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M",
        "size": "5.2GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0",
        "size": "8.9GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-fp16",
        "size": "16GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M",
        "size": "9.3GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0",
        "size": "16GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "14b-fp16",
        "size": "30GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "30b-a3b",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-instruct-2507-q4_K_M",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-q4_K_M",
        "size": "19GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-instruct-2507-q8_0",
        "size": "32GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-thinking-2507-q4_K_M",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-q8_0",
        "size": "33GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-thinking-2507-q8_0",
        "size": "32GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-fp16",
        "size": "61GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-instruct-2507-fp16",
        "size": "61GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-thinking-2507-fp16",
        "size": "61GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-instruct",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-thinking",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M",
        "size": "20GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0",
        "size": "35GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "32b-fp16",
        "size": "66GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "235b-a22b",
        "size": "142GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "235b-a22b-instruct-2507-q4_K_M",
        "size": "142GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "235b-a22b-q4_K_M",
        "size": "142GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "235b-a22b-instruct-2507-q8_0",
        "size": "250GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "235b-a22b-thinking-2507-q4_K_M",
        "size": "142GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "235b-a22b-q8_0",
        "size": "250GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "235b-a22b-thinking-2507-q8_0",
        "size": "250GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "235b-a22b-fp16",
        "size": "470GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "235b-a22b-thinking-2507-fp16",
        "size": "470GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "235b-instruct",
        "size": "142GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "235b-thinking",
        "size": "142GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 16300000
  },
  {
    "name": "qwen3-coder",
    "slug": "qwen3-coder",
    "description": "Alibaba's performant long context models for agentic and coding tasks.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "480b",
        "size": "290GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-q4_K_M",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-q8_0",
        "size": "32GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "30b-a3b-fp16",
        "size": "61GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "480b-a35b-q4_K_M",
        "size": "290GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "480b-a35b-q8_0",
        "size": "510GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "480b-a35b-fp16",
        "size": "960GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "480b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 1700000
  },
  {
    "name": "qwen3-embedding",
    "slug": "qwen3-embedding",
    "description": "Building upon the foundational models of the Qwen3 series, Qwen3 Embedding provides a comprehensive range of text embeddings models in various sizes",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "0.6b",
        "size": "639MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "4b",
        "size": "2.5GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.7GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "0.6b-q8_0",
        "size": "639MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "0.6b-fp16",
        "size": "1.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "4b-q4_K_M",
        "size": "2.5GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "4b-q8_0",
        "size": "4.3GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "4b-fp16",
        "size": "8.0GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M",
        "size": "4.7GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0",
        "size": "8.0GB",
        "context": "40K",
        "input": "Text"
      },
      {
        "name": "8b-fp16",
        "size": "15GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": 226800
  },
  {
    "name": "qwen3-next",
    "slug": "qwen3-next",
    "description": "The first installment in the Qwen3-Next series with strong performance in terms of both parameter efficiency and inference speed.",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-instruct-q4_K_M",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-instruct-q8_0",
        "size": "85GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-instruct-fp16",
        "size": "159GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking-q4_K_M",
        "size": "50GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking-q8_0",
        "size": "85GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-a3b-thinking-fp16",
        "size": "159GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "80b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 225300
  },
  {
    "name": "qwen3-vl",
    "slug": "qwen3-vl",
    "description": "The most powerful vision-language model in the Qwen model family to date.",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct-q4_K_M",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct-q8_0",
        "size": "2.6GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-instruct-bf16",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking-q4_K_M",
        "size": "1.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking-q8_0",
        "size": "2.6GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "2b-thinking-bf16",
        "size": "4.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct-q4_K_M",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct-q8_0",
        "size": "5.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-instruct-bf16",
        "size": "8.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking-q4_K_M",
        "size": "3.3GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking-q8_0",
        "size": "5.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "4b-thinking-bf16",
        "size": "8.9GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-q4_K_M",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-q8_0",
        "size": "9.8GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-instruct-bf16",
        "size": "18GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking-q4_K_M",
        "size": "6.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking-q8_0",
        "size": "9.8GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "8b-thinking-bf16",
        "size": "18GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct-q4_K_M",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct-q8_0",
        "size": "34GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-instruct-bf16",
        "size": "62GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-thinking",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-thinking-q4_K_M",
        "size": "20GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-thinking-q8_0",
        "size": "34GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "30b-a3b-thinking-bf16",
        "size": "62GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-q4_K_M",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-q8_0",
        "size": "36GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-instruct-bf16",
        "size": "67GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking-q4_K_M",
        "size": "21GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking-q8_0",
        "size": "36GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "32b-thinking-bf16",
        "size": "67GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-instruct",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-instruct-q4_K_M",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-instruct-q8_0",
        "size": "251GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-instruct-bf16",
        "size": "471GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-thinking",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-thinking-q4_K_M",
        "size": "143GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-thinking-q8_0",
        "size": "251GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-a22b-thinking-bf16",
        "size": "471GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "235b-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "235b-instruct-cloud",
        "size": "-",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 907300
  },
  {
    "name": "r1-1776",
    "slug": "r1-1776",
    "description": "A version of the DeepSeek-R1 model that has been post trained to provide unbiased, accurate, and factual information by Perplexity.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "671b",
        "size": "404GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-distill-llama-q4_K_M",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-distill-llama-q8_0",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-distill-llama-fp16",
        "size": "141GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "671b-q4_K_M",
        "size": "404GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b-q8_0",
        "size": "713GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "671b-fp16",
        "size": "1.3TB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 170700
  },
  {
    "name": "rahman_786/llama3.1-cypher-query",
    "slug": "rahman_786/llama3.1-cypher-query",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "8b",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "razvanab/dolphin-llama3-rude",
    "slug": "razvanab/dolphin-llama3-rude",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "rcpsy2022/deepseek-coder-v2",
    "slug": "rcpsy2022/deepseek-coder-v2",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "reanima_08/deepseek-coder",
    "slug": "reanima_08/deepseek-coder",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "redule26/huihui_ai_qwen2.5-vl-7b-abliterated",
    "slug": "redule26/huihui_ai_qwen2.5-vl-7b-abliterated",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.0GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": 8105
  },
  {
    "name": "rhundt/qwen3-64k",
    "slug": "rhundt/qwen3-64k",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "30b",
        "size": "19GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "richardyoung/deepseek-coder-33b-heretic",
    "slug": "richardyoung/deepseek-coder-33b-heretic",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "67GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "richardyoung/deepseek-r1-32b-uncensored",
    "slug": "richardyoung/deepseek-r1-32b-uncensored",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "richardyoung/dolphin-yi-34b-heretic",
    "slug": "richardyoung/dolphin-yi-34b-heretic",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "61GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "richardyoung/olmo-3-7b-rlzero-math",
    "slug": "richardyoung/olmo-3-7b-rlzero-math",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "iq3_m",
        "size": "3.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "5.2GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "7.8GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "iq4_xs",
        "size": "4.0GB",
        "context": "64K",
        "input": "Text"
      },
      {
        "name": "f16",
        "size": "15GB",
        "context": "64K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "richardyoung/smolvlm2-2.2b-instruct",
    "slug": "richardyoung/smolvlm2-2.2b-instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "1.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "1.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "1.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "1.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "iq4_xs",
        "size": "1.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "f16",
        "size": "3.6GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "Rishabhpb26/ChatPro-2-mini",
    "slug": "Rishabhpb26/ChatPro-2-mini",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "813MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 25
  },
  {
    "name": "rjmalagon/dolphin-2.9.4-llama3.1-8b",
    "slug": "rjmalagon/dolphin-2.9.4-llama3.1-8b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q8_0",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "f16",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "rjmalagon/dolphin3-r1-mistral",
    "slug": "rjmalagon/dolphin3-r1-mistral",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "24b-bf16",
        "size": "47GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 47
  },
  {
    "name": "rjmalagon/dolphin3.0-mistral",
    "slug": "rjmalagon/dolphin3.0-mistral",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "24b-bf16",
        "size": "47GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 63
  },
  {
    "name": "rjmalagon/dolphin3.0-qwen2.5-3b",
    "slug": "rjmalagon/dolphin3.0-qwen2.5-3b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "bf16",
        "size": "6.2GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 99
  },
  {
    "name": "rjmalagon/med-qwen3-vl",
    "slug": "rjmalagon/med-qwen3-vl",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "8b-instruct-fp16",
        "size": "18GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "rnj-1",
    "slug": "rnj-1",
    "description": "Rnj-1 is a family of 8B parameter open-weight, dense models trained from scratch by Essential AI, optimized for code and STEM with capabilities on par with SOTA open-weight models.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-cloud",
        "size": "-",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q4_K_M",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-q8_0",
        "size": "8.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-instruct-fp16",
        "size": "17GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 20500
  },
  {
    "name": "rnogy/Nvidia_Llama-3_3-Nemotron-Super-49B-v1_5",
    "slug": "rnogy/Nvidia_Llama-3_3-Nemotron-Super-49B-v1_5",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "100GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q3_K_M",
        "size": "24GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q4_K_M",
        "size": "30GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "53GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "RobiLabs/lexa-rho",
    "slug": "RobiLabs/lexa-rho",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "8b",
        "size": "5.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "RobinBially/bge-m3-8k",
    "slug": "RobinBially/bge-m3-8k",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "635MB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 11
  },
  {
    "name": "RobinBially/nomic-embed-text-8k",
    "slug": "RobinBially/nomic-embed-text-8k",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "274MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 1134
  },
  {
    "name": "romko391/granite4.0-tiny-preview",
    "slug": "romko391/granite4.0-tiny-preview",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.9GB",
        "context": "1M",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "rosemarla/devstral-abliterated-vision",
    "slug": "rosemarla/devstral-abliterated-vision",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "rushikesh_67/llama3.3-70b-fenics-q4",
    "slug": "rushikesh_67/llama3.3-70b-fenics-q4",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "rushikesh_67/llama3.3-fenics-3new",
    "slug": "rushikesh_67/llama3.3-fenics-3new",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "rushikesh_67/llama3.3-fenics-70b-q8",
    "slug": "rushikesh_67/llama3.3-fenics-70b-q8",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "Ryan512FL/llama3.3-GHAI-abliterated",
    "slug": "Ryan512FL/llama3.3-GHAI-abliterated",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "16B",
        "size": "18GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ2_XXS",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "IQ2_XS",
        "size": "21GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 555
  },
  {
    "name": "ryanshillington/Qwen3-Embedding-0.6B",
    "slug": "ryanshillington/Qwen3-Embedding-0.6B",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ryanshillington/Qwen3-Embedding-4B",
    "slug": "ryanshillington/Qwen3-Embedding-4B",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "8.0GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ryanshillington/Qwen3-Embedding-8B",
    "slug": "ryanshillington/Qwen3-Embedding-8B",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "15GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sadiq-bd/llama3.2-1b-uncensored",
    "slug": "sadiq-bd/llama3.2-1b-uncensored",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "955MB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 1041
  },
  {
    "name": "sadiq-bd/llama3.2-3b-uncensored",
    "slug": "sadiq-bd/llama3.2-3b-uncensored",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.2GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 1080
  },
  {
    "name": "saicharan1010/SmolLM2-FT-legal-india",
    "slug": "saicharan1010/SmolLM2-FT-legal-india",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "271MB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sailor2",
    "slug": "sailor2",
    "description": "Sailor2 are multilingual language models made for South-East Asia. Available in 1B, 8B, and 20B parameter sizes.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "5.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b",
        "size": "1.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "5.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "20b",
        "size": "12GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-chat-q4_K_M",
        "size": "739MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-chat-q8_0",
        "size": "1.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-chat-fp16",
        "size": "2.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-chat-q4_K_M",
        "size": "5.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-chat-q8_0",
        "size": "9.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "8b-chat-fp16",
        "size": "17GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "20b-chat-q4_K_M",
        "size": "12GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "20b-chat-q8_0",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "20b-chat-fp16",
        "size": "38GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 78200
  },
  {
    "name": "sam860/dolphin3-llama3.2",
    "slug": "sam860/dolphin3-llama3.2",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "1b",
        "size": "1.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-Q5_K_M",
        "size": "932MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-Q8_0",
        "size": "1.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-F16",
        "size": "2.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-Q4_K_M",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-Q5_K_M",
        "size": "2.4GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-Q8_0",
        "size": "3.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-F16",
        "size": "6.4GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 975
  },
  {
    "name": "sam860/dolphin3-qwen2.5",
    "slug": "sam860/dolphin3-qwen2.5",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "1.5b",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "1.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1.5b-Q4_K_M",
        "size": "986MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-Q5_K_M",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-Q8_0",
        "size": "1.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b-Q4_0",
        "size": "1.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-Q4_K_M",
        "size": "1.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-Q5_K_M",
        "size": "2.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-Q8_0",
        "size": "3.3GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 1130
  },
  {
    "name": "sam860/falcon-h1",
    "slug": "sam860/falcon-h1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "1.5b",
        "size": "1.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-deep-Q4_0",
        "size": "904MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-deep-Q8_0",
        "size": "1.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-Q4_0",
        "size": "916MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-Q8_0",
        "size": "1.7GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sam860/granite-4.0",
    "slug": "sam860/granite-4.0",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "micro",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "350m",
        "size": "366MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "1b",
        "size": "1.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "3.2b",
        "size": "1.9GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "3.4b",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.0GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "350m-Q8_0",
        "size": "378MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "1b-Q4_0",
        "size": "978MB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1b-Q8_0",
        "size": "1.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "h-1b-Q4_0",
        "size": "870MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "h-1b-Q8_0",
        "size": "1.6GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "h-350m-Q8_0",
        "size": "366MB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "h-micro",
        "size": "1.9GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "h-micro-Q4_0",
        "size": "1.9GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "h-tiny",
        "size": "4.0GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "h-tiny-Q4_0",
        "size": "4.0GB",
        "context": "1M",
        "input": "Text"
      },
      {
        "name": "micro-Q4_0",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sam860/granite-embedding-english",
    "slug": "sam860/granite-embedding-english",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "30m-Q8_0",
        "size": "34MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "30m-F16",
        "size": "63MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "125m-Q8_0",
        "size": "135MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "125m-F16",
        "size": "251MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sam860/granite-embedding-multilingual",
    "slug": "sam860/granite-embedding-multilingual",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "107m-Q8_0",
        "size": "121MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "107m-F16",
        "size": "221MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "278m-Q8_0",
        "size": "303MB",
        "context": "512",
        "input": "Text"
      },
      {
        "name": "278m-F16",
        "size": "563MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "samantha-mistral",
    "slug": "samantha-mistral",
    "description": "A companion assistant trained in philosophy, psychology, and personal relationships. Based on Mistral.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q2_K",
        "size": "3.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q3_K_S",
        "size": "3.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q3_K_M",
        "size": "3.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q3_K_L",
        "size": "3.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q4_0",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q4_1",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q4_K_S",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q4_K_M",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q5_0",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q5_1",
        "size": "5.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q5_K_S",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q5_K_M",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q6_K",
        "size": "5.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-q8_0",
        "size": "7.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-instruct-fp16",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q2_K",
        "size": "3.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q3_K_S",
        "size": "3.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q3_K_M",
        "size": "3.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q3_K_L",
        "size": "3.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q4_0",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q4_1",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q4_K_S",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q4_K_M",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q5_0",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q5_1",
        "size": "5.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q5_K_S",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q5_K_M",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q6_K",
        "size": "5.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-q8_0",
        "size": "7.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-text-fp16",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q2_K",
        "size": "3.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q3_K_S",
        "size": "3.2GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q3_K_M",
        "size": "3.5GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q3_K_L",
        "size": "3.8GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q4_0",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q4_1",
        "size": "4.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q4_K_S",
        "size": "4.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q4_K_M",
        "size": "4.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q5_0",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q5_1",
        "size": "5.4GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q5_K_S",
        "size": "5.0GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q5_K_M",
        "size": "5.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q6_K",
        "size": "5.9GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-q8_0",
        "size": "7.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-v1.2-text-fp16",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 184300
  },
  {
    "name": "sammcj/deepseek-r1-distilled-llama-70b",
    "slug": "sammcj/deepseek-r1-distilled-llama-70b",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "q5_k_m",
        "size": "50GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sammcj/devstral-small-24b-2505-ud",
    "slug": "sammcj/devstral-small-24b-2505-ud",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "64k-q6_k_xl",
        "size": "21GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "128k-q6_k_xl",
        "size": "21GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "cline-128k-q6_k_xl",
        "size": "21GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "cline-64k-q4_k_xl",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "cline-64k-q6_k_xl",
        "size": "21GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sammcj/glm-4-32b-0414",
    "slug": "sammcj/glm-4-32b-0414",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "q6_k",
        "size": "27GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sammcj/mxbai-embed-large-v1",
    "slug": "sammcj/mxbai-embed-large-v1",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "q8_0",
        "size": "358MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": 67
  },
  {
    "name": "scb10x/llama3.1-typhoon2-8b-instruct",
    "slug": "scb10x/llama3.1-typhoon2-8b-instruct",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "scb10x/llama3.2-typhoon2-3b-instruct",
    "slug": "scb10x/llama3.2-typhoon2-3b-instruct",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "schroneko/mistral-nemo-minitron-8b-instruct",
    "slug": "schroneko/mistral-nemo-minitron-8b-instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q3_k_s",
        "size": "3.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q3_k_m",
        "size": "4.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q3_k_l",
        "size": "4.5GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_0",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_1",
        "size": "5.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_k_s",
        "size": "4.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q4_k_m",
        "size": "5.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_0",
        "size": "5.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_1",
        "size": "6.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_k_s",
        "size": "5.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q5_k_m",
        "size": "6.0GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "6.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "8.9GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 842
  },
  {
    "name": "scomper/minicpm-v2.5",
    "slug": "scomper/minicpm-v2.5",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.5GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 4985
  },
  {
    "name": "seamon67/Devstral1.1-2507",
    "slug": "seamon67/Devstral1.1-2507",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "24b-q4_K_M",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-q8_0",
        "size": "26GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-f16",
        "size": "48GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "seamon67/Devstral1.1-Fused",
    "slug": "seamon67/Devstral1.1-Fused",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "36b-q4_K_M",
        "size": "23GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "36b-q8_0",
        "size": "40GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "seamon67/Devstral2-Small",
    "slug": "seamon67/Devstral2-Small",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "24b",
        "size": "15GB",
        "context": "384K",
        "input": "Text, Image"
      },
      {
        "name": "24b-q4_K_M",
        "size": "15GB",
        "context": "384K",
        "input": "Text, Image"
      },
      {
        "name": "24b-q8_0",
        "size": "26GB",
        "context": "384K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "seamon67/Gemma3",
    "slug": "seamon67/Gemma3",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "27b",
        "size": "17GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-it-qat",
        "size": "18GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-q4_K_M",
        "size": "17GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-q8_0",
        "size": "30GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "seamon67/Gemma3-Abliterated",
    "slug": "seamon67/Gemma3-Abliterated",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "4b-q4_K_M",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-q8_0",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-f16",
        "size": "8.6GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-q4_K_M",
        "size": "17GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-q8_0",
        "size": "30GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-f16",
        "size": "55GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "seamon67/Gemma3-Tiger",
    "slug": "seamon67/Gemma3-Tiger",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "27b",
        "size": "18GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-q4_K_M",
        "size": "18GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-q8_0",
        "size": "32GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "seamon67/Magistral1.2-2509",
    "slug": "seamon67/Magistral1.2-2509",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "24b",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-q4_K_M",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-q8_0",
        "size": "26GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-f16",
        "size": "48GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "seamon67/Ministral-3-Reasoning",
    "slug": "seamon67/Ministral-3-Reasoning",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "14b",
        "size": "9.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b-q4_K_M",
        "size": "9.1GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b-q8_0",
        "size": "15GB",
        "context": "256K",
        "input": "Text, Image"
      },
      {
        "name": "14b-f16",
        "size": "28GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "seamon67/Qwen2.5VL-Abliterated",
    "slug": "seamon67/Qwen2.5VL-Abliterated",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "32b-q4_K_M",
        "size": "21GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b-q8_0",
        "size": "36GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b-f16",
        "size": "67GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "secfa/DeepSeek-R1-UD-IQ1_S",
    "slug": "secfa/DeepSeek-R1-UD-IQ1_S",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "140GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "24g",
        "size": "140GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 170900
  },
  {
    "name": "second_constantine/deepseek-coder-v2",
    "slug": "second_constantine/deepseek-coder-v2",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "16b",
        "size": "8.6GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "16b-Q4_K_M",
        "size": "10GB",
        "context": "160K",
        "input": "Text"
      },
      {
        "name": "16b-IQ4_XS",
        "size": "8.6GB",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "second_constantine/gpt-oss-u",
    "slug": "second_constantine/gpt-oss-u",
    "description": "",
    "features": [
      "thinking"
    ],
    "tags": [
      {
        "name": "20b",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 26300
  },
  {
    "name": "second_constantine/magistral-small",
    "slug": "second_constantine/magistral-small",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "24b",
        "size": "18GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "second_constantine/mistral-small-3.2",
    "slug": "second_constantine/mistral-small-3.2",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "24b",
        "size": "18GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-UD-Q4_K_XL",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "24b-UD-Q5_K_XL",
        "size": "18GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "sileader/qwen3-14b-unsloth",
    "slug": "sileader/qwen3-14b-unsloth",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "IQ2_M",
        "size": "5.4GB",
        "context": "40K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "SimonPu/Devstral-Small",
    "slug": "SimonPu/Devstral-Small",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "2507-Q4_K_XL",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "SimonPu/Mistral-Small-3.1",
    "slug": "SimonPu/Mistral-Small-3.1",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "24B-Instruct-2503_q6_K",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "SimonPu/Mistral-Small-3.2",
    "slug": "SimonPu/Mistral-Small-3.2",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "Q4_K_XL",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "siv/Qwen3-Embedding-0.6B-GGUF",
    "slug": "siv/Qwen3-Embedding-0.6B-GGUF",
    "description": "",
    "features": [
      "embedding",
      "tools"
    ],
    "tags": [
      {
        "name": "Q8_0",
        "size": "639MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "F16",
        "size": "1.2GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sjo/deepseek-r1-8b-llama-distill-abliterated-q8_0",
    "slug": "sjo/deepseek-r1-8b-llama-distill-abliterated-q8_0",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "skyleraiguy/digitaltwin",
    "slug": "skyleraiguy/digitaltwin",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 47
  },
  {
    "name": "sleechengn/DeepScaleR-1.5B-Preview",
    "slug": "sleechengn/DeepScaleR-1.5B-Preview",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sleechengn/mistral-small3.1",
    "slug": "sleechengn/mistral-small3.1",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "24b-instruct-2503-q4_K_M",
        "size": "15GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "sleechengn/Mistral-Small3.1-24B-Instruct-2503",
    "slug": "sleechengn/Mistral-Small3.1-24B-Instruct-2503",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q2_K_L",
        "size": "9.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q4_K_L",
        "size": "15GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q5_K_L",
        "size": "17GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q3_K_L",
        "size": "12GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "slekrem/gpt-oss-claude-code-32k",
    "slug": "slekrem/gpt-oss-claude-code-32k",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "20b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "smallthinker",
    "slug": "smallthinker",
    "description": "A new small reasoning model fine-tuned from the Qwen 2.5 3B Instruct model.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "3.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-preview-q4_K_M",
        "size": "2.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-preview-q8_0",
        "size": "3.6GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "3b-preview-fp16",
        "size": "6.8GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 117800
  },
  {
    "name": "smollm2",
    "slug": "smollm2",
    "description": "SmolLM2 is a family of compact language models available in three size: 135M, 360M, and 1.7B parameters.",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "1.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m",
        "size": "271MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m",
        "size": "726MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b",
        "size": "1.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q2_K",
        "size": "88MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q3_K_S",
        "size": "88MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q3_K_M",
        "size": "94MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q3_K_L",
        "size": "98MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q4_0",
        "size": "92MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q4_1",
        "size": "98MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q4_K_S",
        "size": "102MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q4_K_M",
        "size": "105MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q5_0",
        "size": "105MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q5_1",
        "size": "112MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q5_K_S",
        "size": "110MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q5_K_M",
        "size": "112MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q6_K",
        "size": "138MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-q8_0",
        "size": "145MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "135m-instruct-fp16",
        "size": "271MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q2_K",
        "size": "219MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q3_K_S",
        "size": "219MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q3_K_M",
        "size": "235MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q3_K_L",
        "size": "246MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q4_0",
        "size": "229MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q4_1",
        "size": "249MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q4_K_S",
        "size": "260MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q4_K_M",
        "size": "271MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q5_0",
        "size": "268MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q5_1",
        "size": "288MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q5_K_S",
        "size": "283MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q5_K_M",
        "size": "290MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q6_K",
        "size": "367MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-q8_0",
        "size": "386MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "360m-instruct-fp16",
        "size": "726MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q2_K",
        "size": "675MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q3_K_S",
        "size": "777MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q3_K_M",
        "size": "860MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q3_K_L",
        "size": "933MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q4_0",
        "size": "991MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q4_1",
        "size": "1.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q4_K_S",
        "size": "999MB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q4_K_M",
        "size": "1.1GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q5_0",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q5_1",
        "size": "1.3GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q5_K_S",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q5_K_M",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q6_K",
        "size": "1.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-q8_0",
        "size": "1.8GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "1.7b-instruct-fp16",
        "size": "3.4GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 2200000
  },
  {
    "name": "solar-pro",
    "slug": "solar-pro",
    "description": "Solar Pro Preview: an advanced large language model (LLM) with 22 billion parameters designed to fit into a single GPU",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "13GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "preview",
        "size": "13GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b",
        "size": "13GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q2_K",
        "size": "8.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q3_K_S",
        "size": "9.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q3_K_M",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q3_K_L",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q4_0",
        "size": "12GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q4_1",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q4_K_S",
        "size": "13GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q4_K_M",
        "size": "13GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q5_0",
        "size": "15GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q5_1",
        "size": "17GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q5_K_S",
        "size": "15GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q5_K_M",
        "size": "16GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q6_K",
        "size": "18GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-q8_0",
        "size": "24GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "22b-preview-instruct-fp16",
        "size": "44GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "solobsd/tinyllama-2-miniguanaco",
    "slug": "solobsd/tinyllama-2-miniguanaco",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "782MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 154
  },
  {
    "name": "solobsd/tinyllama-chat",
    "slug": "solobsd/tinyllama-chat",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "783MB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 269
  },
  {
    "name": "sparksammy/deepcoder-langspecify",
    "slug": "sparksammy/deepcoder-langspecify",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sparksammy/microcoder-ministral-3",
    "slug": "sparksammy/microcoder-ministral-3",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "6.0GB",
        "context": "256K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "spratling/mistral-small-3.1-24B-it-2503",
    "slug": "spratling/mistral-small-3.1-24B-it-2503",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "Q6_K",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "25GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "srizon/pixie",
    "slug": "srizon/pixie",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "9.4GB",
        "context": "32K",
        "input": "Text, Image"
      }
    ],
    "downloads": 3776
  },
  {
    "name": "stable-code",
    "slug": "stable-code",
    "description": "Stable Code 3B is a coding model with instruct and code completion variants on par with models such as Code Llama 7B that are 2.5x larger.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "code",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "instruct",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q2_K",
        "size": "1.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q3_K_S",
        "size": "1.3GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q3_K_M",
        "size": "1.4GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q3_K_L",
        "size": "1.5GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q4_0",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q4_1",
        "size": "1.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q4_K_S",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q4_K_M",
        "size": "1.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q5_0",
        "size": "1.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q5_1",
        "size": "2.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q5_K_S",
        "size": "1.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q5_K_M",
        "size": "2.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q6_K",
        "size": "2.3GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-q8_0",
        "size": "3.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-code-fp16",
        "size": "5.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q2_K",
        "size": "1.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q3_K_S",
        "size": "1.3GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q3_K_M",
        "size": "1.4GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q3_K_L",
        "size": "1.5GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q4_0",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q4_1",
        "size": "1.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q4_K_S",
        "size": "1.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q4_K_M",
        "size": "1.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q5_0",
        "size": "1.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q5_1",
        "size": "2.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q5_K_S",
        "size": "1.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q5_K_M",
        "size": "2.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q6_K",
        "size": "2.3GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-q8_0",
        "size": "3.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-instruct-fp16",
        "size": "5.6GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": 227300
  },
  {
    "name": "stablelm-zephyr",
    "slug": "stablelm-zephyr",
    "description": "A lightweight chat model allowing accurate, and responsive output without requiring high-end hardware.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "1.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q2_K",
        "size": "1.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q3_K_S",
        "size": "1.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q3_K_M",
        "size": "1.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q3_K_L",
        "size": "1.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q4_0",
        "size": "1.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q4_1",
        "size": "1.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q4_K_S",
        "size": "1.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q4_K_M",
        "size": "1.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q5_0",
        "size": "1.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q5_1",
        "size": "2.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q5_K_S",
        "size": "1.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q5_K_M",
        "size": "2.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q6_K",
        "size": "2.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-q8_0",
        "size": "3.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "3b-fp16",
        "size": "5.6GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "STAR_ROBOT_LLM/smollm2_htmlext_finetune",
    "slug": "STAR_ROBOT_LLM/smollm2_htmlext_finetune",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "271MB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "starcoder2",
    "slug": "starcoder2",
    "description": "StarCoder2 is the next generation of transparently trained open code LLMs that comes in three sizes: 3B, 7B and 15B parameters.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "instruct",
        "size": "9.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "1.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b",
        "size": "9.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q2_K",
        "size": "1.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q3_K_S",
        "size": "1.3GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q3_K_M",
        "size": "1.5GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q3_K_L",
        "size": "1.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q4_0",
        "size": "1.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q4_1",
        "size": "1.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q4_K_S",
        "size": "1.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q4_K_M",
        "size": "1.8GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q5_0",
        "size": "2.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q5_1",
        "size": "2.3GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q5_K_S",
        "size": "2.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q5_K_M",
        "size": "2.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q6_K",
        "size": "2.5GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-q8_0",
        "size": "3.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "3b-fp16",
        "size": "6.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q2_K",
        "size": "2.7GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q3_K_S",
        "size": "3.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q3_K_M",
        "size": "3.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q3_K_L",
        "size": "4.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q4_0",
        "size": "4.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q4_1",
        "size": "4.5GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_S",
        "size": "4.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M",
        "size": "4.4GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q5_0",
        "size": "4.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q5_1",
        "size": "5.4GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q5_K_S",
        "size": "4.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q5_K_M",
        "size": "5.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q6_K",
        "size": "5.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0",
        "size": "7.6GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "7b-fp16",
        "size": "14GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct",
        "size": "9.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q2_K",
        "size": "6.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q3_K_S",
        "size": "7.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q3_K_M",
        "size": "8.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q3_K_L",
        "size": "9.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-q4_0",
        "size": "9.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q4_0",
        "size": "9.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q4_1",
        "size": "10GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q4_K_S",
        "size": "9.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q4_K_M",
        "size": "9.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q5_0",
        "size": "11GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q5_1",
        "size": "12GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q5_K_S",
        "size": "11GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q5_K_M",
        "size": "11GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q6_K",
        "size": "13GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-q8_0",
        "size": "17GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-instruct-v0.1-fp16",
        "size": "32GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q2_K",
        "size": "6.2GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q3_K_S",
        "size": "7.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q3_K_M",
        "size": "8.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q3_K_L",
        "size": "9.0GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q4_0",
        "size": "9.1GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q4_1",
        "size": "10GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q4_K_S",
        "size": "9.3GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q4_K_M",
        "size": "9.9GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q5_0",
        "size": "11GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q5_1",
        "size": "12GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q5_K_S",
        "size": "11GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q5_K_M",
        "size": "11GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q6_K",
        "size": "13GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-q8_0",
        "size": "17GB",
        "context": "16K",
        "input": "Text"
      },
      {
        "name": "15b-fp16",
        "size": "32GB",
        "context": "16K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "stryng/Algorithmic_AI_RC1_70B",
    "slug": "stryng/Algorithmic_AI_RC1_70B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "sunny-g/deepseek-v3-0324",
    "slug": "sunny-g/deepseek-v3-0324",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "ud-q2_k_xl",
        "size": "248GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 291
  },
  {
    "name": "svjack/gpt-oss-20b-heretic",
    "slug": "svjack/gpt-oss-20b-heretic",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 340
  },
  {
    "name": "t1c/deepseek-math-7b-rl",
    "slug": "t1c/deepseek-math-7b-rl",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "Q4",
        "size": "4.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "Q5",
        "size": "4.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "Q6",
        "size": "5.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "Q8",
        "size": "7.3GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "tarun_dachepally/EGL_Granite_4layers",
    "slug": "tarun_dachepally/EGL_Granite_4layers",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "125K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "tender_mayer_860/glm-4.7-flash-abliterated",
    "slug": "tender_mayer_860/glm-4.7-flash-abliterated",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "tensorsoft/translate_en2ko",
    "slug": "tensorsoft/translate_en2ko",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "thirdeyeai/SmolLM2-1.7B-Instruct-Uncensored.gguf",
    "slug": "thirdeyeai/SmolLM2-1.7B-Instruct-Uncensored.gguf",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "Q4_0",
        "size": "1.4GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "1.9GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "F16",
        "size": "3.6GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "tinydolphin",
    "slug": "tinydolphin",
    "description": "An experimental 1.1B parameter model trained on the new Dolphin 2.8 dataset by Eric Hartford and based on TinyLlama.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "637MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "v2.8",
        "size": "637MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b",
        "size": "637MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q2_K",
        "size": "432MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q3_K_S",
        "size": "499MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q3_K_M",
        "size": "548MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q3_K_L",
        "size": "592MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q4_0",
        "size": "637MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q4_1",
        "size": "701MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q4_K_S",
        "size": "640MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q4_K_M",
        "size": "668MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q5_0",
        "size": "766MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q5_1",
        "size": "831MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q5_K_S",
        "size": "766MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q5_K_M",
        "size": "782MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q6_K",
        "size": "903MB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-q8_0",
        "size": "1.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "1.1b-v2.8-fp16",
        "size": "2.2GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 224500
  },
  {
    "name": "tinyllama",
    "slug": "tinyllama",
    "description": "The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "638MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "chat",
        "size": "638MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "v0.6",
        "size": "638MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "v1",
        "size": "638MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b",
        "size": "638MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat",
        "size": "638MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q2_K",
        "size": "483MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q3_K_S",
        "size": "500MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q3_K_M",
        "size": "551MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q3_K_L",
        "size": "593MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q4_0",
        "size": "638MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q4_1",
        "size": "702MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q4_K_S",
        "size": "644MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q4_K_M",
        "size": "669MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q5_0",
        "size": "767MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q5_1",
        "size": "832MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q5_K_S",
        "size": "767MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q5_K_M",
        "size": "783MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q6_K",
        "size": "904MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-q8_0",
        "size": "1.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v0.6-fp16",
        "size": "2.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q2_K",
        "size": "483MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q3_K_S",
        "size": "500MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q3_K_M",
        "size": "551MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q3_K_L",
        "size": "593MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q4_0",
        "size": "638MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q4_1",
        "size": "702MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q4_K_S",
        "size": "644MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q4_K_M",
        "size": "669MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q5_0",
        "size": "767MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q5_1",
        "size": "832MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q5_K_S",
        "size": "767MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q5_K_M",
        "size": "783MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q6_K",
        "size": "904MB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-q8_0",
        "size": "1.2GB",
        "context": "2K",
        "input": "Text"
      },
      {
        "name": "1.1b-chat-v1-fp16",
        "size": "2.2GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": 3200000
  },
  {
    "name": "tom_himanen/deepseek-r1-roo-cline-tools",
    "slug": "tom_himanen/deepseek-r1-roo-cline-tools",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "1.5b",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-16k_ctx-temp0.1",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-16k_ctx-temp0.2",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-16k_ctx-temp0.3",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-16k_ctx-temp0.4",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-16k_ctx-temp0.5",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-16k_ctx-temp0.6",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-16k_ctx-temp0.7",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-32k_ctx-temp0.1",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-32k_ctx-temp0.2",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-32k_ctx-temp0.3",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-32k_ctx-temp0.4",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-32k_ctx-temp0.5",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-32k_ctx-temp0.6",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-32k_ctx-temp0.7",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-64k_ctx-temp0.1",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-64k_ctx-temp0.2",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-64k_ctx-temp0.3",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-64k_ctx-temp0.4",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-64k_ctx-temp0.5",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-64k_ctx-temp0.6",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-64k_ctx-temp0.7",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-8k_ctx-temp0.1",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-8k_ctx-temp0.2",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-8k_ctx-temp0.3",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-8k_ctx-temp0.4",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-8k_ctx-temp0.5",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-8k_ctx-temp0.6",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-8k_ctx-temp0.7",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-16k_ctx-temp0.1",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-16k_ctx-temp0.2",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-16k_ctx-temp0.3",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-16k_ctx-temp0.4",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-16k_ctx-temp0.5",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-16k_ctx-temp0.6",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-16k_ctx-temp0.7",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-32k_ctx-temp0.1",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-32k_ctx-temp0.2",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-32k_ctx-temp0.3",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-32k_ctx-temp0.4",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-32k_ctx-temp0.5",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-32k_ctx-temp0.6",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-32k_ctx-temp0.7",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-64k_ctx-temp0.1",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-64k_ctx-temp0.2",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-64k_ctx-temp0.3",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-64k_ctx-temp0.4",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-64k_ctx-temp0.5",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-64k_ctx-temp0.6",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-64k_ctx-temp0.7",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-8k_ctx-temp0.1",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-8k_ctx-temp0.2",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-8k_ctx-temp0.3",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-8k_ctx-temp0.4",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-8k_ctx-temp0.5",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-8k_ctx-temp0.6",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q4_K_M-8k_ctx-temp0.7",
        "size": "1.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-16k_ctx-temp0.1",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-16k_ctx-temp0.2",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-16k_ctx-temp0.3",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-16k_ctx-temp0.4",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-16k_ctx-temp0.5",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-16k_ctx-temp0.6",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-16k_ctx-temp0.7",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-32k_ctx-temp0.1",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-32k_ctx-temp0.2",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-32k_ctx-temp0.3",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-32k_ctx-temp0.4",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-32k_ctx-temp0.5",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-32k_ctx-temp0.6",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-32k_ctx-temp0.7",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-64k_ctx-temp0.1",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-64k_ctx-temp0.2",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-64k_ctx-temp0.3",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-64k_ctx-temp0.4",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-64k_ctx-temp0.5",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-64k_ctx-temp0.6",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-64k_ctx-temp0.7",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-8k_ctx-temp0.1",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-8k_ctx-temp0.2",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-8k_ctx-temp0.3",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-8k_ctx-temp0.4",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-8k_ctx-temp0.5",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-8k_ctx-temp0.6",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "1.5b-q8_0-8k_ctx-temp0.7",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-16k_ctx-temp0.1",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-16k_ctx-temp0.2",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-16k_ctx-temp0.3",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-16k_ctx-temp0.4",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-16k_ctx-temp0.5",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-16k_ctx-temp0.6",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-16k_ctx-temp0.7",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-32k_ctx-temp0.1",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-32k_ctx-temp0.2",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-32k_ctx-temp0.3",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-32k_ctx-temp0.4",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-32k_ctx-temp0.5",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-32k_ctx-temp0.6",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-32k_ctx-temp0.7",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-64k_ctx-temp0.1",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-64k_ctx-temp0.2",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-64k_ctx-temp0.3",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-64k_ctx-temp0.4",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-64k_ctx-temp0.5",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-64k_ctx-temp0.6",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-64k_ctx-temp0.7",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-8k_ctx-temp0.1",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-8k_ctx-temp0.2",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-8k_ctx-temp0.3",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-8k_ctx-temp0.4",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-8k_ctx-temp0.5",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-8k_ctx-temp0.6",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-8k_ctx-temp0.7",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-16k_ctx-temp0.1",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-16k_ctx-temp0.2",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-16k_ctx-temp0.3",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-16k_ctx-temp0.4",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-16k_ctx-temp0.5",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-16k_ctx-temp0.6",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-16k_ctx-temp0.7",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-32k_ctx-temp0.1",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-32k_ctx-temp0.2",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-32k_ctx-temp0.3",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-32k_ctx-temp0.4",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-32k_ctx-temp0.5",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-32k_ctx-temp0.6",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-32k_ctx-temp0.7",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-64k_ctx-temp0.1",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-64k_ctx-temp0.2",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-64k_ctx-temp0.3",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-64k_ctx-temp0.4",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-64k_ctx-temp0.5",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-64k_ctx-temp0.6",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-64k_ctx-temp0.7",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-8k_ctx-temp0.1",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-8k_ctx-temp0.2",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-8k_ctx-temp0.3",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-8k_ctx-temp0.4",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-8k_ctx-temp0.5",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-8k_ctx-temp0.6",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M-8k_ctx-temp0.7",
        "size": "4.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-16k_ctx-temp0.1",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-16k_ctx-temp0.2",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-16k_ctx-temp0.3",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-16k_ctx-temp0.4",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-16k_ctx-temp0.5",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-16k_ctx-temp0.6",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-16k_ctx-temp0.7",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-32k_ctx-temp0.1",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-32k_ctx-temp0.2",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-32k_ctx-temp0.3",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-32k_ctx-temp0.4",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-32k_ctx-temp0.5",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-32k_ctx-temp0.6",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-32k_ctx-temp0.7",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-64k_ctx-temp0.1",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-64k_ctx-temp0.2",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-64k_ctx-temp0.3",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-64k_ctx-temp0.4",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-64k_ctx-temp0.5",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-64k_ctx-temp0.6",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-64k_ctx-temp0.7",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-8k_ctx-temp0.1",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-8k_ctx-temp0.2",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-8k_ctx-temp0.3",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-8k_ctx-temp0.4",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-8k_ctx-temp0.5",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-8k_ctx-temp0.6",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0-8k_ctx-temp0.7",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-16k_ctx-temp0.1",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-16k_ctx-temp0.2",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-16k_ctx-temp0.3",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-16k_ctx-temp0.4",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-16k_ctx-temp0.5",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-16k_ctx-temp0.6",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-16k_ctx-temp0.7",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-32k_ctx-temp0.1",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-32k_ctx-temp0.2",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-32k_ctx-temp0.3",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-32k_ctx-temp0.4",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-32k_ctx-temp0.5",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-32k_ctx-temp0.6",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-32k_ctx-temp0.7",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-64k_ctx-temp0.1",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-64k_ctx-temp0.2",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-64k_ctx-temp0.3",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-64k_ctx-temp0.4",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-64k_ctx-temp0.5",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-64k_ctx-temp0.6",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-64k_ctx-temp0.7",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-8k_ctx-temp0.1",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-8k_ctx-temp0.2",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-8k_ctx-temp0.3",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-8k_ctx-temp0.4",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-8k_ctx-temp0.5",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-8k_ctx-temp0.6",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-8k_ctx-temp0.7",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-16k_ctx-temp0.1",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-16k_ctx-temp0.2",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-16k_ctx-temp0.3",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-16k_ctx-temp0.4",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-16k_ctx-temp0.5",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-16k_ctx-temp0.6",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-16k_ctx-temp0.7",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-32k_ctx-temp0.1",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-32k_ctx-temp0.2",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-32k_ctx-temp0.3",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-32k_ctx-temp0.4",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-32k_ctx-temp0.5",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-32k_ctx-temp0.6",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-32k_ctx-temp0.7",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-64k_ctx-temp0.1",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-64k_ctx-temp0.2",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-64k_ctx-temp0.3",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-64k_ctx-temp0.4",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-64k_ctx-temp0.5",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-64k_ctx-temp0.6",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-64k_ctx-temp0.7",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-8k_ctx-temp0.1",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-8k_ctx-temp0.2",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-8k_ctx-temp0.3",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-8k_ctx-temp0.4",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-8k_ctx-temp0.5",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-8k_ctx-temp0.6",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q4_K_M-8k_ctx-temp0.7",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-16k_ctx-temp0.1",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-16k_ctx-temp0.2",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-16k_ctx-temp0.3",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-16k_ctx-temp0.4",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-16k_ctx-temp0.5",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-16k_ctx-temp0.6",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-16k_ctx-temp0.7",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-32k_ctx-temp0.1",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-32k_ctx-temp0.2",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-32k_ctx-temp0.3",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-32k_ctx-temp0.4",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-32k_ctx-temp0.5",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-32k_ctx-temp0.6",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-32k_ctx-temp0.7",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-64k_ctx-temp0.1",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-64k_ctx-temp0.2",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-64k_ctx-temp0.3",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-64k_ctx-temp0.4",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-64k_ctx-temp0.5",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-64k_ctx-temp0.6",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-64k_ctx-temp0.7",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-8k_ctx-temp0.1",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-8k_ctx-temp0.2",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-8k_ctx-temp0.3",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-8k_ctx-temp0.4",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-8k_ctx-temp0.5",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-8k_ctx-temp0.6",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "8b-q8_0-8k_ctx-temp0.7",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-16k_ctx-temp0.1",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-16k_ctx-temp0.2",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-16k_ctx-temp0.3",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-16k_ctx-temp0.4",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-16k_ctx-temp0.5",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-16k_ctx-temp0.6",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-16k_ctx-temp0.7",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-32k_ctx-temp0.1",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-32k_ctx-temp0.2",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-32k_ctx-temp0.3",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-32k_ctx-temp0.4",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-32k_ctx-temp0.5",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-32k_ctx-temp0.6",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-32k_ctx-temp0.7",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-64k_ctx-temp0.1",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-64k_ctx-temp0.2",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-64k_ctx-temp0.3",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-64k_ctx-temp0.4",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-64k_ctx-temp0.5",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-64k_ctx-temp0.6",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-64k_ctx-temp0.7",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-8k_ctx-temp0.1",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-8k_ctx-temp0.2",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-8k_ctx-temp0.3",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-8k_ctx-temp0.4",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-8k_ctx-temp0.5",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-8k_ctx-temp0.6",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-8k_ctx-temp0.7",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-16k_ctx-temp0.1",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-16k_ctx-temp0.2",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-16k_ctx-temp0.3",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-16k_ctx-temp0.4",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-16k_ctx-temp0.5",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-16k_ctx-temp0.6",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-16k_ctx-temp0.7",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-32k_ctx-temp0.1",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-32k_ctx-temp0.2",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-32k_ctx-temp0.3",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-32k_ctx-temp0.4",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-32k_ctx-temp0.5",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-32k_ctx-temp0.6",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-32k_ctx-temp0.7",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-64k_ctx-temp0.1",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-64k_ctx-temp0.2",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-64k_ctx-temp0.3",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-64k_ctx-temp0.4",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-64k_ctx-temp0.5",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-64k_ctx-temp0.6",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-64k_ctx-temp0.7",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-8k_ctx-temp0.1",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-8k_ctx-temp0.2",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-8k_ctx-temp0.3",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-8k_ctx-temp0.4",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-8k_ctx-temp0.5",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-8k_ctx-temp0.6",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q4_K_M-8k_ctx-temp0.7",
        "size": "9.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-16k_ctx-temp0.1",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-16k_ctx-temp0.2",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-16k_ctx-temp0.3",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-16k_ctx-temp0.4",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-16k_ctx-temp0.5",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-16k_ctx-temp0.6",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-16k_ctx-temp0.7",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-32k_ctx-temp0.1",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-32k_ctx-temp0.2",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-32k_ctx-temp0.3",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-32k_ctx-temp0.4",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-32k_ctx-temp0.5",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-32k_ctx-temp0.6",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-32k_ctx-temp0.7",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-64k_ctx-temp0.1",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-64k_ctx-temp0.2",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-64k_ctx-temp0.3",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-64k_ctx-temp0.4",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-64k_ctx-temp0.5",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-64k_ctx-temp0.6",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-64k_ctx-temp0.7",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-8k_ctx-temp0.1",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-8k_ctx-temp0.2",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-8k_ctx-temp0.3",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-8k_ctx-temp0.4",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-8k_ctx-temp0.5",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-8k_ctx-temp0.6",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "14b-q8_0-8k_ctx-temp0.7",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-16k_ctx-temp0.1",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-16k_ctx-temp0.2",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-16k_ctx-temp0.3",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-16k_ctx-temp0.4",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-16k_ctx-temp0.5",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-16k_ctx-temp0.6",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-16k_ctx-temp0.7",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-32k_ctx-temp0.1",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-32k_ctx-temp0.2",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-32k_ctx-temp0.3",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-32k_ctx-temp0.4",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-32k_ctx-temp0.5",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-32k_ctx-temp0.6",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-32k_ctx-temp0.7",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-64k_ctx-temp0.1",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-64k_ctx-temp0.2",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-64k_ctx-temp0.3",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-64k_ctx-temp0.4",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-64k_ctx-temp0.5",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-64k_ctx-temp0.6",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-64k_ctx-temp0.7",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-8k_ctx-temp0.1",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-8k_ctx-temp0.2",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-8k_ctx-temp0.3",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-8k_ctx-temp0.4",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-8k_ctx-temp0.5",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-8k_ctx-temp0.6",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-8k_ctx-temp0.7",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-16k_ctx-temp0.1",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-16k_ctx-temp0.2",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-16k_ctx-temp0.3",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-16k_ctx-temp0.4",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-16k_ctx-temp0.5",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-16k_ctx-temp0.6",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-16k_ctx-temp0.7",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-32k_ctx-temp0.1",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-32k_ctx-temp0.2",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-32k_ctx-temp0.3",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-32k_ctx-temp0.4",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-32k_ctx-temp0.5",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-32k_ctx-temp0.6",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-32k_ctx-temp0.7",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-64k_ctx-temp0.1",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-64k_ctx-temp0.2",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-64k_ctx-temp0.3",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-64k_ctx-temp0.4",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-64k_ctx-temp0.5",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-64k_ctx-temp0.6",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-64k_ctx-temp0.7",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-8k_ctx-temp0.1",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-8k_ctx-temp0.2",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-8k_ctx-temp0.3",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-8k_ctx-temp0.4",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-8k_ctx-temp0.5",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-8k_ctx-temp0.6",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M-8k_ctx-temp0.7",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-16k_ctx-temp0.1",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-16k_ctx-temp0.2",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-16k_ctx-temp0.3",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-16k_ctx-temp0.4",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-16k_ctx-temp0.5",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-16k_ctx-temp0.6",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-16k_ctx-temp0.7",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-32k_ctx-temp0.1",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-32k_ctx-temp0.2",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-32k_ctx-temp0.3",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-32k_ctx-temp0.4",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-32k_ctx-temp0.5",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-32k_ctx-temp0.6",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-32k_ctx-temp0.7",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-64k_ctx-temp0.1",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-64k_ctx-temp0.2",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-64k_ctx-temp0.3",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-64k_ctx-temp0.4",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-64k_ctx-temp0.5",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-64k_ctx-temp0.6",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-64k_ctx-temp0.7",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-8k_ctx-temp0.1",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-8k_ctx-temp0.2",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-8k_ctx-temp0.3",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-8k_ctx-temp0.4",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-8k_ctx-temp0.5",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-8k_ctx-temp0.6",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0-8k_ctx-temp0.7",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-16k_ctx-temp0.1",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-16k_ctx-temp0.2",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-16k_ctx-temp0.3",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-16k_ctx-temp0.4",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-16k_ctx-temp0.5",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-16k_ctx-temp0.6",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-16k_ctx-temp0.7",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-32k_ctx-temp0.1",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-32k_ctx-temp0.2",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-32k_ctx-temp0.3",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-32k_ctx-temp0.4",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-32k_ctx-temp0.5",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-32k_ctx-temp0.6",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-32k_ctx-temp0.7",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-64k_ctx-temp0.1",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-64k_ctx-temp0.2",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-64k_ctx-temp0.3",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-64k_ctx-temp0.4",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-64k_ctx-temp0.5",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-64k_ctx-temp0.6",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-64k_ctx-temp0.7",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-8k_ctx-temp0.1",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-8k_ctx-temp0.2",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-8k_ctx-temp0.3",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-8k_ctx-temp0.4",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-8k_ctx-temp0.5",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-8k_ctx-temp0.6",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-8k_ctx-temp0.7",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-16k_ctx-temp0.1",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-16k_ctx-temp0.2",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-16k_ctx-temp0.3",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-16k_ctx-temp0.4",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-16k_ctx-temp0.5",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-16k_ctx-temp0.6",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-16k_ctx-temp0.7",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-32k_ctx-temp0.1",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-32k_ctx-temp0.2",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-32k_ctx-temp0.3",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-32k_ctx-temp0.4",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-32k_ctx-temp0.5",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-32k_ctx-temp0.6",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-32k_ctx-temp0.7",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-64k_ctx-temp0.1",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-64k_ctx-temp0.2",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-64k_ctx-temp0.3",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-64k_ctx-temp0.4",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-64k_ctx-temp0.5",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-64k_ctx-temp0.6",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-64k_ctx-temp0.7",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-8k_ctx-temp0.1",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-8k_ctx-temp0.2",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-8k_ctx-temp0.3",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-8k_ctx-temp0.4",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-8k_ctx-temp0.5",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-8k_ctx-temp0.6",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q4_K_M-8k_ctx-temp0.7",
        "size": "43GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-16k_ctx-temp0.1",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-16k_ctx-temp0.2",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-16k_ctx-temp0.3",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-16k_ctx-temp0.4",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-16k_ctx-temp0.5",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-16k_ctx-temp0.6",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-16k_ctx-temp0.7",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-32k_ctx-temp0.1",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-32k_ctx-temp0.2",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-32k_ctx-temp0.3",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-32k_ctx-temp0.4",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-32k_ctx-temp0.5",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-32k_ctx-temp0.6",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-32k_ctx-temp0.7",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-64k_ctx-temp0.1",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-64k_ctx-temp0.2",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-64k_ctx-temp0.3",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-64k_ctx-temp0.4",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-64k_ctx-temp0.5",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-64k_ctx-temp0.6",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-64k_ctx-temp0.7",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-8k_ctx-temp0.1",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-8k_ctx-temp0.2",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-8k_ctx-temp0.3",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-8k_ctx-temp0.4",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-8k_ctx-temp0.5",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-8k_ctx-temp0.6",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "70b-q8_0-8k_ctx-temp0.7",
        "size": "75GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 17200
  },
  {
    "name": "tom_himanen/ministral-3-14b-reasoning",
    "slug": "tom_himanen/ministral-3-14b-reasoning",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q2_K",
        "size": "5.2GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q3_K_M",
        "size": "6.7GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q5_K_M",
        "size": "9.6GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q6_K",
        "size": "11GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "14GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q2_K-128k",
        "size": "5.2GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q2_K-16k",
        "size": "5.2GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q2_K-256k",
        "size": "5.2GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q2_K-32k",
        "size": "5.2GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q2_K-64k",
        "size": "5.2GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q3_K_M-128k",
        "size": "6.7GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q3_K_M-16k",
        "size": "6.7GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q3_K_M-256k",
        "size": "6.7GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q3_K_M-32k",
        "size": "6.7GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q3_K_M-64k",
        "size": "6.7GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q5_K_M-128k",
        "size": "9.6GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q5_K_M-16k",
        "size": "9.6GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q5_K_M-256k",
        "size": "9.6GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q5_K_M-32k",
        "size": "9.6GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q5_K_M-64k",
        "size": "9.6GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q6_K-128k",
        "size": "11GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q6_K-16k",
        "size": "11GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q6_K-256k",
        "size": "11GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q6_K-32k",
        "size": "11GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q6_K-64k",
        "size": "11GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q8_0-128k",
        "size": "14GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q8_0-16k",
        "size": "14GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q8_0-256k",
        "size": "14GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q8_0-32k",
        "size": "14GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "q8_0-64k",
        "size": "14GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "toshk0/nomic-embed-text-v2-moe",
    "slug": "toshk0/nomic-embed-text-v2-moe",
    "description": "",
    "features": [
      "embedding"
    ],
    "tags": [
      {
        "name": "Q6_K",
        "size": "397MB",
        "context": "512",
        "input": "Text"
      }
    ],
    "downloads": 1229
  },
  {
    "name": "transkatgirl/Mistral-Small-3.1-24B-Base",
    "slug": "transkatgirl/Mistral-Small-3.1-24B-Base",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q4_k_m",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "19GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "25GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "transkatgirl/OLMo-2-32B",
    "slug": "transkatgirl/OLMo-2-32B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "q4_k_m",
        "size": "19GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q6_k",
        "size": "26GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "q8_0",
        "size": "34GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 18
  },
  {
    "name": "transkatgirl/SmolLM2-1.7B",
    "slug": "transkatgirl/SmolLM2-1.7B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.4GB",
        "context": "2K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "translategemma",
    "slug": "translategemma",
    "description": "A new collection of open translation models built on Gemma 3, helping people communicate across 55 languages.",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b",
        "size": "17GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-it-q4_K_M",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-it-q8_0",
        "size": "4.9GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "4b-it-bf16",
        "size": "8.6GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b-it-q4_K_M",
        "size": "8.1GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b-it-q8_0",
        "size": "13GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "12b-it-bf16",
        "size": "24GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-it-q4_K_M",
        "size": "17GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-it-q8_0",
        "size": "30GB",
        "context": "128K",
        "input": "Text, Image"
      },
      {
        "name": "27b-it-bf16",
        "size": "55GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "trinsition/minicpmv",
    "slug": "trinsition/minicpmv",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "16GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 502
  },
  {
    "name": "TwinkleAI/Llama-3.2-3B-F1-Resoning-Instruct",
    "slug": "TwinkleAI/Llama-3.2-3B-F1-Resoning-Instruct",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "2.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "3b",
        "size": "2.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q2_K",
        "size": "1.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q3_K_S",
        "size": "1.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q3_K_M",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q3_K_L",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_0",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_1",
        "size": "2.3GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_K_S",
        "size": "2.1GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "2.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q5_0",
        "size": "2.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q5_1",
        "size": "2.7GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q5_K_S",
        "size": "2.5GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "2.6GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "3.0GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "3.8GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "F16",
        "size": "7.2GB",
        "context": "128K",
        "input": "Text"
      },
      {
        "name": "BF16",
        "size": "7.2GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "ucx0204/glm-4.6V-Flash-Q8",
    "slug": "ucx0204/glm-4.6V-Flash-Q8",
    "description": "",
    "features": [
      "vision",
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "12GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "ukjin/Qwen3-30B-A3B-Thinking-2507-Deepseek-v3.1-Distill",
    "slug": "ukjin/Qwen3-30B-A3B-Thinking-2507-Deepseek-v3.1-Distill",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      },
      {
        "name": "4b",
        "size": "19GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": 943
  },
  {
    "name": "unclecode/tinycallama",
    "slug": "unclecode/tinycallama",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.2GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 315
  },
  {
    "name": "unitythemaker/llama3.2-vision-tools",
    "slug": "unitythemaker/llama3.2-vision-tools",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "7.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": 896
  },
  {
    "name": "user-v4/joycaption-beta",
    "slug": "user-v4/joycaption-beta",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "9.4GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "vaibhav-s-dabhade/phi-3.5-mini-instruct",
    "slug": "vaibhav-s-dabhade/phi-3.5-mini-instruct",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.4GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "vanilj/mistral-large-instruct-2407-iq3_xx",
    "slug": "vanilj/mistral-large-instruct-2407-iq3_xx",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "47GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "vanilj/mistral-nemo-12b-celeste-v1.9",
    "slug": "vanilj/mistral-nemo-12b-celeste-v1.9",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "7.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "Q3_K_M",
        "size": "6.1GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "Q4_K_M",
        "size": "7.5GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "Q5_K_M",
        "size": "8.7GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "Q6_K",
        "size": "10GB",
        "context": "1000K",
        "input": "Text"
      },
      {
        "name": "Q8_0",
        "size": "13GB",
        "context": "1000K",
        "input": "Text"
      }
    ],
    "downloads": 2498
  },
  {
    "name": "vanta-research/atom-olmo3-7b",
    "slug": "vanta-research/atom-olmo3-7b",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "4.5GB",
        "context": "64K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "volvi/GLaDOS3.4_3B",
    "slug": "volvi/GLaDOS3.4_3B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "2.0GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "volvi/HAL3.2-1B",
    "slug": "volvi/HAL3.2-1B",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.3GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "wangshenzhi/gemma2-27b-chinese-chat",
    "slug": "wangshenzhi/gemma2-27b-chinese-chat",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "16GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 1590
  },
  {
    "name": "wangshenzhi/gemma2-9b-chinese-chat",
    "slug": "wangshenzhi/gemma2-9b-chinese-chat",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "5.8GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 4675
  },
  {
    "name": "wao/DeepSeek-R1-Distill-Qwen-32B-Japanese",
    "slug": "wao/DeepSeek-R1-Distill-Qwen-32B-Japanese",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "35GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "wesjos/Llama3.2-Fu",
    "slug": "wesjos/Llama3.2-Fu",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "3b",
        "size": "2.3GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "William_Llama/deepseek-llm-67b-chat-GGUF",
    "slug": "William_Llama/deepseek-llm-67b-chat-GGUF",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "40GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "wonderful_lederberg_878/glm-4.7-flash",
    "slug": "wonderful_lederberg_878/glm-4.7-flash",
    "description": "",
    "features": [
      "tools",
      "thinking"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "19GB",
        "context": "198K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "wudilaomo/Mo_DeepSeek-R1-Medical",
    "slug": "wudilaomo/Mo_DeepSeek-R1-Medical",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "16GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "x1nx3r/llama3.2-thinking",
    "slug": "x1nx3r/llama3.2-thinking",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "6.4GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "XDPXI/Codex-0.1-Mini",
    "slug": "XDPXI/Codex-0.1-Mini",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "16b",
        "size": "8.9GB",
        "context": "160K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "xiaowangge/deepseek-v3-qwen2.5",
    "slug": "xiaowangge/deepseek-v3-qwen2.5",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b",
        "size": "20GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-q4_K_M",
        "size": "4.7GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-q8_0",
        "size": "8.1GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "7b-fp16",
        "size": "15GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q4_K_M",
        "size": "66GB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "32b-q8_0",
        "size": "35GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": 845
  },
  {
    "name": "xiayu/openbmb-minicpm-llama3-v-2_5",
    "slug": "xiayu/openbmb-minicpm-llama3-v-2_5",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "Q8_0",
        "size": "9.6GB",
        "context": "8K",
        "input": "Text"
      },
      {
        "name": "fp16",
        "size": "17GB",
        "context": "8K",
        "input": "Text"
      }
    ],
    "downloads": 2784
  },
  {
    "name": "xwinlm",
    "slug": "xwinlm",
    "description": "Conversational model based on Llama 2 that performs competitively on various benchmarks.",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q2_K",
        "size": "2.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q3_K_S",
        "size": "2.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q3_K_M",
        "size": "3.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q3_K_L",
        "size": "3.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_0",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_1",
        "size": "4.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_K_S",
        "size": "3.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q4_K_M",
        "size": "4.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_0",
        "size": "4.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_1",
        "size": "5.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_K_S",
        "size": "4.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q5_K_M",
        "size": "4.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q6_K",
        "size": "5.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-q8_0",
        "size": "7.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.1-fp16",
        "size": "13GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q2_K",
        "size": "2.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q3_K_S",
        "size": "2.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q3_K_L",
        "size": "3.6GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q4_0",
        "size": "3.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q4_1",
        "size": "4.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q4_K_S",
        "size": "3.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q4_K_M",
        "size": "4.1GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q5_0",
        "size": "4.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q5_K_S",
        "size": "4.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q5_K_M",
        "size": "4.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q6_K",
        "size": "5.5GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-q8_0",
        "size": "7.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "7b-v0.2-fp16",
        "size": "13GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q2_K",
        "size": "5.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q3_K_S",
        "size": "5.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q3_K_M",
        "size": "6.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q3_K_L",
        "size": "6.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q4_0",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q4_1",
        "size": "8.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q4_K_S",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q4_K_M",
        "size": "7.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q5_0",
        "size": "9.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q5_1",
        "size": "9.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q5_K_S",
        "size": "9.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q5_K_M",
        "size": "9.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q6_K",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-q8_0",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.1-fp16",
        "size": "26GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q2_K",
        "size": "5.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q3_K_S",
        "size": "5.7GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q3_K_M",
        "size": "6.3GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q3_K_L",
        "size": "6.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q4_0",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q4_1",
        "size": "8.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q4_K_S",
        "size": "7.4GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q4_K_M",
        "size": "7.9GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q5_0",
        "size": "9.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q5_1",
        "size": "9.8GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q5_K_S",
        "size": "9.0GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q5_K_M",
        "size": "9.2GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q6_K",
        "size": "11GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-q8_0",
        "size": "14GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "13b-v0.2-fp16",
        "size": "26GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1",
        "size": "39GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q2_K",
        "size": "29GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q3_K_S",
        "size": "30GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q3_K_M",
        "size": "33GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q3_K_L",
        "size": "36GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q4_0",
        "size": "39GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q4_1",
        "size": "43GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q4_K_S",
        "size": "39GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q4_K_M",
        "size": "41GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q5_0",
        "size": "47GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q5_1",
        "size": "52GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q5_K_S",
        "size": "47GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q6_K",
        "size": "57GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-q8_0",
        "size": "73GB",
        "context": "4K",
        "input": "Text"
      },
      {
        "name": "70b-v0.1-fp16",
        "size": "138GB",
        "context": "4K",
        "input": "Text"
      }
    ],
    "downloads": 167700
  },
  {
    "name": "yashagrawal/ReAct-Deepseek-R1-Distill-Llama-8B-bnb-4bit",
    "slug": "yashagrawal/ReAct-Deepseek-R1-Distill-Llama-8B-bnb-4bit",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "8.5GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "yasserrmd/DeepScaleR-1.5B-Preview",
    "slug": "yasserrmd/DeepScaleR-1.5B-Preview",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.9GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "yemifo/qwen25-vl-3b-instruct4k",
    "slug": "yemifo/qwen25-vl-3b-instruct4k",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.9GB",
        "context": "125K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "yemifo/qwen25-vl-3b-q4km",
    "slug": "yemifo/qwen25-vl-3b-q4km",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "latest",
        "size": "1.9GB",
        "context": "125K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "yuiseki/devstral-small-2507",
    "slug": "yuiseki/devstral-small-2507",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "24b",
        "size": "14GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "yungwarlock/mistral-small",
    "slug": "yungwarlock/mistral-small",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "14GB",
        "context": "32K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "z-uo/llava-med-v1.5-mistral-7b_f32",
    "slug": "z-uo/llava-med-v1.5-mistral-7b_f32",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "30GB",
        "context": "32K",
        "input": "Text, Image"
      }
    ],
    "downloads": 99
  },
  {
    "name": "z-uo/llava-med-v1.5-mistral-7b_q8_0",
    "slug": "z-uo/llava-med-v1.5-mistral-7b_q8_0",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "8.3GB",
        "context": "32K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "z-uo/qwen2.5vl_tools",
    "slug": "z-uo/qwen2.5vl_tools",
    "description": "",
    "features": [
      "vision",
      "tools"
    ],
    "tags": [
      {
        "name": "3b",
        "size": "3.2GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "7b",
        "size": "6.0GB",
        "context": "125K",
        "input": "Text, Image"
      },
      {
        "name": "32b",
        "size": "21GB",
        "context": "125K",
        "input": "Text, Image"
      }
    ],
    "downloads": null
  },
  {
    "name": "zdolny/qwen3-coder58k-tools",
    "slug": "zdolny/qwen3-coder58k-tools",
    "description": "",
    "features": [
      "tools"
    ],
    "tags": [
      {
        "name": "latest",
        "size": "18GB",
        "context": "256K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "zhinao/tiny-r1",
    "slug": "zhinao/tiny-r1",
    "description": "",
    "features": [],
    "tags": [
      {
        "name": "32b",
        "size": "20GB",
        "context": "128K",
        "input": "Text"
      }
    ],
    "downloads": null
  },
  {
    "name": "zongwei/gemma3-translator",
    "slug": "zongwei/gemma3-translator",
    "description": "",
    "features": [
      "vision"
    ],
    "tags": [
      {
        "name": "1b",
        "size": "815MB",
        "context": "32K",
        "input": "Text"
      },
      {
        "name": "4b",
        "size": "3.3GB",
        "context": "128K",
        "input": "Text, Image"
      }
    ],
    "downloads": 117800
  }
]