# 1.23.19 Testable usage of the agent flow

**Parent:** 1.23.x (skills agent). **Source:** Request for a CLI that exercises each stage of the agent flow in isolation.

**Coding standards:** All proposed and implemented code must follow `.cursor/rules/CODING_STANDARDS.md`. Before marking ready, verify: nullable types, null checks, no `@"..."` except multi-line/help, no one-use temporaries/trivial aliases, brace style (line break for class/method, inline for if/for; no one-line if with body), `this.` for instance members, full `GLib.*` and no `using`, property defaults not constructor init, line breaking for long calls, no StringBuilder except hundreds-of-iterations loops, no string build in loops, `string[] name = {}` not `new string[0]`, loops use `continue` not else/nesting, no character looping (prefer string methods/regex), file try/catch only when existence unknown, minimal try/catch scope, no leading underscore, no `get_*()` — use properties or verb-less names (e.g. `refinement_prompt()` not `get_refinement_prompt()`).

**Plan focus:** Concrete code only. No sentences.

---

## 1. Objective

Create a new example application **oc-test-skill-agent** that extends the standard application (like other examples) and provides **testable, step-by-step usage** of the skills agent flow. Each stage can be run independently so prompts and outputs can be inspected without running the full pipeline.

---

## 2. Application shape

- **Name:** `oc-test-skill-agent`
- **Extends:** Standard application pattern — e.g. `Application` + `OLLMchat.ApplicationInterface` (like `oc-test-cli`) or `TestAppBase` (like `oc-test-gtkmd`). Prefer the same pattern as other examples that need config and CLI (e.g. TestAppBase for shared debug/url/model options).
- **Build:** Add executable in `examples/meson.build` and wire into root `meson.build` run targets if appropriate.
- **Inputs:** Rationalized CLI:
  - `--project PATH`, `--prompt TEXT`, `--model ID` — project, user prompt, optional model override.
  - `--input FILE` — task list file for refine, execute, iteration (and for loading when a mode needs it).
  - `--test-output FILE` — LLM output file to parse: task list creation output (parse-tasklist), refinement output (parse-refine), or executor output (parse-execute). One option for all parse modes.
  - `--task-list FILE` — task list file; required for parse-refine and parse-execute (to resolve Details at --step/--task-num). Not used for parse-tasklist (that mode parses --test-output into a task list).
  - `--input-refine FILE` — refinement output file; required for `--run execute-prompt` and `--run execute`. Testable processes: no chaining; execute gets task list from `--input` and refinement from `--input-refine`. The task at `--step`/`--task-num` gets refinement applied via ResultParser.extract_refinement(detail) so it has tools/tool_calls before run_tools and executor.
  - `--run MODE` — one of: prompt, prompt-run, parse-tasklist, parse-refine, parse-execute, refine-prompt, refine, execute-prompt, execute, refine-all, execute-all. Reduces many boolean/file options to one mode selector.
  - `--step N`, `--task-num N` — step/task indices (default 0) for refine and execute modes; select which task in the parsed list. Execute runs on that **one** task, which must already have refinement applied (tool calls from refine output).

---

## 3. Modes (keyed by `--run MODE`; file inputs: `--input`, `--test-output`, `--task-list` as needed)

### 3.1 Output task-creation prompt (no LLM call)

- **Trigger:** `--project PATH --prompt TEXT` with no `--run`, or `--run prompt`.
- **Behaviour:** Build the **task-creation prompt** that would be sent to the LLM (same content as built in `Runner` for `task_creation_initial.md`). Output that prompt (e.g. system + user, or the two messages in a clear format) to stdout.
- **Implementation notes:** `Runner.task_creation()` is private. Either:
  - Add a public (or test-only) method on `Runner` that builds and returns the task-creation prompt (e.g. system and user strings, or a single formatted blob), given a user prompt and optional previous_proposal / previous_proposal_issues; or
  - In the example, construct `Skill.Factory` + `Runner` with a minimal `OLLMfiles.ProjectManager` (and session) set up so that `active_project` (or equivalent) reflects `--project`, then call a new method that exposes the prompt; or
  - Build the same prompt in the example using `Skill.PromptTemplate.template("task_creation_initial.md")` and the same `fill()` arguments as in `Runner.task_creation()`, using `Runner.env()` and factory’s `skill_manager`, after setting project on the project manager.
- **Output:** The exact prompt text the LLM would receive (so it can be pasted or replayed elsewhere).

### 3.2 Run task-creation prompt against a model

- **Trigger:** `--run prompt-run` with `--project` and `--prompt`. Optionally `--model ID`.
- **Behaviour:** Build the same task-creation prompt as in §3.1, send it to the selected **model** (from `--model` or config), and **print the raw LLM response** to stdout.
- **Implementation:** Reuse the prompt built as in §3.1; create a `Chat` (or equivalent) with the default connection/model, send the two messages (system, user), stream or wait for the response, print content.
- **Output:** Raw model output (e.g. markdown task list proposal).

### 3.3 Parse task-list output and print summary

- **Trigger:** `--run parse-tasklist` with `--test-output FILE`.
- **Behaviour:** Read **FILE** as the raw LLM task-list creation output (e.g. from a previous `--run prompt-run` run). Construct a `ResultParser` with a Runner (or minimal runner-like context) and this response string; call **`parse_task_list()`**. Then output a **summary** based on what is in the parser:
  - If `parser.issues != ""`: print issues.
  - If parse succeeded (`parser.issues == ""`), `runner.task_list` is populated; print a short summary of that list (e.g. number of steps; for each step, number of tasks and for each task: skill name, “What is needed” one-liner). Optionally print `parser.proposal` or section headings.
- **Implementation notes:** `ResultParser` needs a `Runner` to build `Details` and `List`. The example must have a way to construct a minimal Runner (Factory + session + project manager with `--project` set) so that `parse_task_list()` can run. The Runner does not need to perform any LLM calls for this mode.
- **Output:** Human-readable summary of the parsed task list and any validation issues.

### 3.3.1 Parse refinement output and print summary

- **Trigger:** `--run parse-refine` with `--test-output FILE` (refinement LLM output) and `--task-list FILE` (task list to resolve Details).
- **Behaviour:** Read the refinement file (`--test-output`) as the raw LLM refinement output (e.g. from a previous `--run refine` run). Load task list from `--task-list`; resolve detail at --step/--task-num. Parse refinement with `ResultParser` and `extract_refinement(detail)`. Print a summary (e.g. tool count, code_blocks count, any issues).
- **Output:** Human-readable summary of the parsed refinement and any issues.

### 3.3.2 Parse execute output and print summary

- **Trigger:** `--run parse-execute` with `--test-output FILE` (executor LLM output) and `--task-list FILE` (task list to resolve Details).
- **Behaviour:** Read the executor file (`--test-output`) as the raw LLM executor response. Load task list from `--task-list`; resolve detail at --step/--task-num. Use `ResultParser.extract_exec(detail)` to parse it. Print the results (e.g. `detail.result`, issues).
- **Output:** Human-readable summary of the parsed execution result and any issues.

### 3.4 Output refinement prompt for a given task

- **Trigger:** `--run refine-prompt` with optional `--step` (default 0) and `--task-num` (default 0). Default 0/0 = first step, first task.
- **Behaviour:** Output the **refinement prompt** (system + user messages) that would be sent to the LLM for that task. This is the content built in `Details.refine()` using `task_refinement.md` and the task’s coarse_task_markdown(), reference_contents(), etc.
- **State:** Task list must be **explicit**: `--input FILE` required (task list file). No implicit state from a prior run. Load from FILE, then resolve by `steps.get(step).children.get(task-num)` (bounds check).
- **Implementation notes:** `Details.refine()` does not expose the filled prompt. Either add a method on `Details` (or a test helper) that returns the refinement messages (system, user) without sending, or in the example build the same template fill using the task’s public data (coarse_task_markdown is private; task_data and reference_contents are used inside refine). Prefer exposing a “refinement prompt for this task” API on `Details` or Runner for clarity and single source of truth.
- **Output:** The exact refinement prompt (system + user) for that task.

### 3.5 Run refinement for a task

- **Trigger:** `--run refine` with optional `--step` and `--task-num` (default 0/0). **Requires `--input FILE`** (task list file); explicit, no implicit state.
- **Behaviour:** Build the refinement prompt for that task (as in §3.4), send it to the default model, and **print the LLM response** to stdout.
- **State:** Same as §3.4 (explicit `--input FILE`).
- **Output:** Raw refinement output (e.g. ## Task, ## Tool Calls, etc.).

### 3.6 Execute-task tools and output executor prompt

- **Trigger:** `--run execute-prompt` with `--step`/`--task-num` (default 0/0). **Requires `--input FILE`** (task list file). **Requires refinement applied to that task** (see State).
- **Behaviour:** For the **task at step/task-num** (one Details instance): run `Details.run_tools()` so `tool_outputs` and tool_calls are populated; then build the **executor prompt** (task_execution.md: query, skill_definition, precursor = reference_contents from task list + tool call/output blocks). Output that prompt to stdout.
- **State:** Execute operates on a **single task** (the one selected by step/task-num). That task must have **refinement applied**: it must have `tools` and `tool_calls` from the refinement LLM output (reference info and “What is needed” come from the **task list**; tool calls come from the **refinement output**). **Requires `--input` (task list) and `--input-refine FILE` (refinement output).** Load task list, resolve detail at step/task-num, parse refinement file with ResultParser, call `extract_refinement(detail)`, then run_tools and build executor prompt. No chaining — explicit file inputs only.
- **Output:** The exact executor prompt (system + user) that would be sent in `post_evaluate()`.

### 3.7 Run executor and show results

- **Trigger:** `--run execute` with `--step`/`--task-num`. **Requires `--input`** (task list) and **`--input-refine FILE`** (refinement output); same as §3.6.
- **Behaviour:** For that task: run_tools(), build executor prompt, send to LLM, parse response with `ResultParser.extract_exec(this)`, print results (e.g. task.result, result summary, issues).
- **State:** Same as §3.6: require `--input` and `--input-refine`; refinement applied via extract_refinement(detail); then tool_outputs set by run_tools().
- **Output:** Parsed result summary and any issues; optionally raw response.

---

## 4. Dependencies and wiring

- **Runner / Factory:** The example needs a way to obtain:
  - A `Skill.Factory` (or equivalent) with a `ProjectManager` that has `active_project` (or equivalent) set from `--project`.
  - A `Runner` instance (or a minimal stand-in) for:
    - Building task-creation prompt (§3.1, §3.2).
    - Passing to `ResultParser` for `parse_task_list()` (§3.3).
    - Building refinement and executor prompts if those are implemented via Runner/Details (§3.4–3.7).
- **Session / history:** Runner’s base expects a session. Use a minimal in-memory or no-op session for CLI.
- **Config / model:** Reuse the same config loading as other examples (e.g. `ApplicationInterface.base_load_config()`). For `--run prompt-run`, `--run refine`, and `--run execute`, use the model from `--model` when provided, otherwise the default model from config (as in `oc-test-cli`).

---

## 5. Optional: state file(s)

To make `--run refine-prompt`, `--run refine`, `--run execute-prompt`, and `--run execute` usable across invocations (e.g. save output of `--run prompt-run` to a file, then `--run parse-tasklist --input FILE`, then `--run refine-prompt` with default step/task-num), the app may support:

- Saving the last parsed `task_list` (or a serialized form) to a state file after parse-tasklist (which reads `--test-output`), and/or
- Loading task list and/or refined task from file(s) for later modes.

This is optional in v1; each mode uses explicit file inputs only. Execute (and execute-prompt) always take explicit files: `--input` (task list) and `--input-refine` (refinement output). No chaining — testable processes only.

---

## 6. Summary table

| Option / mode           | Purpose |
|-------------------------|--------|
| `--project PATH`        | Project path (required for prompt/refine/execute). |
| `--prompt TEXT`         | User prompt (required for prompt / prompt-run). |
| `--model ID`            | (Optional) Model for LLM calls; overrides default. |
| `--input FILE`          | Task list file. Required for refine-prompt, refine, execute-prompt, execute, iteration-prompt, iteration. |
| `--test-output FILE`    | LLM output file to parse. Required for parse-tasklist (task list creation output), parse-refine (refinement output), parse-execute (executor output). One option for all parse modes. |
| `--task-list FILE`      | Task list file. Required for parse-refine and parse-execute only; used with --step/--task-num to resolve the Details to pass to extract_refinement / extract_exec. (Parse-tasklist does not need it — it parses --test-output into a task list.) |
| `--input-refine FILE`   | Refinement output file. Required for execute-prompt and execute; parse and apply via extract_refinement(detail) to task at step/task-num. No chaining — explicit inputs only. |
| `--run MODE`            | Mode: prompt \| prompt-run \| parse-tasklist \| parse-refine \| parse-execute \| refine-prompt \| refine \| execute-prompt \| execute \| iteration-prompt \| iteration \| refine-all \| execute-all. |
| `--step N`              | Step index (default 0). Selects which task for refine and execute. |
| `--task-num N`          | Task index within step (default 0). Execute runs on this one task, which must have refinement (tool calls) applied. |

---

## 7. Implementation order

1. Add `oc-test-skill-agent` example skeleton (application class, `--project`, `--prompt`, `--model`, help).
2. Implement §3.1 (output task-creation prompt): add or use API to get task-creation prompt from Runner; wire to CLI.
3. Implement §3.2 (`--run-prompt`): reuse prompt from §3.1, call selected model (`--model` or default), print output.
4. Implement §3.3 (`--run parse-tasklist --test-output FILE`): minimal Runner + ProjectManager, read file, `parse_task_list()`, print summary. **Required before §3.4/§3.5** — refinement needs a parsed task list (or load from `--input`).
5. Implement §3.3.1 (`--run parse-refine`) and §3.3.2 (`--run parse-execute`): parse refinement/executor output from `--test-output FILE`; require `--task-list FILE` to resolve Details; print summary.
6. Implement §3.4 (`--run refine-prompt`): resolve task by --step/--task-num (default 0/0) from in-process state or `--input FILE`; add/use API to get refinement prompt; output it.
7. Implement §3.5 (`--run refine`): build refinement prompt for step/task-num, send to LLM, print response.
8. Implement §3.6 (`--run execute-prompt`): require `--input` (task list) and `--input-refine` (refinement output); parse refinement, extract_refinement(detail), run tools, build executor prompt, output it.
9. Implement §3.7 (`--run execute`): same inputs; send executor prompt, parse with `extract_exec`, print results.
10. Optional: state file(s) for cross-run persistence.
11. (Bundle 4) Implement `--run refine-all` and `--run execute-all`: iterate over all steps/tasks; same logic as single-task refine/execute per task.

---

## 9. Proposed changes by bundle

Proposed code; not in codebase until approved. Each bundle lists every affected file and change for that phase so it can be done in one go.

### Bundle 1: task_creation_prompt + remove open_files **(DONE)**

One method: `task_creation_prompt(..., skill_catalog, project_manager)`. Caller passes `OLLMcoder.Skill.Manager` and `OLLMfiles.ProjectManager`; method gets current file from project_manager (e.g. active_file, ensure buffer). No open_files. **Note:** The method is for testing; arguments are passed so the test can supply catalog and project manager without relying on runner/factory state.

**liboccoder/Skill/Runner.vala** — single method; remove private `task_creation()`:

```vala
public PromptTemplate task_creation_prompt(string user_prompt,
    string previous_proposal, string previous_proposal_issues,
    OLLMcoder.Skill.Manager skill_catalog, OLLMfiles.ProjectManager project_manager) throws GLib.Error
{
    var file = project_manager.active_file;
    if (file != null) {
        project_manager.buffer_provider.create_buffer(file);
    }
    var tpl = PromptTemplate.template("task_creation_initial.md");
    tpl.fill(
        "user_prompt", tpl.header_fenced("User Prompt", user_prompt, "text"),
        "environment", tpl.header_raw("Environment", this.env()),
        "project_description", (project_manager.active_project == null ?
            "" : project_manager.active_project.project_description()),
        "current_file", file == null ? "" : tpl.header_file("Current File - " + file.path, file),
        "previous_proposal", previous_proposal == "" ? "" :
            tpl.header_raw("Previous Proposal", previous_proposal),
        "previous_proposal_issues", previous_proposal_issues == "" ? "" :
            tpl.header_raw("Previous Proposal Issues", previous_proposal_issues),
        "skill_catalog", skill_catalog.to_markdown());
    tpl.system_fill("skill_catalog", skill_catalog.to_markdown());
    return tpl;
}
```

**liboccoder/Skill/Runner.vala** — `send_async()` loop body:

```vala
var tpl = this.task_creation_prompt(user_prompt, previous_proposal, previous_proposal_issues, this.sr_factory.skill_manager, this.sr_factory.project_manager);
this.user_request = tpl.user_to_document();
var messages = new Gee.ArrayList<OLLMchat.Message>();
messages.add(new OLLMchat.Message("system", tpl.filled_system));
messages.add(new OLLMchat.Message("user", tpl.filled_user));
// ... send, parse, etc.
```

**resources/skill-prompts/task_creation_initial.md** — remove this line:

```md
{open_files}
```

**examples/oc-test-skill-agent.vala** — build Runner then §3.1 / §3.2:

Build project_manager (DB, load projects, resolve project from `--project`, activate), then Factory + Runner:

```vala
var db_path = GLib.Path.build_filename(this.data_dir, "files.sqlite");
var db = new SQ.Database(db_path, false);
var project_manager = new OLLMfiles.ProjectManager(db);
yield project_manager.load_projects_from_db();

var project = project_manager.projects.path_map.get(opt_project);
if (project == null) {
    cl.printerr("Project not found: %s\n", opt_project);
    throw new GLib.IOError.NOT_FOUND("Project not found: " + opt_project);
}
yield project.load_files_from_db();
OLLMfiles.Folder.background_recurse = false;
yield project.read_dir(new GLib.DateTime.now_local().to_unix(), true);
project.project_files.update_from(project);
yield project_manager.activate_project(project);

var skills_dirs = new Gee.ArrayList<string>();
skills_dirs.add(GLib.Path.build_filename(GLib.Environment.get_home_dir(), "gitlive", "OLLMchat", "resources", "skills"));
var factory = new OLLMcoder.Skill.Factory(project_manager, skills_dirs, "");
var history_manager = new OLLMchat.History.Manager(this);
var session = new OLLMchat.History.EmptySession(history_manager);
var runner = (OLLMcoder.Skill.Runner) factory.create_agent(session);
```

§3.1 and §3.2 (use `runner` and `opt_prompt` from above):

```vala
// §3.1 (method gets current file from project_manager.active_file)
var tpl = runner.task_creation_prompt(opt_prompt, "", "", runner.sr_factory.skill_manager, runner.sr_factory.project_manager);
stdout.printf("=== system ===\n%s\n=== user ===\n%s\n", tpl.filled_system, tpl.filled_user);

// §3.2
var tpl = runner.task_creation_prompt(opt_prompt, "", "", runner.sr_factory.skill_manager, runner.sr_factory.project_manager);
var messages = new Gee.ArrayList<OLLMchat.Message>();
messages.add(new OLLMchat.Message("system", tpl.filled_system));
messages.add(new OLLMchat.Message("user", tpl.filled_user));
// send messages to model (--model or default), print response
```

### Bundle 2: refinement_prompt **(DONE)**

**Prerequisite:** Refinement (§3.4, §3.5) and execute (§3.6, §3.7) need a **parsed task list** (List + Details). Tests are **explicit**: `--run refine-prompt`, `--run refine`, `--run execute-prompt`, and `--run execute` all **require `--input FILE`** (task list file). No implicit state from a prior run; load task list from FILE in that mode. Refinement and execute use --step (default 0) and --task-num (default 0) for direct index access; no walking. Bundle 2 does not implement §3.3; it only adds the refinement_prompt API and template.

**Concrete code for §3.3 (`--run parse-tasklist --test-output FILE`)** — in `examples/oc-test-skill-agent.vala`, when mode is parse-tasklist call the shared helper with `opt_test_output` (the LLM output file to parse) then print summary:

```vala
// §3.3: parse tasklist file — load via helper, then print summary (helper throws on failure)
this.load_task_list(opt_test_output);  // opt_test_output = task list creation LLM output when --run parse-tasklist
var list = this.runner.task_list;
stdout.printf("Steps: %d\n", list.steps.size);
int task_index = 0;
foreach (var step in list.steps) {
    stdout.printf("  Step: %d tasks\n", step.children.size);
    foreach (var t in step.children) {
        task_index++;
        var skill = t.task_data.has_key("Skill") ?
            t.task_data.get("Skill").to_markdown().strip() : "";
        var needed = t.task_data.has_key("What is needed") ?
            t.task_data.get("What is needed").to_markdown().strip() : "";
        stdout.printf("    Task %d: skill=%s  What is needed: %s\n",
            task_index, skill, needed.replace("\n", " "));
    }
}
return;
```

**Shared helper** `load_task_list(string path)` — implement once; §3.3 and §3.4/§3.5 call it:

```vala
private void load_task_list(string path) throws GLib.Error
{
    if (path == "") {
        cl.printerr("Task list file path is empty.\n");
        throw new GLib.IOError.INVALID_ARGUMENT("Task list file path is empty");
    }
    if (!GLib.FileUtils.test(path, GLib.FileTest.EXISTS)) {
        cl.printerr("File not found: %s\n", path);
        throw new GLib.IOError.NOT_FOUND("File not found: " + path);
    }
    string content;
    GLib.FileUtils.get_contents(path, out content);
    var parser = new OLLMcoder.Task.ResultParser(this.runner, content);
    parser.parse_task_list();
    if (parser.issues != "") {
        cl.printerr("Parse issues: %s\n", parser.issues);
        throw new GLib.IOError.INVALID_ARGUMENT(parser.issues);
    }
}
```

(§3.3 runs when `--run parse-tasklist`; `--test-output FILE` is required, so opt_test_output is set.)

Runner must already be built (same as §3.1/§3.2). Refinement and execute are explicit: they require `--input FILE` (and execute requires `--input-refine FILE`); load from files in that run. No chaining — testable processes only.

**Shared helper (no duplication):** Use one helper for “load task list from file” so §3.3 and §3.4/§3.5 don’t duplicate read+parse. Helper: given path (non-null), error if path is "" or file !FileUtils.test(EXISTS); get_contents; ResultParser(runner, content); parse_task_list(); on parser.issues non-empty throw (or return issues to caller); otherwise runner.task_list is set. §3.3: call helper, then if runner.task_list != null print summary. §3.4/§3.5: require `--input FILE`; call same helper (path = opt_input). No implicit state.

**liboccoder/Task/Details.vala**

Refinement prompt: no current_file placeholder — reference_contents already includes current file when in the task's References.

```vala
public OLLMcoder.Skill.PromptTemplate refinement_prompt() throws GLib.Error
{
    var definition = this.skill_manager.fetch(this);
    var tpl = OLLMcoder.Skill.PromptTemplate.template("task_refinement.md");
    tpl.system_fill(); // needed to fill in filled_system
    tpl.fill(
        "issues", tpl.header_raw("Issues with the current call", this.result_parser.issues),
        "task_data", tpl.header_raw("Task", this.to_markdown(MarkdownPhase.REFINEMENT)),
        "environment", this.runner.env(),
        "project_description", (this.runner.sr_factory.project_manager.active_project == null ?
            "" : this.runner.sr_factory.project_manager.active_project.project_description()),
        "task_reference_contents", this.reference_contents(),
        "skill_details", definition.full_content);
    return tpl;
}
```

**liboccoder/Task/Details.vala** — in `refine()`, replace the fill (no current_file):

```vala
tpl.fill(
    "issues", tpl.header_raw("Issues with the current call", this.result_parser.issues),
    "task_data", tpl.header_raw("Task", this.to_markdown(MarkdownPhase.REFINEMENT)),
    "environment", this.runner.env(),
    "project_description", (this.runner.sr_factory.project_manager.active_project == null ?
        "" : this.runner.sr_factory.project_manager.active_project.project_description()),
    "task_reference_contents", this.reference_contents(),
    "skill_details", definition.full_content);
```

**resources/skill-prompts/task_creation_initial.md** — add (e.g. in Reference link types or Output format):

```md
If a task needs the current (open) document, add a reference to it in that task's References using the standard link format (e.g. [Basename](/absolute/path/to/file)).
```

**examples/oc-test-skill-agent.vala** — §3.4 and §3.5: **explicit** only. `--run refine-prompt` and `--run refine` **require `--input FILE`** (task list file). No implicit state. Build runner, load task list from `opt_input`, then resolve by `--step`/`--task-num` (default 0/0).

```vala
// Explicit: --input FILE required for refine-prompt / refine
if (opt_input == null || opt_input == "") {
    throw new GLib.IOError.INVALID_ARGUMENT("--run refine-prompt / refine requires --input FILE (task list)");
}
this.load_task_list(opt_input);

// Resolve task by step/task-num (default 0/0 = first step, first task)
var list = this.runner.task_list;
if (opt_step < 0 || opt_step >= list.steps.size) {
    cl.printerr("Step %d out of range (0..%d).\n", opt_step, list.steps.size - 1);
    throw new GLib.IOError.NOT_FOUND("Step out of range");
}
var step = list.steps.get(opt_step);
if (opt_task_num < 0 || opt_task_num >= step.children.size) {
    cl.printerr("Task %d out of range (0..%d).\n", opt_task_num, step.children.size - 1);
    throw new GLib.IOError.NOT_FOUND("Task out of range");
}
var detail = step.children.get(opt_task_num);

// §3.4 --run refine-prompt: output refinement prompt only
var tpl = detail.refinement_prompt();
stdout.printf("=== system ===\n%s\n=== user ===\n%s\n", tpl.filled_system, tpl.filled_user);

// §3.5 --run refine: build same prompt, send to model, print response
var tpl = detail.refinement_prompt();
var messages = new Gee.ArrayList<OLLMchat.Message>();
messages.add(new OLLMchat.Message("system", tpl.filled_system));
messages.add(new OLLMchat.Message("user", tpl.filled_user));
var response_obj = yield this.runner.chat().send(messages, null);
stdout.printf("%s", response_obj != null && response_obj.message != null ? response_obj.message.content ?? "" : "");
```

### Bundle 3: executor_prompt **(DONE)**

**liboccoder/Task/Details.vala**

```vala
public OLLMcoder.Skill.PromptTemplate executor_prompt() throws GLib.Error
{
    var definition = this.skill_manager.fetch(this);
    var tpl = OLLMcoder.Skill.PromptTemplate.template("task_execution.md");
    tpl.system_fill();
    tpl.fill(
        "query", this.task_data.get("What is needed").to_markdown(),
        "skill_definition", definition.full_content,
        "precursor", this.executor_precursor());
    return tpl;
}
```

**examples/oc-test-skill-agent.vala** — §3.6 and §3.7:

```vala
// §3.6 --execute-task: for task N
yield detail.run_tools();
var tpl = detail.executor_prompt();
stdout.printf("=== system ===\n%s\n=== user ===\n%s\n", tpl.filled_system, tpl.filled_user);

// §3.7 --run-execute-task: same then send to model
yield detail.run_tools();
var tpl = detail.executor_prompt();
// send (system, user) to model; parse response with result_parser.extract_exec(detail); print results
```

**Bundle 3 review:** Concrete code above is complete and ready for review. In `oc-test-skill-agent`, execute-prompt and execute operate on **one task** (step/task-num). No chaining: require `--input` (task list) and `--input-refine FILE` (refinement output). Load task list, resolve detail, parse refinement file and call `extract_refinement(detail)`, then `detail.run_tools()`, `detail.executor_prompt()`, and (for execute) send + `result_parser.extract_exec(detail)`.

**Remaining to complete the test tool:**
- §3.3.1 `--run parse-refine` and §3.3.2 `--run parse-execute`: specified in §3 and implementation order step 5; proposed as Bundle 5 below.
- **Task list iteration:** The step that **updates the plan with execution results** and gets from the LLM either a **new set of tasks** or a **final report** (goals complete). Proposed as Bundle 4 below.

### Bundle 4: Task list iteration (plan updated with results → new tasks or report)

**What iteration is:** After a round of task execution, the Runner sends the **current task list** (with completed tasks’ outputs in the precursor) to the LLM using **task_list_iteration.md**. The LLM either (1) returns the **same list** (goals complete; effectively a report/done) or (2) returns a **revised task list with new tasks** (more work needed). So the plan is **updated with the results**; the output is **new tasks or just report**. Implementation of the iteration step itself is in 1.23.18 §7 (`run_task_list_iteration()` in Runner). Bundle 4 here is about **making that step testable** in the test tool.

**Goal:** Test the iteration step in isolation: build the iteration prompt from a task list (with optional completed outputs), and either output that prompt or send it and print the parsed result (new task list or unchanged list / report).

- **Modes:** `--run iteration-prompt` (output the iteration prompt; no LLM call), `--run iteration` (build prompt, send to LLM, parse_task_list(), print summary of the new list or report).
- **Trigger:** `--run iteration-prompt` or `--run iteration` with `--input FILE` (task list file). The task list should reflect “after execution”: tasks that have run should have **Output** (and optionally exec_done/result) so the iteration prompt includes “outputs from completed tasks”. For the test tool, that means either (a) the file is the output of a previous parse-tasklist run where the user has manually added `**Output** …` lines to completed tasks, or (b) we add a separate input for “completed outputs” (e.g. a file or directory of result summaries) that the test tool injects into the precursor. TBD: minimal convention so the test tool can build a valid iteration prompt without running the full pipeline.
- **Behaviour:** Load task list from `--input`. Build the iteration prompt as in Runner.run_task_list_iteration() (see 1.23.18 §7): current_task_list = list.to_markdown(), precursor_with_completed_outputs from tasks that have result/output, fill task_list_iteration.md. iteration-prompt: print system + user. iteration: send, parse_task_list(), if parser.issues print issues; else print summary of runner.task_list (e.g. steps/tasks count, goals_summary if present) or “unchanged / no new tasks” vs “new tasks: …”.
- **Dependency:** Runner exposes a method that builds the iteration prompt from **this.task_list** (no list argument); run_task_list_iteration() and the test tool both call it.

**Concrete code — not in codebase until approved.**

**liboccoder/Skill/Runner.vala** — add method before `run_task_list_iteration()`:

```vala
/**
 * Build the task list iteration prompt (task_list_iteration.md) from this.task_list.
 * Current task list = this.task_list.to_markdown(). Used by run_task_list_iteration() and by the test CLI.
 */
public PromptTemplate iteration_prompt(string previous_proposal_issues = "") throws GLib.Error
{
    var tpl = PromptTemplate.template("task_list_iteration.md");
    tpl.system_fill("skill_catalog", this.sr_factory.skill_manager.to_markdown());

    tpl.fill(
        "current_task_list", this.task_list.to_markdown(),
        "environment", tpl.header_raw("Environment", this.env()),
        "project_description", this.sr_factory.project_manager.active_project == null ? "" :
            this.sr_factory.project_manager.active_project.project_description(),
        "previous_proposal_issues", previous_proposal_issues == "" ? "" :
            tpl.header_raw("Issues with the tasks", previous_proposal_issues));
    return tpl;
}
```

**liboccoder/Skill/Runner.vala** — replace stub `run_task_list_iteration()` with:

```vala
/** Task list iteration: send current list to LLM, parse response; this.task_list is replaced by parse_task_list() on success. Up to 5 retries with previous_proposal_issues. On parse failure parser sets this.task_list = null; restore from saved ref so next iteration_prompt() has a list. */
public async void run_task_list_iteration() throws GLib.Error
{
    if (this.task_list == null) {
        return;
    }
    var previous_proposal_issues = "";
    for (var try_count = 0; try_count < 5; try_count++) {
        var saved_list = this.task_list;
        var tpl = this.iteration_prompt(previous_proposal_issues);
        var messages = new Gee.ArrayList<OLLMchat.Message>();
        messages.add(new OLLMchat.Message("system", tpl.filled_system));
        messages.add(new OLLMchat.Message("user", tpl.filled_user));
        var response_obj = yield this.chat_call.send(messages, null);
        var response = response_obj != null ? response_obj.message.content : "";
        var parser = new OLLMcoder.Task.ResultParser(this, response);
        parser.parse_task_list();
        if (parser.issues != "") {
            previous_proposal_issues = parser.issues;
            this.task_list = saved_list;
            continue;
        }
        var skill_issues = this.task_list.validate_skills();
        if (skill_issues == "") {
            return;
        }
        previous_proposal_issues = skill_issues;
    }
    this.add_message(new OLLMchat.Message("ui", "Task list iteration: could not get valid task list after 5 tries."));
}
```

**examples/oc-test-skill-agent.vala** — add to `--run` option help: `|iteration-prompt|iteration`. Add two cases:

```vala
case "iteration-prompt":
case "iteration": {
    if (opt_input == null || opt_input == "") {
        throw new GLib.IOError.INVALID_ARGUMENT("--run iteration-prompt / iteration requires --input FILE (task list)");
    }
    yield this.build_runner();
    this.load_task_list(opt_input);
    var tpl = this.runner.iteration_prompt("");
    if (opt_run == "iteration-prompt") {
        stdout.printf("=== system ===\n%s\n=== user ===\n%s\n", tpl.filled_system, tpl.filled_user);
        return;
    }
    var messages = new Gee.ArrayList<OLLMchat.Message>();
    messages.add(new OLLMchat.Message("system", tpl.filled_system));
    messages.add(new OLLMchat.Message("user", tpl.filled_user));
    var response_obj = yield this.runner.chat().send(messages, null);
    var response_text = response_obj != null && response_obj.message != null ? response_obj.message.content ?? "" : "";
    var result_parser = new OLLMcoder.Task.ResultParser(this.runner, response_text);
    result_parser.parse_task_list();
    if (result_parser.issues != "") {
        this.cl.printerr("Iteration parse issues: %s\n", result_parser.issues);
        return;
    }
    var new_list = this.runner.task_list;
    stdout.printf("Steps: %d\n", (int) new_list.steps.size);
    int task_count = 0;
    foreach (var step in new_list.steps) {
        task_count += (int) step.children.size;
    }
    stdout.printf("Tasks: %d\n", task_count);
    if (new_list.goals_summary_md != "") {
        stdout.printf("Goals summary: %s\n", new_list.goals_summary_md.strip().replace("\n", " "));
    }
    stdout.printf("%s", response_text);
    return;
}
```

### ResultParser

No changes. Test app uses existing parse_task_list(), extract_refinement(), extract_exec() with minimal Runner/Details.

### Bundle 5: Parse refinement and parse execute (§3.3.1, §3.3.2)

**Scope:** Implement the two remaining parse modes so refinement output and executor output can be parsed and summarized from a file without running the full refine/execute flow.

**Dependency:** Both modes need a **Details** (for `extract_refinement(detail)` and `extract_exec(detail)`), so both require a task list plus `--step` / `--task-num` to resolve the task. Use a second file input for the content to parse.

**Options:** `--test-output FILE` = LLM output file to parse (used by parse-tasklist, parse-refine, parse-execute). `--task-list FILE` = task list file; required only for parse-refine and parse-execute (to resolve Details at --step/--task-num). Parse-tasklist only needs `--test-output` (task list creation LLM output).

**parse-refine (§3.3.1):**
- **Trigger:** `--run parse-refine` with `--test-output FILE` (refinement LLM output), `--task-list FILE` (task list), `--project`, `--step` (default 0), `--task-num` (default 0).
- **Behaviour:** Build runner, `load_task_list(opt_task_list)`, resolve detail from step/task-num (bounds check). Read `--test-output` file, `ResultParser(runner, content)`, `parser.extract_refinement(detail)`. Print summary: e.g. tool count, code_blocks count, any `parser.issues`.
- **Output:** Human-readable summary of the parsed refinement and any issues.

**parse-execute (§3.3.2):**
- **Trigger:** `--run parse-execute` with `--test-output FILE` (executor LLM output), `--task-list FILE` (task list), `--project`, `--step` (default 0), `--task-num` (default 0).
- **Behaviour:** Build runner, `load_task_list(opt_task_list)`, resolve detail from step/task-num (bounds check). Read `--test-output` file, `ResultParser(runner, content)`, `parser.extract_exec(detail)`. Print `detail.result` and any `parser.issues`.
- **Output:** Human-readable summary of the parsed execution result and any issues.

**Concrete code — not in codebase until approved.**

**examples/oc-test-skill-agent.vala** — add statics and options, reset in command_line:

```vala
// With other statics:
private static string? opt_test_output = null;
private static string? opt_task_list = null;

// In options array (e.g. after input-refine):
{ "test-output", 0, 0, GLib.OptionArg.FILENAME, ref opt_test_output,
    "LLM output file to parse (parse-tasklist: task list creation; parse-refine: refinement; parse-execute: executor)", "FILE" },
{ "task-list", 0, 0, GLib.OptionArg.FILENAME, ref opt_task_list,
    "Task list file (required for parse-refine and parse-execute)", "FILE" },

// In command_line(), with other resets:
opt_test_output = null;
opt_task_list = null;
```

- **parse-tasklist:** Require `--test-output FILE`; call `load_task_list(opt_test_output)` (that file is the task list creation LLM output). No `--task-list` (parse-tasklist produces the task list from the file).
- **parse-refine / parse-execute:** Require `--test-output FILE` (refinement or executor LLM output) and `--task-list FILE` (task list); use `opt_test_output` for the file to parse, `opt_task_list` for `load_task_list()`.

**examples/oc-test-skill-agent.vala** — replace the "Not implemented" stubs for `parse-refine` and `parse-execute` with:

```vala
case "parse-refine": {
    if (opt_test_output == null || opt_test_output == "") {
        throw new GLib.IOError.INVALID_ARGUMENT("--run parse-refine requires --test-output FILE (refinement LLM output)");
    }
    if (!GLib.FileUtils.test(opt_test_output, GLib.FileTest.EXISTS)) {
        this.cl.printerr("Refinement file not found: %s\n", opt_test_output);
        throw new GLib.IOError.NOT_FOUND("File not found: " + opt_test_output);
    }
    if (opt_task_list == null || opt_task_list == "") {
        throw new GLib.IOError.INVALID_ARGUMENT("--run parse-refine requires --task-list FILE (task list)");
    }
    yield this.build_runner();
    this.load_task_list(opt_task_list);
    var list = this.runner.task_list;
    if (opt_step < 0 || opt_step >= (int) list.steps.size) {
        this.cl.printerr("Step %d out of range (0..%d).\n", opt_step, (int) list.steps.size - 1);
        throw new GLib.IOError.NOT_FOUND("Step out of range");
    }
    var step = list.steps.get(opt_step);
    if (opt_task_num < 0 || opt_task_num >= (int) step.children.size) {
        this.cl.printerr("Task %d out of range (0..%d).\n", opt_task_num, (int) step.children.size - 1);
        throw new GLib.IOError.NOT_FOUND("Task out of range");
    }
    var detail = step.children.get(opt_task_num);
    string content;
    GLib.FileUtils.get_contents(opt_test_output, out content);
    var parser = new OLLMcoder.Task.ResultParser(this.runner, content);
    parser.extract_refinement(detail);
    if (parser.issues != "") {
        this.cl.printerr("Refinement parse issues: %s\n", parser.issues);
    }
    stdout.printf("Tools: %d\n", (int) detail.tools.size);
    stdout.printf("Code blocks: %d\n", (int) detail.code_blocks.size);
    return;
}
case "parse-execute": {
    if (opt_test_output == null || opt_test_output == "") {
        throw new GLib.IOError.INVALID_ARGUMENT("--run parse-execute requires --test-output FILE (executor LLM output)");
    }
    if (!GLib.FileUtils.test(opt_test_output, GLib.FileTest.EXISTS)) {
        this.cl.printerr("Executor output file not found: %s\n", opt_test_output);
        throw new GLib.IOError.NOT_FOUND("File not found: " + opt_test_output);
    }
    if (opt_task_list == null || opt_task_list == "") {
        throw new GLib.IOError.INVALID_ARGUMENT("--run parse-execute requires --task-list FILE (task list)");
    }
    yield this.build_runner();
    this.load_task_list(opt_task_list);
    var list = this.runner.task_list;
    if (opt_step < 0 || opt_step >= (int) list.steps.size) {
        this.cl.printerr("Step %d out of range (0..%d).\n", opt_step, (int) list.steps.size - 1);
        throw new GLib.IOError.NOT_FOUND("Step out of range");
    }
    var step = list.steps.get(opt_step);
    if (opt_task_num < 0 || opt_task_num >= (int) step.children.size) {
        this.cl.printerr("Task %d out of range (0..%d).\n", opt_task_num, (int) step.children.size - 1);
        throw new GLib.IOError.NOT_FOUND("Task out of range");
    }
    var detail = step.children.get(opt_task_num);
    string content;
    GLib.FileUtils.get_contents(opt_test_output, out content);
    var parser = new OLLMcoder.Task.ResultParser(this.runner, content);
    parser.extract_exec(detail);
    if (parser.issues != "") {
        this.cl.printerr("Executor parse issues: %s\n", parser.issues);
    }
    if (detail.result != "") {
        stdout.printf("%s", detail.result);
    }
    return;
}
```

---

## 10. Out of scope

- Changing the design of prompts or of Runner/Details/ResultParser beyond adding small test-friendly accessors (e.g. “get prompt for this stage”).
- Full end-to-end automation of the whole agent in this example; the goal is **testable usage** of each stage, not a single “run everything” command (that remains the normal app flow).
