# 1.23.19 Testable usage of the agent flow

**Parent:** 1.23.x (skills agent). **Source:** Request for a CLI that exercises each stage of the agent flow in isolation.

**Coding standards:** All proposed and implemented code must follow `.cursor/rules/CODING_STANDARDS.md`. Before marking ready, verify: nullable types, null checks, no `@"..."` except multi-line/help, no one-use temporaries/trivial aliases, brace style (line break for class/method, inline for if/for; no one-line if with body), `this.` for instance members, full `GLib.*` and no `using`, property defaults not constructor init, line breaking for long calls, no StringBuilder except hundreds-of-iterations loops, no string build in loops, `string[] name = {}` not `new string[0]`, loops use `continue` not else/nesting, no character looping (prefer string methods/regex), file try/catch only when existence unknown, minimal try/catch scope, no leading underscore, no `get_*()` — use properties or verb-less names (e.g. `refinement_prompt()` not `get_refinement_prompt()`).

**Plan focus:** Concrete code only. No sentences.

---

## 1. Objective

Create a new example application **oc-test-skill-agent** that extends the standard application (like other examples) and provides **testable, step-by-step usage** of the skills agent flow. Each stage can be run independently so prompts and outputs can be inspected without running the full pipeline.

---

## 2. Application shape

- **Name:** `oc-test-skill-agent`
- **Extends:** Standard application pattern — e.g. `Application` + `OLLMchat.ApplicationInterface` (like `oc-test-cli`) or `TestAppBase` (like `oc-test-gtkmd`). Prefer the same pattern as other examples that need config and CLI (e.g. TestAppBase for shared debug/url/model options).
- **Build:** Add executable in `examples/meson.build` and wire into root `meson.build` run targets if appropriate.
- **Inputs:** Rationalized CLI:
  - `--project PATH`, `--prompt TEXT`, `--model ID` — project, user prompt, optional model override.
  - `--input FILE` — single option for any file input: task-list file (for parse-tasklist or as task list for refine/execute), refinement output (parse-refine), or executor output (parse-execute). Required when the chosen mode needs a file.
  - `--run MODE` — one of: prompt, prompt-run, parse-tasklist, parse-refine, parse-execute, refine-prompt, refine, execute-prompt, execute. Reduces many boolean/file options to one mode selector.
  - `--step N`, `--task-num N` — step/task indices (default 0) for refine and execute modes.

---

## 3. Modes (keyed by `--run MODE` and `--input FILE`)

### 3.1 Output task-creation prompt (no LLM call)

- **Trigger:** `--project PATH --prompt TEXT` with no `--run`, or `--run prompt`.
- **Behaviour:** Build the **task-creation prompt** that would be sent to the LLM (same content as built in `Runner` for `task_creation_initial.md`). Output that prompt (e.g. system + user, or the two messages in a clear format) to stdout.
- **Implementation notes:** `Runner.task_creation()` is private. Either:
  - Add a public (or test-only) method on `Runner` that builds and returns the task-creation prompt (e.g. system and user strings, or a single formatted blob), given a user prompt and optional previous_proposal / previous_proposal_issues; or
  - In the example, construct `Skill.Factory` + `Runner` with a minimal `OLLMfiles.ProjectManager` (and session) set up so that `active_project` (or equivalent) reflects `--project`, then call a new method that exposes the prompt; or
  - Build the same prompt in the example using `Skill.PromptTemplate.template("task_creation_initial.md")` and the same `fill()` arguments as in `Runner.task_creation()`, using `Runner.env()` and factory’s `skill_manager`, after setting project on the project manager.
- **Output:** The exact prompt text the LLM would receive (so it can be pasted or replayed elsewhere).

### 3.2 Run task-creation prompt against a model

- **Trigger:** `--run prompt-run` with `--project` and `--prompt`. Optionally `--model ID`.
- **Behaviour:** Build the same task-creation prompt as in §3.1, send it to the selected **model** (from `--model` or config), and **print the raw LLM response** to stdout.
- **Implementation:** Reuse the prompt built as in §3.1; create a `Chat` (or equivalent) with the default connection/model, send the two messages (system, user), stream or wait for the response, print content.
- **Output:** Raw model output (e.g. markdown task list proposal).

### 3.3 Parse task-list output and print summary

- **Trigger:** `--run parse-tasklist` with `--input FILE`.
- **Behaviour:** Read **FILE** as the raw LLM task-list output (e.g. from a previous `--run prompt-run` run). Construct a `ResultParser` with a Runner (or minimal runner-like context) and this response string; call **`parse_task_list()`**. Then output a **summary** based on what is in the parser:
  - If `parser.issues != ""`: print issues.
  - If `parser.task_list != null`: print a short summary of the task list (e.g. number of steps; for each step, number of tasks and for each task: skill name, “What is needed” one-liner). Optionally print `parser.proposal` or section headings.
- **Implementation notes:** `ResultParser` needs a `Runner` to build `Details` and `List`. The example must have a way to construct a minimal Runner (Factory + session + project manager with `--project` set) so that `parse_task_list()` can run. The Runner does not need to perform any LLM calls for this mode.
- **Output:** Human-readable summary of the parsed task list and any validation issues.

### 3.3.1 Parse refinement output and print summary

- **Trigger:** `--run parse-refine` with `--input FILE`.
- **Behaviour:** Read FILE as the raw LLM refinement output (e.g. from a previous `--run refine` run). Parse it in the same way refinement results are processed (e.g. with `ResultParser` or the logic used to extract refinement for a task). Print a summary (e.g. extracted sections, tool calls, any issues).
- **Output:** Human-readable summary of the parsed refinement and any issues.

### 3.3.2 Parse execute output and print summary

- **Trigger:** `--run parse-execute` with `--input FILE`.
- **Behaviour:** Read FILE as the raw LLM executor response. Use `ResultParser.extract_exec()` (with a suitable task/Details context) to parse it. Print the results (e.g. `task.result`, result summary, issues).
- **Output:** Human-readable summary of the parsed execution result and any issues.

### 3.4 Output refinement prompt for a given task

- **Trigger:** `--run refine-prompt` with optional `--step` (default 0) and `--task-num` (default 0). Default 0/0 = first step, first task.
- **Behaviour:** Output the **refinement prompt** (system + user messages) that would be sent to the LLM for that task. This is the content built in `Details.refine()` using `task_refinement.md` and the task’s coarse_task_markdown(), reference_contents(), etc.
- **State:** Task list must be **explicit**: `--input FILE` required (task list file). No implicit state from a prior run. Load from FILE, then resolve by `steps.get(step).children.get(task-num)` (bounds check).
- **Implementation notes:** `Details.refine()` does not expose the filled prompt. Either add a method on `Details` (or a test helper) that returns the refinement messages (system, user) without sending, or in the example build the same template fill using the task’s public data (coarse_task_markdown is private; task_data and reference_contents are used inside refine). Prefer exposing a “refinement prompt for this task” API on `Details` or Runner for clarity and single source of truth.
- **Output:** The exact refinement prompt (system + user) for that task.

### 3.5 Run refinement for a task

- **Trigger:** `--run refine` with optional `--step` and `--task-num` (default 0/0). **Requires `--input FILE`** (task list file); explicit, no implicit state.
- **Behaviour:** Build the refinement prompt for that task (as in §3.4), send it to the default model, and **print the LLM response** to stdout.
- **State:** Same as §3.4 (explicit `--input FILE`).
- **Output:** Raw refinement output (e.g. ## Task, ## Tool Calls, etc.).

### 3.6 Execute-task tools and output executor prompt

- **Trigger:** `--run execute-prompt` with `--step`/`--task-num` (default 0/0). **Requires `--input FILE`** (task list file); explicit, as in §3.4.
- **Behaviour:** For the task at step/task-num:
  - Run the **execute-task tools** (tool calls) for that task — i.e. `Details.run_tools()` so that `tool_outputs` (and tool_calls) are populated.
  - Then build the **executor prompt** (the prompt that would be sent to the LLM in `Details.post_evaluate()`: `task_execution.md` filled with query, skill_definition, precursor = reference_contents + tool call/output blocks).
  - Output that executor prompt to stdout.
- **State:** The task must already be **refined** (have tools and optionally tool_calls). So either:
  - Refinement was run earlier (e.g. `--run refine`) and the task’s refinement result was applied (e.g. `extract_refinement`), and we run tools then build executor prompt; or
  - State is loaded from file(s): e.g. task list from one file, refined task N from another file, and we run tools (which may need a real tool implementation or stub) then output executor prompt.
- **Implementation notes:** If tools have side effects (e.g. read file, run command), the example may use the real tool implementations or a stub that returns fixed output for testing. The plan does not require changing tool semantics; only that “run tools” and “output executor prompt” are both possible.
- **Output:** The exact executor prompt (system + user) that would be sent in `post_evaluate()`.

### 3.7 Run executor and show results

- **Trigger:** `--run execute` with `--step`/`--task-num`. **Requires `--input FILE`** (task list file); explicit, as in §3.4.
- **Behaviour:** For that task: call the LLM with the **executor prompt** (as in `Details.post_evaluate()`), then parse the response with `ResultParser.extract_exec(this)` and **print the results** (e.g. `task.result`, “Result summary” content, and/or full response).
- **State:** Task must have tools run and tool_outputs set (as after §3.6). Executor prompt is built and sent; response is parsed and summarized.
- **Output:** Parsed result summary and any issues; optionally raw response.

---

## 4. Dependencies and wiring

- **Runner / Factory:** The example needs a way to obtain:
  - A `Skill.Factory` (or equivalent) with a `ProjectManager` that has `active_project` (or equivalent) set from `--project`.
  - A `Runner` instance (or a minimal stand-in) for:
    - Building task-creation prompt (§3.1, §3.2).
    - Passing to `ResultParser` for `parse_task_list()` (§3.3).
    - Building refinement and executor prompts if those are implemented via Runner/Details (§3.4–3.7).
- **Session / history:** Runner’s base expects a session. Use a minimal in-memory or no-op session for CLI.
- **Config / model:** Reuse the same config loading as other examples (e.g. `ApplicationInterface.base_load_config()`). For `--run prompt-run`, `--run refine`, and `--run execute`, use the model from `--model` when provided, otherwise the default model from config (as in `oc-test-cli`).

---

## 5. Optional: state file(s)

To make `--run refine-prompt`, `--run refine`, `--run execute-prompt`, and `--run execute` usable across invocations (e.g. save output of `--run prompt-run` to a file, then `--run parse-tasklist --input FILE`, then `--run refine-prompt` with default step/task-num), the app may support:

- Saving the last parsed `task_list` (or a serialized form) to a state file after parse-tasklist, and/or
- Loading task list and/or refined task from file(s) for later modes.

This is optional in v1; the plan can require “run in one process” (e.g. `--run-prompt` then `--parse-tasklist -` reading stdin, then `--refine-task` with default step/task-num) and add file-based state in a follow-up.

---

## 6. Summary table

| Option / mode           | Purpose |
|-------------------------|--------|
| `--project PATH`        | Project path (required for prompt/refine/execute). |
| `--prompt TEXT`         | User prompt (required for prompt / prompt-run). |
| `--model ID`            | (Optional) Model for LLM calls; overrides default. |
| `--input FILE`          | Input file: task list (parse-tasklist or for refine/execute), refinement output (parse-refine), or executor output (parse-execute). Required when mode needs a file. |
| `--run MODE`            | Mode: prompt \| prompt-run \| parse-tasklist \| parse-refine \| parse-execute \| refine-prompt \| refine \| execute-prompt \| execute. |
| `--step N`              | Step index (default 0). For refine and execute modes. |
| `--task-num N`          | Task index within step (default 0). For refine and execute modes. |

---

## 7. Implementation order

1. Add `oc-test-skill-agent` example skeleton (application class, `--project`, `--prompt`, `--model`, help).
2. Implement §3.1 (output task-creation prompt): add or use API to get task-creation prompt from Runner; wire to CLI.
3. Implement §3.2 (`--run-prompt`): reuse prompt from §3.1, call selected model (`--model` or default), print output.
4. Implement §3.3 (`--run parse-tasklist --input FILE`): minimal Runner + ProjectManager, read file, `parse_task_list()`, print summary. **Required before §3.4/§3.5** — refinement needs a parsed task list (or load from `--input`).
5. Implement §3.3.1 (`--run parse-refine`) and §3.3.2 (`--run parse-execute`): parse refinement/executor output from `--input FILE`, print summary.
6. Implement §3.4 (`--run refine-prompt`): resolve task by --step/--task-num (default 0/0) from in-process state or `--input FILE`; add/use API to get refinement prompt; output it.
7. Implement §3.5 (`--run refine`): build refinement prompt for step/task-num, send to LLM, print response.
8. Implement §3.6 (`--run execute-prompt`): run tools for task, build executor prompt, output it.
9. Implement §3.7 (`--run execute`): send executor prompt, parse with `extract_exec`, print results.
10. Optional: state file(s) for cross-run persistence.

---

## 9. Proposed changes by bundle

Proposed code; not in codebase until approved. Each bundle lists every affected file and change for that phase so it can be done in one go.

### Bundle 1: task_creation_prompt + remove open_files

One method: `task_creation_prompt(..., skill_catalog, project_manager)`. Caller passes `OLLMcoder.Skill.Manager` and `OLLMfiles.ProjectManager`; method gets current file from project_manager (e.g. active_file, ensure buffer). No open_files. **Note:** The method is for testing; arguments are passed so the test can supply catalog and project manager without relying on runner/factory state.

**liboccoder/Skill/Runner.vala** — single method; remove private `task_creation()`:

```vala
public PromptTemplate task_creation_prompt(string user_prompt,
    string previous_proposal, string previous_proposal_issues,
    OLLMcoder.Skill.Manager skill_catalog, OLLMfiles.ProjectManager project_manager) throws GLib.Error
{
    var file = project_manager.active_file;
    if (file != null) {
        project_manager.buffer_provider.create_buffer(file);
    }
    var tpl = PromptTemplate.template("task_creation_initial.md");
    tpl.fill(
        "user_prompt", tpl.header_fenced("User Prompt", user_prompt, "text"),
        "environment", tpl.header_raw("Environment", this.env()),
        "project_description", (project_manager.active_project == null ?
            "" : project_manager.active_project.project_description()),
        "current_file", file == null ? "" : tpl.header_file("Current File - " + file.path, file),
        "previous_proposal", previous_proposal == "" ? "" :
            tpl.header_raw("Previous Proposal", previous_proposal),
        "previous_proposal_issues", previous_proposal_issues == "" ? "" :
            tpl.header_raw("Previous Proposal Issues", previous_proposal_issues),
        "skill_catalog", skill_catalog.to_markdown());
    tpl.system_fill("skill_catalog", skill_catalog.to_markdown());
    return tpl;
}
```

**liboccoder/Skill/Runner.vala** — `send_async()` loop body:

```vala
var tpl = this.task_creation_prompt(user_prompt, previous_proposal, previous_proposal_issues, this.sr_factory.skill_manager, this.sr_factory.project_manager);
this.user_request = tpl.user_to_document();
var messages = new Gee.ArrayList<OLLMchat.Message>();
messages.add(new OLLMchat.Message("system", tpl.filled_system));
messages.add(new OLLMchat.Message("user", tpl.filled_user));
// ... send, parse, etc.
```

**resources/skill-prompts/task_creation_initial.md** — remove this line:

```md
{open_files}
```

**examples/oc-test-skill-agent.vala** — build Runner then §3.1 / §3.2:

Build project_manager (DB, load projects, resolve project from `--project`, activate), then Factory + Runner:

```vala
var db_path = GLib.Path.build_filename(this.data_dir, "files.sqlite");
var db = new SQ.Database(db_path, false);
var project_manager = new OLLMfiles.ProjectManager(db);
yield project_manager.load_projects_from_db();

var project = project_manager.projects.path_map.get(opt_project);
if (project == null) {
    cl.printerr("Project not found: %s\n", opt_project);
    throw new GLib.IOError.NOT_FOUND("Project not found: " + opt_project);
}
yield project.load_files_from_db();
OLLMfiles.Folder.background_recurse = false;
yield project.read_dir(new GLib.DateTime.now_local().to_unix(), true);
project.project_files.update_from(project);
yield project_manager.activate_project(project);

var skills_dirs = new Gee.ArrayList<string>();
skills_dirs.add(GLib.Path.build_filename(GLib.Environment.get_home_dir(), "gitlive", "OLLMchat", "resources", "skills"));
var factory = new OLLMcoder.Skill.Factory(project_manager, skills_dirs, "");
var history_manager = new OLLMchat.History.Manager(this);
var session = new OLLMchat.History.EmptySession(history_manager);
var runner = (OLLMcoder.Skill.Runner) factory.create_agent(session);
```

§3.1 and §3.2 (use `runner` and `opt_prompt` from above):

```vala
// §3.1 (method gets current file from project_manager.active_file)
var tpl = runner.task_creation_prompt(opt_prompt, "", "", runner.sr_factory.skill_manager, runner.sr_factory.project_manager);
stdout.printf("=== system ===\n%s\n=== user ===\n%s\n", tpl.filled_system, tpl.filled_user);

// §3.2
var tpl = runner.task_creation_prompt(opt_prompt, "", "", runner.sr_factory.skill_manager, runner.sr_factory.project_manager);
var messages = new Gee.ArrayList<OLLMchat.Message>();
messages.add(new OLLMchat.Message("system", tpl.filled_system));
messages.add(new OLLMchat.Message("user", tpl.filled_user));
// send messages to model (--model or default), print response
```

### Bundle 2: refinement_prompt

**Prerequisite:** Refinement (§3.4, §3.5) and execute (§3.6, §3.7) need a **parsed task list** (List + Details). Tests are **explicit**: `--run refine-prompt`, `--run refine`, `--run execute-prompt`, and `--run execute` all **require `--input FILE`** (task list file). No implicit state from a prior run; load task list from FILE in that mode. Refinement and execute use --step (default 0) and --task-num (default 0) for direct index access; no walking. Bundle 2 does not implement §3.3; it only adds the refinement_prompt API and template.

**Concrete code for §3.3 (`--run parse-tasklist --input FILE`)** — in `examples/oc-test-skill-agent.vala`, when mode is parse-tasklist call the shared helper with `opt_input` then print summary:

```vala
// §3.3: parse tasklist file — load via helper, then print summary (helper throws on failure)
this.load_task_list(opt_input);  // opt_input required when --run parse-tasklist
var list = this.runner.task_list;
stdout.printf("Steps: %d\n", list.steps.size);
int task_index = 0;
foreach (var step in list.steps) {
    stdout.printf("  Step: %d tasks\n", step.children.size);
    foreach (var t in step.children) {
        task_index++;
        var skill = t.task_data.has_key("Skill") ?
            t.task_data.get("Skill").to_markdown().strip() : "";
        var needed = t.task_data.has_key("What is needed") ?
            t.task_data.get("What is needed").to_markdown().strip() : "";
        stdout.printf("    Task %d: skill=%s  What is needed: %s\n",
            task_index, skill, needed.replace("\n", " "));
    }
}
return;
```

**Shared helper** `load_task_list(string path)` — implement once; §3.3 and §3.4/§3.5 call it:

```vala
private void load_task_list(string path) throws GLib.Error
{
    if (path == "") {
        cl.printerr("Task list file path is empty.\n");
        throw new GLib.IOError.INVALID_ARGUMENT("Task list file path is empty");
    }
    if (!GLib.FileUtils.test(path, GLib.FileTest.EXISTS)) {
        cl.printerr("File not found: %s\n", path);
        throw new GLib.IOError.NOT_FOUND("File not found: " + path);
    }
    string content;
    GLib.FileUtils.get_contents(path, out content);
    var parser = new OLLMcoder.Task.ResultParser(this.runner, content);
    parser.parse_task_list();
    if (parser.issues != "") {
        cl.printerr("Parse issues: %s\n", parser.issues);
        throw new GLib.IOError.INVALID_ARGUMENT(parser.issues);
    }
}
```

(§3.3 runs when `--run parse-tasklist`; `--input FILE` is required, so opt_input is set.)

Runner must already be built (same as §3.1/§3.2). Refinement and execute are explicit: they require `--input FILE` and load the task list in that run (no "later in same process" state).

**Shared helper (no duplication):** Use one helper for “load task list from file” so §3.3 and §3.4/§3.5 don’t duplicate read+parse. Helper: given path (non-null), error if path is "" or file !FileUtils.test(EXISTS); get_contents; ResultParser(runner, content); parse_task_list(); on parser.issues non-empty throw (or return issues to caller); otherwise runner.task_list is set. §3.3: call helper, then if runner.task_list != null print summary. §3.4/§3.5: require `--input FILE`; call same helper (path = opt_input). No implicit state.

**liboccoder/Task/Details.vala**

Refinement prompt: no current_file placeholder — reference_contents already includes current file when in the task's References.

```vala
public OLLMcoder.Skill.PromptTemplate refinement_prompt() throws GLib.Error
{
    var definition = this.skill_manager.fetch(this);
    var tpl = OLLMcoder.Skill.PromptTemplate.template("task_refinement.md");
    tpl.system_fill(); // needed to fill in filled_system
    tpl.fill(
        "issues", tpl.header_raw("Issues with the current call", this.result_parser.issues),
        "task_data", tpl.header_raw("Task", this.to_markdown(MarkdownPhase.REFINEMENT)),
        "environment", this.runner.env(),
        "project_description", (this.runner.sr_factory.project_manager.active_project == null ?
            "" : this.runner.sr_factory.project_manager.active_project.project_description()),
        "task_reference_contents", this.reference_contents(),
        "skill_details", definition.full_content);
    return tpl;
}
```

**liboccoder/Task/Details.vala** — in `refine()`, replace the fill (no current_file):

```vala
tpl.fill(
    "issues", tpl.header_raw("Issues with the current call", this.result_parser.issues),
    "task_data", tpl.header_raw("Task", this.to_markdown(MarkdownPhase.REFINEMENT)),
    "environment", this.runner.env(),
    "project_description", (this.runner.sr_factory.project_manager.active_project == null ?
        "" : this.runner.sr_factory.project_manager.active_project.project_description()),
    "task_reference_contents", this.reference_contents(),
    "skill_details", definition.full_content);
```

**resources/skill-prompts/task_creation_initial.md** — add (e.g. in Reference link types or Output format):

```md
If a task needs the current (open) document, add a reference to it in that task's References using the standard link format (e.g. [Basename](/absolute/path/to/file)).
```

**examples/oc-test-skill-agent.vala** — §3.4 and §3.5: **explicit** only. `--run refine-prompt` and `--run refine` **require `--input FILE`** (task list file). No implicit state. Build runner, load task list from `opt_input`, then resolve by `--step`/`--task-num` (default 0/0).

```vala
// Explicit: --input FILE required for refine-prompt / refine
if (opt_input == null || opt_input == "") {
    throw new GLib.IOError.INVALID_ARGUMENT("--run refine-prompt / refine requires --input FILE (task list)");
}
this.load_task_list(opt_input);

// Resolve task by step/task-num (default 0/0 = first step, first task)
var list = this.runner.task_list;
if (opt_step < 0 || opt_step >= list.steps.size) {
    cl.printerr("Step %d out of range (0..%d).\n", opt_step, list.steps.size - 1);
    throw new GLib.IOError.NOT_FOUND("Step out of range");
}
var step = list.steps.get(opt_step);
if (opt_task_num < 0 || opt_task_num >= step.children.size) {
    cl.printerr("Task %d out of range (0..%d).\n", opt_task_num, step.children.size - 1);
    throw new GLib.IOError.NOT_FOUND("Task out of range");
}
var detail = step.children.get(opt_task_num);

// §3.4 --run refine-prompt: output refinement prompt only
var tpl = detail.refinement_prompt();
stdout.printf("=== system ===\n%s\n=== user ===\n%s\n", tpl.filled_system, tpl.filled_user);

// §3.5 --run refine: build same prompt, send to model, print response
var tpl = detail.refinement_prompt();
var messages = new Gee.ArrayList<OLLMchat.Message>();
messages.add(new OLLMchat.Message("system", tpl.filled_system));
messages.add(new OLLMchat.Message("user", tpl.filled_user));
var response_obj = yield this.runner.chat().send(messages, null);
stdout.printf("%s", response_obj != null && response_obj.message != null ? response_obj.message.content ?? "" : "");
```

### Bundle 3: executor_prompt

**liboccoder/Task/Details.vala**

```vala
public OLLMcoder.Skill.PromptTemplate executor_prompt() throws GLib.Error
{
    var definition = this.skill_manager.fetch(this);
    var tpl = OLLMcoder.Skill.PromptTemplate.template("task_execution.md");
    tpl.system_fill();
    tpl.fill(
        "query", this.task_data.get("What is needed").to_markdown(),
        "skill_definition", definition.full_content,
        "precursor", this.executor_precursor());
    return tpl;
}
```

**examples/oc-test-skill-agent.vala** — §3.6 and §3.7:

```vala
// §3.6 --execute-task: for task N
yield detail.run_tools();
var tpl = detail.executor_prompt();
stdout.printf("=== system ===\n%s\n=== user ===\n%s\n", tpl.filled_system, tpl.filled_user);

// §3.7 --run-execute-task: same then send to model
yield detail.run_tools();
var tpl = detail.executor_prompt();
// send (system, user) to model; parse response with result_parser.extract_exec(detail); print results
```

### ResultParser

No changes. Test app uses existing parse_task_list(), extract_refinement(), extract_exec() with minimal Runner/Details.

---

## 10. Out of scope

- Changing the design of prompts or of Runner/Details/ResultParser beyond adding small test-friendly accessors (e.g. “get prompt for this stage”).
- Full end-to-end automation of the whole agent in this example; the goal is **testable usage** of each stage, not a single “run everything” command (that remains the normal app flow).
