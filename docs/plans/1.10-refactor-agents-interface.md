# 1.10. Refactor Agents as Interface Between UI and Client

## Overview

Refactor the agent architecture so that agents act as the interface layer between the UI and the client, rather than being embedded within the client. This separation will make agents more flexible, allow for better UI integration, and enable dynamic agent creation and modification.

**Key Change**: Remove `libocagent` library entirely and move `BaseAgent` and `JustAsk` classes to `libollmchat` with namespace `OLLMchat.Agent` (replacing `OLLMagent` namespace).

## Status

⏳ **TODO** - To be implemented.

## Implementation Todo Plan

### Phase 1: Remove libocagent and Move to OLLMchat.Agent Namespace
- [ ] **Remove libocagent library**:
  - [ ] Move `BaseAgent` from `libocagent/BaseAgent.vala` (namespace `OLLMagent`) to `libollmchat/Agent/Base.vala` (namespace `OLLMchat.Agent`)
  - [ ] Move `JustAsk` from `libocagent/JustAsk.vala` (namespace `OLLMagent`) to `libollmchat/Agent/JustAsk.vala` (namespace `OLLMchat.Agent`)
  - [ ] Update all references from `OLLMagent.BaseAgent` to `OLLMchat.Agent.Base`
  - [ ] Update all references from `OLLMagent.JustAsk` to `OLLMchat.Agent.JustAsk`
  - [ ] Remove libocagent from meson.build files
  - [ ] Remove libocagent directory
  - [ ] Update all imports and dependencies
- [ ] Create `AgentHandler` class in `libollmchat/Prompt/AgentHandler.vala`:
  - [ ] Handler wraps client instance for a single request
  - [ ] Handler has `handle_request_async(ChatRequest request)` method to execute requests
  - [ ] Handler sets up signal connections to client (stream_chunk, stream_content, etc.)
  - [ ] Handler relays client signals to session methods
  - [ ] Handler has `disconnect_client_signals()` method for cleanup
  - [ ] Handler manages lifecycle of a single chat request
- [ ] Update `OLLMchat.Agent.Base` class:
  - [ ] Remove client dependency (agents are lightweight)
  - [ ] Remove signals (handlers have signals)
  - [ ] Update `create_handler()` to accept ChatRequest and Session: `create_handler(ChatRequest request, Session session)`
  - [ ] Keep prompt generation methods (`fill()`, `generate_system_prompt()`, etc.)
  - [ ] Keep `configure_tools()` method for tool configuration
  - [ ] Remove dependency on client's `prompt_assistant`
- [ ] Update `OLLMchat.Agent.JustAsk` class:
  - [ ] Remove client from constructor (agents are lightweight)
  - [ ] Override `create_handler()` to return `AgentHandler`
  - [ ] Minimal changes needed, mostly pass-through behavior
- [ ] Build and verify Phase 1 compiles

### Phase 2: Client Simplification
- [ ] Update `Client` class:
  - [ ] Remove `prompt_assistant` property
  - [ ] Remove prompt generation logic from client
  - [ ] Update `chat()` method to accept pre-prepared Chat object (or just execute it)
  - [ ] Ensure client does NOT modify messages array (use what agent prepared)
  - [ ] Remove tool execution from client level (tools are now managed at agent level)
- [ ] Update `Call.Chat` class:
  - [ ] Remove dependency on `client.prompt_assistant`
  - [ ] Ensure `exec_chat()` works with pre-prepared messages array
  - [ ] Ensure `reply()` method can be called by agent to rebuild conversation
  - [ ] **Default dummy agent** - Call/Chat constructor should use default "just-ask" agent to avoid null checks (manager always has at least one agent registered)
- [ ] Build and verify Phase 2 compiles

### Phase 3: Manager Updates
- [ ] Update `History.Manager` class:
  - [ ] Keep agent registration (`manager.agents` HashMap)
  - [ ] **Always register default "just-ask" agent** - Manager constructor should register `OLLMchat.Agent.JustAsk` as default
  - [ ] Add `get_active_agent()` method - Gets agent from `manager.agents` based on `session.agent_name`
  - [ ] Tools are managed at agent level (not manager or client level)
  - [ ] Agents are lightweight, no client dependency (agents don't have clients - handlers do)
- [ ] Build and verify Phase 3 compiles (Manager.vala compiles successfully)

### Phase 4: UI Integration
- [ ] Update `ChatInput` or `ChatWidget` class:
  - [ ] Change to send messages to manager (e.g., `manager.send_message_async(user_input)`)
  - [ ] Manager flow: Get active agent → Create handler → Send message
  - [ ] Connect to manager signals (not handler signals directly)
  - [ ] Handle streaming chunks from manager signals
  - [ ] Remove direct client access
- [ ] Update `History.Manager` class:
  - [ ] Add `send_message_async(string user_input)` method:
    - Get active agent: `agent = this.get_active_agent()`
    - Create handler: `handler = agent.create_handler(this.session)` (handler creates client from session)
    - Handler registers tools from manager on handler's client (tools managed at manager level)
    - Call `handler.send_message_async(user_input)`
    - Clean up handler after request completes
- [ ] Update `AgentHandler` class:
  - [ ] For replies: rebuild conversation history from Session
  - [ ] For replies: call `agent.fill()` to regenerate system prompt with current context
  - [ ] For replies: update system message in messages array (replace old system message if present)
  - [ ] Ensure CodeAssistant system prompt is regenerated on each reply (not cached)
- [ ] Update `Window` class:
  - [ ] Tools are managed at agent level (not manager or client level)
  - [ ] Agents are registered on `manager.agents`
  - [ ] UI sends messages to manager, not directly to agent or client
  - [ ] UI receives replies through manager signals
- [ ] Build and verify Phase 4 compiles

### Phase 4.5: CodeAssistant Content Generation Simplification
- [ ] Simplify CodeAssistant system prompt generation:
  - [ ] **Current**: System prompt is split into multiple resources (introduction.md, communication.md, tool_calling.md, etc.) and concatenated
  - [ ] **New**: Store system prompt in a single string with placeholders (e.g., `{introduction}`, `{communication}`, `{tool_calling}`, etc.)
  - [ ] **Post-process after filling placeholders**:
    - [ ] Build a HashMap of replacements (placeholder → content from resources)
    - [ ] Foreach replacement: string replace placeholder with content
    - [ ] **Remove empty sections**: Look for `<....>\n\n<....>` patterns where content between tags is empty/whitespace only, remove entire section (including tags and surrounding newlines)
  - [ ] This simplifies maintenance and allows for better empty section handling
- [ ] Update CodeAssistant to use simplified content generation
- [ ] Test that empty sections are properly removed
- [ ] Build and verify Phase 4.5 compiles

### Phase 4.6: CodeAssistant Provider Refactoring (Optional)
- [ ] Consider moving CodeAssistantProvider into CodeAssistantHandler:
  - [ ] Move provider logic from CodeAssistant to CodeAssistantHandler
  - [ ] Handler can access context directly (open files, workspace, etc.)
  - [ ] Handler manages context gathering for system prompt generation
  - [ ] CodeAssistant becomes simpler (just prompt generation, no provider)
  - [ ] Evaluate if provider pattern is still needed or if handler can do it directly
- [ ] Update CodeAssistant to remove provider dependency
- [ ] Update CodeAssistantHandler to handle context gathering
- [ ] Build and verify Phase 4.6 compiles

### Phase 5: Cleanup
- [ ] Remove old code paths:
  - [ ] Remove `client.prompt_assistant` usage from all files
  - [ ] Remove direct client.chat() calls from UI
  - [ ] Remove any remaining client access from UI components
- [ ] Verify all functionality works with new architecture
- [ ] Build final version and test

## Related Plans

- **1.7** - Agent Management System (current agent implementation)
- **1.11** - libgjs for Agents (dynamic agent creation)
- **1.3.9** - Agent Configuration (agent configuration UI)

## Current Architecture

**Current State:**
- Agents are embedded within the client via `client.prompt_assistant`
- Client directly uses agent's `generate_system_prompt()` and `generate_user_prompt()` methods
- Manager stores agents and sets active agent on client
- UI selects agent, which updates `manager.active_agent_name`, which then sets `client.prompt_assistant`

**Problems:**
- Tight coupling between client and agents
- Agents are passive prompt generators
- Difficult to add agent-specific UI or behavior
- Client must know about agent structure

## Proposed Architecture

**New State:**
- **Flow**: Chat UI → History Manager → Session → Agent → LLM

### UI Access Patterns

**⚠️ Critical Principle**: UI should NOT access `Call.Chat` directly without Session context. All Chat access must go through Session.

**Why:**
- Session is the proper context for message tracking and history management
- Session owns both `client` and `chat`, providing the complete context
- Direct Chat access bypasses session management and can lead to inconsistent state

**Correct Pattern:**
- UI receives `SessionBase` from Manager signals (e.g., `add_message(Message, SessionBase?)`)
- UI accesses Chat properties via Session: `session.chat`, `session.client`
- UI methods should accept `SessionBase` parameter, not `ChatContentInterface` or `Call.Chat` directly

**Examples:**
- ✅ `ChatView.append_user_message(text, session)` - uses `session.chat` and `session.client`
- ✅ `ChatView.append_complete_assistant_message(message, session)` - uses `session.chat` and `session.client`
- ❌ `ChatView.append_user_message(text, chat_call)` - direct Chat access without Session
- ❌ `ChatView.append_user_message(text, message.message_interface)` - accessing Chat via message interface

**Implementation:**
- Manager signals pass `SessionBase` instead of `ChatContentInterface`
- Session automatically passes itself (`this`) to Manager signals
- Tools call `session.add_message(message)` - session handles passing itself to signal
- **Request Object Flow**: UI sends ChatRequest object with session_id, model_name, connection_name, agent_name, chat_content
  - Manager checks if session_id exists (if empty, creates new session)
  - Manager fills in session_id and passes request to session
  - Session compares agent_name with current agent - if different, gets agent from manager.agents
  - Session asks agent to create handler: `handler = agent.create_handler(request, session)`
  - Handler handles request (creates client, sends to LLM, etc.)
  - **Consider**: Chat call sending data directly to handler rather than using signals?
- **Component Chain**: Each element has reference to related components (except Client)
  - ChatWidget → Manager (UI has reference to Manager)
  - Manager → Session (Manager has reference to active session)
  - Session → Manager (Session has reference to Manager - uses base class/interface if crossing library boundaries)
  - Session → Agent (Session gets agent from manager.agents)
  - Session → AgentHandler (Session creates handler via agent)
  - AgentHandler → Client (Handler creates/manages client)
  - **Client is loosely coupled**: No references to other components, just emits signals or sends data directly
- **Signal Usage**:
  - **Client uses signals** - Client is loosely coupled, emits signals when receiving LLM responses
  - **Signals are needed for non-agent usage** - Direct client usage (without agents) still needs signals for UI updates
  - **Call.Chat can use direct calls to agent (or dummy) along with signals** - For non-agent usage, Chat call can call agent methods directly and also use signals
  - **Agent infrastructure does NOT use signals** - AgentHandler, Session, Manager use direct method calls (not signals)
  - Handler processes and calls session methods directly (not via signals)
  - Session calls manager methods directly (not via signals)
  - Manager emits signals for UI (UI connects to manager signals)
  - **Manager does NOT have reference to UI** - UI connects to manager signals
- **Default Dummy Agent**:
  - **Create a default dummy agent by default** - Avoid null checks in Call/Chat constructor
  - Manager should always have at least one agent registered (default "just-ask" agent)
  - This ensures Call/Chat can always assume an agent exists, avoiding null checks
- **History Manager**:
  - Holds registered agents (`manager.agents`)
  - Holds available tools (tools are managed at manager level, registered on each client when created)
  - Receives ChatRequest object from UI with: session_id, model_name, connection_name, agent_name, chat_content
  - Checks if session_id exists (if empty, creates new session)
  - Fills in session_id and passes request to session
  - Holds registered agents in manager.agents (agents are registered at startup)
- **Session**:
  - Receives ChatRequest from manager
  - Compares agent_name in request with current agent_name
  - If different, gets agent from manager.agents (manager.agents contains registered agents)
  - Asks agent to create handler: `handler = agent.create_handler(request, session)`
  - Asks handler to handle request: `handler.handle_request_async(request)`
  - Has reference to Manager (uses base class/interface if crossing library boundaries)
- **Agent** (`OLLMchat.Agent.Base`, `OLLMchat.Agent.JustAsk`, etc.):
  - **Namespace**: `OLLMchat.Agent` (moved from `OLLMagent` namespace in libocagent)
  - Lightweight, persistent, registered on History Manager
  - Provides `create_handler(ChatRequest request, Session session)` method to create handlers
  - No client dependency
  - Handlers do the actual request handling
- **AgentHandler**:
  - **Creates and manages the client** - can get all parts to build client correctly from request
  - Creates client from request (gets connection/model from request)
  - **Tools are managed at agent level** (not client level) - agent creates/gets tool instances when needed
  - Handles request: creates Chat object, builds messages, sends to LLM
  - **Does NOT connect to client signals** - Agent infrastructure uses direct method calls, not signals
  - Receives data from client via direct method calls (e.g., polling or callbacks)
  - Processes and calls session methods directly (not via signals)

**Benefits:**
- Clear separation of concerns
- Tools managed at manager level (registered on each client when created)
- Agents are stateless and reusable
- Session-specific client instances
- Easy to change active agent per session
- **Signal usage**: Client uses signals (loosely coupled, no references to other components), signals needed for non-agent usage (direct client usage)
- **Call.Chat can use direct calls to agent (or dummy) along with signals** - For non-agent usage, Chat call can call agent methods directly and also use signals
- **Agent infrastructure does NOT use signals** - AgentHandler, Session, Manager use direct method calls (not signals)
- **AgentHandler owns client lifecycle** - does NOT connect to client signals, uses direct method calls instead
- **Client stays decoupled** - no references to other components, just emits signals when receiving LLM responses
- **Clear separation**: Client is low-level API (signals for non-agent usage), Agent infrastructure uses direct method calls
- **Default dummy agent** - Manager always has at least one agent registered (default "just-ask") to avoid null checks in Call/Chat constructor
- **Manager does NOT have reference to UI** - UI connects to manager signals
- **Cross-library relationships use base classes/interfaces** - Session→Manager and Handler→Session use interfaces/base classes if crossing library boundaries

## Architecture Changes

### Agent and Handler Split

**Two-Tier Architecture:**
- **Agent** (`OLLMchat.Agent.Base`, `OLLMchat.Agent.JustAsk`, `OLLMcoder.Prompt.CodeAssistant`): Lightweight, persistent, initialized at startup
  - **Namespace**: `OLLMchat.Agent` (moved from `OLLMagent` namespace in libocagent)
  - Note: `CodeAssistant` is in `liboccoder` namespace `OLLMcoder.Prompt` but extends `OLLMchat.Agent.Base`
  - No client dependency
  - No signals
  - **`fill()` is actually `build_messages()`**: Converts session message array and incoming request into array of messages ready to be sent to chat
  - Only prompt generation (`fill()`/`build_messages()`, `generate_system_prompt()`, etc.)
  - Provides `create_handler(ChatRequest request, Session session)` method to create request handlers
  - Shared across all requests for that agent type
  - Agents do NOT handle requests directly - handlers do
  
- **AgentHandler**: Ephemeral, created per request, manages single chat lifecycle
  - Created by agent with ChatRequest and Session
  - Creates and manages the client instance for the request
  - **Does NOT connect to client signals** - Uses direct method calls instead
  - Has `handle_request_async(ChatRequest request)` method to execute the request
  - Manages the lifecycle of a single chat request
  - Should be disposed/destroyed after the request completes

**AgentHandler Lifecycle:**
1. **Creation**: Session calls `agent.create_handler(request, session)` before sending a message
   - Handler is created with agent reference, ChatRequest, and session
   - Handler has reference to Session (uses base class/interface if crossing library boundaries) for callbacks
   - Handler is ready to process a single request

2. **Request Processing**: Session calls `handler.handle_request_async(request)`
   - **Handler creates client** from request (gets connection/model from request)
   - Handler gets tools from manager (via session.manager) - tools are managed at manager level
   - Handler registers tools on handler's client (tools are managed at manager level, registered on each client when created)
   - Handler creates `Call.Chat` object with handler's client
   - Handler calls `agent.configure_tools()` to configure tools
   - Handler calls `agent.fill(call, request.chat_content)` / `agent.build_messages(call, request.chat_content)` to build message array:
     - Agent retrieves previous conversation messages from Session
     - Agent filters messages to get API-compatible messages
     - Agent generates system prompt (if needed) and user prompt
     - Agent adds messages to `call.messages` array in correct order
   - Handler executes `call.exec_chat()` which sends to LLM API via handler's client
     - LLM may respond with tool calls
     - **Agent handles tool calls** (tool handler is tied to agent, not client):
       - Agent receives tool request, creates/gets tool instance (tools managed at agent level)
       - Tool can access project manager via agent (handler has reference to creating agent)
       - Tool can access session via agent (agent has reference to session)
       - Agent executes tool, adds results to `call.messages`, relays back to LLM
       - Session records tool messages (sent and received) via agent callbacks
       - Recurses until final response (no more tool calls)
     - Handler receives final response via direct method call return (after all tool calls are handled)
   - **Handler does NOT connect to client signals** - Uses direct method calls instead (agent infrastructure does not use signals)
   - **Client emits signals** when receiving LLM responses (for non-agent usage, loosely coupled, no references to other components)
   - **Handler receives data via direct method calls** (e.g., polling or callbacks) and calls session methods directly (e.g., `session.on_chunk(chunk)`)
   - Handler manages the entire request lifecycle

3. **Completion**: After the request completes (streaming ends or final response received)
   - Handler calls `session.on_complete()` or similar
   - Handler cleanup (no signal connections to disconnect - uses direct method calls)
   - Handler should be disposed/destroyed
   - Handler is no longer needed - it was only for that single request
   - Agent remains alive and can create new handlers for subsequent requests

**Key Points:**
- **Agent is persistent**: Created once at startup, lives for the application lifetime
- **Handler is ephemeral**: Created per request, destroyed after request completes
- **One handler per request**: Each chat message gets its own handler instance
- **Handler manages request lifecycle**: From message creation to final response
- **Handler cleanup**: Should be disposed after completion (no signal connections to disconnect - uses direct method calls)

### Agent Interface

**New Agent Responsibilities:**
- Provide prompt generation (`fill()`, `generate_system_prompt()`, etc.)
- Configure tools for requests (`configure_tools()`)
- Create handlers for requests (`create_handler()`)
- Provide UI widgets (already implemented via `get_widget()`)
- Handle agent-specific state and configuration

**Agent Methods:**
- `create_handler(ChatRequest request, Session session)` - Creates a new AgentHandler for a request
  - Handler is created with agent reference, request, and session
  - Handler can get all parts it needs from request, session, and session.manager
  - Handler will create client and get tools when handling the request
- `fill(Call.Chat call, string user_input)` / `build_messages(Call.Chat call, string user_input)` - **Converts session message array and incoming request into array of messages ready to be sent to chat**
  - Retrieves previous conversation messages from Session
  - Filters messages from Session to get API-compatible messages (system, user, assistant, tool)
  - Generates system prompt (if needed) and user prompt
  - Adds messages to `call.messages` array in correct order
- `configure_tools(Call.Chat call)` - Configure tools for the chat
- `get_widget()` - Provide UI widget (already exists)

**Note:** Agents provide handlers. Handlers are in charge of the client. They can get all the parts to build the client correctly from request (connection/model) and manager (tools via session.manager). This maintains proper encapsulation and ensures the handler owns the request lifecycle. Cross-library relationships (Handler→Session, Session→Manager) use base classes/interfaces.

### Client Changes

**Client Simplification:**
- Remove `prompt_assistant` property from Client
- Client becomes a lower-level API
- Client focuses on API communication, not prompt generation
- Prompt generation moves to agent layer

**Client Methods:**
- Keep existing API methods (chat, stream, etc.)
- Remove agent-specific logic
- **Tools are NOT on client** - Tools are managed at agent level (agent creates/gets tool instances)

**Call.Chat Updates:**
- Remove dependency on `client.prompt_assistant`
- Ensure `exec_chat()` works with pre-prepared messages array
- Ensure `reply()` method can be called by agent to rebuild conversation
- **Default dummy agent** - Call/Chat constructor should use default "just-ask" agent to avoid null checks (manager always has at least one agent registered)

### Manager Changes

**Manager Updates:**
- **Holds registered agents** (`manager.agents` HashMap)
- **Always registers default "just-ask" agent** - Manager constructor should register `OLLMchat.Agent.JustAsk` as default
- **Holds available tools** (tools are managed at manager level, registered on each client when created)
- Provides `get_active_agent()` - Gets agent from `manager.agents` based on `session.agent_name`
- Manager coordinates between agents and sessions
- Tools are managed at manager level, registered on each client when it's created (no base_client, no copying)

**Manager Methods:**
- `get_active_agent()` - Get currently active agent from `manager.agents` based on `session.agent_name`
  - Returns `manager.agents.get(session.agent_name == "" ? "just-ask" : session.agent_name)`
- `send_message_async(string user_input)` - Send message through active agent handler (to be added in Phase 4)
- `agent_activated` signal - Emit when agent changes (already exists)
- Tools registration: Tools are managed at manager level, registered on each client when created

### UI Changes

**UI Updates:**
- **Flow**: Chat UI → History Manager → Session → AgentHandler → LLM
- **Signals flow backwards**: LLM → AgentHandler → Session → History Manager → Chat UI
- UI sends messages to History Manager (not directly to agent or client)
- Manager gets active agent from session, creates handler, sends message
- Signals flow back through the chain: Handler → Session → Manager → UI

**ChatInput Changes:**
- Create ChatRequest object with: session_id, model_name, connection_name, agent_name, chat_content
- Send ChatRequest to manager: `manager.send_request_async(request)`
- Manager flow:
  1. Check if request.session_id exists (if empty, create new session)
  2. Fill in request.session_id
  3. Pass request to session: `session.handle_request_async(request)`
  4. Session compares request.agent_name with current agent_name
  5. If different, get agent from manager.agents: `agent = manager.agents.get(request.agent_name)`
  6. Session asks agent to create handler: `handler = agent.create_handler(request, session)`
  7. Session asks handler to handle request: `handler.handle_request_async(request)`
  8. Handler creates client from request
  8. Agent sends to LLM via client
  9. **Consider**: Chat call sending data directly to agent rather than using signals?
  10. Agent processes response and calls session methods directly
  11. Session calls manager methods directly
  12. Manager emits signal (UI connects to manager signals)
- UI connects to manager signals (Manager does NOT have reference to UI)
- Remove direct client access from UI
- **Consider**: Direct data flow from client to agent (no signals needed)

### Session Changes

**Session Updates:**
- Session has `agent_name` property (identifies which agent to use from manager.agents)
- Session has `model`, `connection`, `think` properties (stored separately, not as client)
  - When user changes model/connection in UI dropdown, session properties are updated:
    - `session.connection = new_connection` (from ModelUsage.connection)
    - `session.model = new_model` (from ModelUsage.model)
    - `session.think = model.is_thinking` (from ModelUsage.model_obj)
  - **No client stored on session** - AgentHandler creates client from session properties
  - **ModelUsage includes connection info**: ModelUsage has both `connection` and `model` properties
  - UI dropdown uses ModelUsage objects (which include connection), but currently displays model name only
  - Connection info is available in ModelUsage and is used to update session.connection
- Active agent can change: `session.agent_name` can be updated to switch agents
- Session does NOT store agent reference directly - uses `agent_name` to look up from manager
- Session has reference to Manager (parent) for callbacks
- When creating handler: `agent = manager.get_active_agent()`, then `handler = agent.create_handler(session)` (handler gets client from session)
- Session has callback methods: `on_chunk()`, `on_complete()` - called by handler, calls parent (manager)

## Implementation Details

### Phase 1: Agent Interface Refactoring

**1. Create AgentHandler**
- Handler is created by agent: `handler = agent.create_handler(request, session)`
- Handler has reference to Session (uses base class/interface if crossing library boundaries) for callbacks
- Handler has `handle_request_async(ChatRequest request)` method - async with streaming support
- Handler creates and manages the client when handling request:
  - Gets connection/model from request
  - Gets tools from manager (via session.manager) - copies from manager.base_client
- **Handler does NOT connect to client signals** - Uses direct method calls instead (agent infrastructure does not use signals)
- **Handler calls session methods directly** when receiving data via direct method calls:
  - Handler receives data via direct method calls (e.g., polling or callbacks) → Handler calls `session.on_chunk(chunk)`
  - Session calls `manager.on_chunk(chunk)` → Manager emits signal (UI connects to manager signals)
  - Only Client uses signals (loosely coupled), rest of chain uses direct method calls
  - **Manager does NOT have reference to UI** - UI connects to manager signals
- **Handler creates Chat object internally:**
  - Handler creates `Call.Chat` object with handler's client (handler created and manages client)
  - Handler calls `agent.configure_tools(call)` to configure tools
  - Handler calls `agent.fill(call, user_input)` to generate prompts
  - Handler creates system message (if system_content set)
  - Handler creates user-sent message with original text
- Handler calls `call.exec_chat()` which sends to LLM API
- Handler calls parent methods directly instead of emitting signals
- **Handler lifecycle:** Created per request, disposed after request completes

**2. Update BaseAgent**
- Remove client dependency (agents are lightweight and persistent)
- Remove signals (handlers use direct method calls to parents)
- Remove `send_message_async()` (handlers have this)
- Add `create_handler(Session session)` method - returns new `AgentHandler` instance
  - Handler gets client from `session.client` (handler is in charge of client)
  - Handler can get all parts it needs from session and session.parent (manager)
- Keep prompt generation methods:
  - `fill(Call.Chat call, string user_input)` / `build_messages(Call.Chat call, string user_input)` - **Converts session message array and incoming request into array of messages ready to be sent to chat**
    - Retrieves previous conversation messages from Session
    - Filters messages to get API-compatible messages (system, user, assistant, tool)
    - Generates system prompt (if needed) and user prompt
    - Adds messages to `call.messages` array in correct order
  - `generate_system_prompt()` - generates system prompt
  - `generate_user_prompt(string user_input)` - generates user prompt
- Keep `configure_tools(Call.Chat call)` method - configures tools for chat
- Remove dependency on client's `prompt_assistant`
- **Agent is persistent:** Created once at startup, lives for application lifetime

**3. Update CodeAssistant**
- CodeAssistant is in `liboccoder/Prompt/CodeAssistant.vala` (extends `OLLMchat.Agent.Base`)
- Remove client from constructor (agents are lightweight)
- Override `create_handler()` to return `AgentHandler(this, request, session)`
  - Handler is created with agent reference, request, and session
  - Handler will create client from request when handling the request
- **Simplify content generation**:
  - **Current**: System prompt is split into multiple resources (introduction.md, communication.md, tool_calling.md, etc.) and concatenated
  - **New**: Store system prompt in a single string with placeholders (e.g., `{introduction}`, `{communication}`, `{tool_calling}`, etc.)
  - **Post-process after filling placeholders**:
    - Build a HashMap of replacements (placeholder → content)
    - Foreach replacement: string replace placeholder with content
    - **Remove empty sections**: Look for `<....>\n\n<....>` patterns where content between tags is empty/whitespace only, remove entire section
  - This simplifies maintenance and allows for better empty section handling
- Keep tool configuration logic
- Maintain existing behavior but through handler interface
- **Important:** CodeAssistant's `generate_system_prompt()` must be called on each request to update dynamic context (current file, open files, workspace path, etc.). The system prompt should NOT be cached - it must reflect the current application state on each call.

**4. Update JustAsk**
- Move from `libocagent/JustAsk.vala` (namespace `OLLMagent`) to `libollmchat/Agent/JustAsk.vala` (namespace `OLLMchat.Agent`)
- Remove client from constructor (agents are lightweight)
- Override `create_handler()` to return `AgentHandler(this, request, session)`
  - Handler is created with agent reference, request, and session
  - Handler will create client from request when handling the request
- Minimal changes needed, mostly pass-through behavior

### Phase 2: Client Simplification

**1. Remove prompt_assistant from Client**
- Remove `prompt_assistant` property
- Remove prompt generation logic from client
- Client becomes pure API interface

**2. Update Client Methods**
- `chat()` method accepts pre-generated prompts
- Or client methods accept agent context
- Tools remain at client level (or move to agent?)

### Phase 3: Manager Updates

**1. Update Manager**
- Keep agent registration
- Add `get_active_agent()` helper method (trivial - can be inlined where needed)
- Remove `active_agent_name` if not needed
- Ensure agents have client instances (agents don't have clients - handlers do)

**2. Update new_client()**
- Create client instance
- Create agent with client instance
- Register agent
- Return agent (or keep client separate?)

### Phase 4: UI Integration

**1. Update ChatInput/ChatWidget**
- Send messages to manager: `manager.send_message_async(user_input)`
- Connect to manager signals (stream_chunk, stream_content, etc.)
- Handle streaming chunks from manager signals
- Remove direct client access
- Manager handles: Get agent → Create handler → Send message → Relay signals

**2. Update Manager**
- Add `send_request_async(ChatRequest request)` method:
  - Check if request.session_id exists (if empty, create new session)
  - Fill in request.session_id
  - Pass request to session: `session.handle_request_async(request)`
- Manager holds registered agents in manager.agents (agents are registered at startup)
- Add callback methods for session to call:
  - `on_chunk(string chunk, bool is_thinking, Response.Chat response)` - called by session
  - `on_complete()` - called by session when request completes
  - These methods emit signals (UI connects to manager signals - Manager does NOT have reference to UI)
- Manager holds registered agents in manager.agents (agents are registered at startup)

**3. Update Session**
- Add `handle_request_async(ChatRequest request)` method:
  - Compare request.agent_name with current session.agent_name
  - If different, get agent from manager.agents: `agent = manager.agents.get(request.agent_name)`
  - Ask agent to create handler: `handler = agent.create_handler(request, this)`
  - Ask handler to handle request: `handler.handle_request_async(request)`
- Add callback methods for agent to call:
  - `on_chunk(string chunk, bool is_thinking, Response.Chat response)` - called by agent
  - `on_complete()` - called by agent when request completes
  - These methods call manager methods directly (uses base class/interface if crossing library boundaries)
- Session has reference to Manager (uses base class/interface if crossing library boundaries)

**4. Update Agent (OLLMchat.Agent.Base)**
- Move from `libocagent/BaseAgent.vala` to `libollmchat/Agent/Base.vala`
- Change namespace from `OLLMagent` to `OLLMchat.Agent`
- Update `create_handler()` method to accept ChatRequest and Session: `create_handler(ChatRequest request, Session session)`
  - Returns new AgentHandler instance
  - Handler is created with agent reference, request, and session
- Agent does NOT handle requests directly - handlers do
- Agent is lightweight, persistent - provides handlers for request processing
- Update all references from `OLLMagent.BaseAgent` to `OLLMchat.Agent.Base`

**5. Update AgentHandler**
- Update constructor to accept ChatRequest and Session: `AgentHandler(agent, request, session)`
- Add `handle_request_async(ChatRequest request)` method:
  - Create client from request (gets connection/model from request)
  - Get tools from manager (via session.manager) - tools are managed at manager level
  - Register tools on handler's client (tools are managed at manager level, registered on each client when created)
  - Create `Call.Chat` object
  - Call `agent.configure_tools()` and `agent.build_messages()`
  - Send to LLM via client
  - **Consider**: Chat call sending data directly to handler rather than using signals?
  - Process response and call session methods directly
- Handler creates and manages client

**6. Update Window**
- Tools are managed at manager level (registered on each client when created)
- Agents are registered on `manager.agents` (already done)
- UI sends ChatRequest to manager, not directly to agent or client
- UI receives replies through manager signals

## Files to Modify

### Core Agent Files (Move from libocagent to libollmchat)
- `libollmchat/Agent/Base.vala` - **NEW**: Move from `libocagent/BaseAgent.vala`, change namespace from `OLLMagent` to `OLLMchat.Agent`, update to new interface
- `libollmchat/Agent/JustAsk.vala` - **NEW**: Move from `libocagent/JustAsk.vala`, change namespace from `OLLMagent` to `OLLMchat.Agent`, update to new interface
- `libollmchat/Prompt/AgentHandler.vala` - Create/update handler class
- `liboccoder/Prompt/CodeAssistant.vala` - Update to use new interface (extends `OLLMchat.Agent.Base` instead of `OLLMagent.BaseAgent`)

### Files to Remove
- `libocagent/BaseAgent.vala` - Move to libollmchat/Agent/Base.vala
- `libocagent/JustAsk.vala` - Move to libollmchat/Agent/JustAsk.vala
- `libocagent/meson.build` - Remove libocagent library build
- Remove libocagent directory entirely

### Client Files
- `libollmchat/Client.vala` - Remove prompt_assistant, simplify API
- `libollmchat/Call/Chat.vala` - Update to work without prompt_assistant

### Manager Files
- `libollmchat/History/Manager.vala` - Add `send_message_async()` method, ensure tools are on manager, agents are registered
  - Update references from `OLLMagent.BaseAgent` to `OLLMchat.Agent.Base`
  - Update agent registration: `manager.agents.set("just-ask", new OLLMchat.Agent.JustAsk())`

### UI Files
- `libollmchatgtk/ChatInput.vala` - Send messages to agent instead of client
- `ollmchat/Window.vala` - Update agent initialization with client instances

## Migration Strategy

1. **Add new code** - Implement new agent interface methods alongside existing code
2. **Build** - Ensure new code compiles successfully
3. **Replace old calls & remove old code** - Update UI to use new interface, then remove old code paths

## Design Considerations

### Client Ownership
- **Option A**: Agent owns client instance (agent creates/manages client)
- **Option B**: Agent wraps client instance (client created externally, passed to agent)
- **Option C**: Agent references client (client managed separately, agent uses reference)

**Recommendation**: Option B - Agent wraps client, allows for client reuse and better separation

### Tool Management

**Tools are on Agent (not Client):**
- Tool handler is tied to the agent (not the client)
- Tools are managed at agent level (agent creates/gets tool instances)
- Tools that use project manager were created with it, and handler has reference to its creating agent so it can access project manager via that
- Tool can access session via agent (agent has reference to session)
- Agent manages tool execution and relays tool replies back to LLM
- Session records tool messages (sent and received) via agent callbacks

**How Tools Fit In:**
- Tools are managed at agent level (not client level)
- Agent creates/gets tool instances when needed
- Tools can access project manager via agent (handler has reference to creating agent)
- Tools can access session via agent (agent has reference to session)
- Agent executes tools and relays results back to LLM
- Agent can filter/configure which tools are available via `configure_tools(Call.Chat call)`
- Session records all messages (including tool calls/responses) via agent

**Tool Calls and Responses Flow:**
1. **Handler calls `call.exec_chat()`** - Sends request to LLM via handler's client
2. **LLM responds** - Response may contain `tool_calls` in `response.message.tool_calls`
3. **Agent handles tool calls** - Tool handler is tied to the agent (not the client):
   - Agent receives tool request from LLM response
   - Agent creates tool instance (tools that use project manager were created with it)
   - Handler has reference to its creating agent, so tool can access project manager via agent
   - Tool can access session via agent (agent has reference to session)
   - Agent executes tool via `agent.execute_tool(tool_call)`
   - Tool execution results are added to `call.messages` as tool reply messages
   - Agent relays tool reply back to LLM (via handler's client)
   - Session records the message being sent and received (via agent callbacks)
4. **Tool execution flow**:
   - Agent receives tool call from LLM response
   - Agent creates/gets tool instance (tools managed at agent level, not client level)
   - Tool executes (can access project manager via agent, can access session via agent)
   - Tool result is returned to agent
   - Agent adds tool reply message to `call.messages`
   - Agent continues conversation by calling `call.exec_chat()` again with tool results
   - This recurses until LLM gives final response (no more tool calls)
5. **Session records messages** - Session records tool execution messages (sent and received) via agent callbacks
   - Agent calls session methods to record tool messages
6. **Handler receives final response** - After all tool calls are handled, handler receives final response
   - Handler receives response via direct method call return (not via signals)
   - Handler processes response and calls session methods directly
- **Key Point:** Tool handler is tied to the agent, not the client. Agent manages tool execution and relays results back to LLM. Session records all messages (including tool calls/responses) via agent.

### Session-Agent Relationship
- **Session has `agent_name` property**: Identifies which agent to use from `manager.agents`
- **Manager holds registered agents**: `manager.agents` HashMap contains all available agents
- **Active agent lookup**: `manager.get_active_agent()` returns `manager.agents.get(session.agent_name == "" ? "just-ask" : session.agent_name)`
- **Agent can change**: `session.agent_name` can be updated to switch to a different agent
- **Agents are stateless**: Same agent instance can be used by multiple sessions

### Reply Handling
- **Option A**: Agent emits signals for replies (UI connects to signals)
- **Option B**: Agent uses callback functions (UI passes callbacks to agent)
- **Option C**: Hybrid (signals for events, callbacks for streaming)

**Recommendation**: Option C - Signals for reply events, callbacks for streaming chunks. Provides flexibility for both synchronous and asynchronous reply handling.

## Message Flow

**Current Flow (Before Refactoring):**
```
UI → Client → LLM API
LLM API → Client → UI
```

**New Flow (After Refactoring):**
```
Forward: Chat UI (ChatRequest) → History Manager → Session → Agent → AgentHandler → Client → LLM
Backward: LLM → Client (signals for non-agent usage, direct calls for agent infrastructure) → AgentHandler (direct method calls, NO signals) → Session (method calls) → History Manager (method calls/signals for UI) → Chat UI
```

**ChatRequest Object:**
- `session_id` (string) - Session identifier (empty for new session)
- `model_name` (string) - Model to use
- `connection_name` (string) - Connection to use
- `agent_name` (string) - Agent to use
- `chat_content` (string) - User's message content

**Key Points:**
- UI sends ChatRequest object to Manager
- Manager checks if session_id exists (if empty, creates new session)
- Manager fills in session_id and passes request to session
  - Session compares agent_name with current agent - if different, gets agent from manager.agents
- Session asks agent to create handler: `handler = agent.create_handler(request, session)`
- Session asks handler to handle request: `handler.handle_request_async(request)`
- Handler creates client from request (gets connection/model from request)
- **Consider**: Chat call sending data directly to handler rather than using signals
- **Only Client uses signals** (loosely coupled, no references to other components) OR sends data directly
- **Rest of chain uses direct method calls** (Handler → Session → Manager → Manager emits signal → UI)
- **Manager does NOT have reference to UI** - UI connects to manager signals
- **Cross-library relationships use base classes/interfaces** (Agent→Session, Session→Manager)
- **⚠️ UI Access Pattern**: UI should NOT access `Call.Chat` directly without Session context. All Chat access should go through Session (e.g., `session.chat`, `session.client`). This ensures proper session management and message tracking. When UI needs Chat properties, it should receive `SessionBase` from signals/methods and access Chat via `session.chat`.

**Detailed Flow:**
1. **UI → Manager**: Chat UI sends ChatRequest object to manager (e.g., `manager.send_request_async(request)`)
   - ChatRequest contains: session_id, model_name, connection_name, agent_name, chat_content
2. **Manager checks session**: Manager checks if request.session_id exists
   - If empty, creates new session
   - Fills in request.session_id
   - Passes request to session: `session.handle_request_async(request)`
3. **Session handles request**: Session receives ChatRequest
   - Compares request.agent_name with current session.agent_name
   - If different, gets agent from manager.agents: `agent = manager.agents.get(request.agent_name)`
   - Asks agent to create handler: `handler = agent.create_handler(request, this)`
   - Asks handler to handle request: `handler.handle_request_async(request)`
4. **Handler creates client**: Handler receives request from session
   - Creates client from request (gets connection/model from request)
   - Creates `Call.Chat` object with handler's client
   - **Tools are managed at agent level** (not client level) - agent creates/gets tool instances when needed
5. **Handler configures tools**: Handler calls `agent.configure_tools(call)` to configure/filter tools
6. **Handler builds messages**: Handler calls `agent.fill(call, request.chat_content)` / `agent.build_messages(call, request.chat_content)`:
   - **Agent builds message array**: Converts session message array and incoming request into array of messages ready to be sent to chat
   - Agent retrieves previous conversation messages from Session
   - Agent filters messages from Session to get API-compatible messages (system, user, assistant, tool)
   - Agent generates system prompt (if needed) → sets `call.system_content`
     - **For CodeAssistant:** System prompt is regenerated on each call to include current context (open files, workspace, etc.)
     - System prompt should NOT be cached - it must reflect current application state
     - **CodeAssistant uses simplified content generation**: Single string with placeholders, HashMap replacements, removes empty sections
   - Agent generates user prompt → sets `call.chat_content`
   - Agent adds messages to `call.messages` array in correct order (system, previous messages, new user message)
7. **Handler sends to LLM**: Handler calls `call.exec_chat()` which sends to LLM API via handler's client
   - `exec_chat()` handles tool calls automatically if LLM requests them:
     - Executes tools using `client.tools`
     - Adds tool results to `call.messages`
     - Automatically continues conversation with tool results
     - Recurses until final response (no more tool calls)
   - Tool execution emits `client.message_created()` signals for UI updates (for non-agent usage)
   - Handler receives final response via direct method call return (after all tool calls are handled)
   - **Important:** The Chat object's messages array is already fully prepared
   - Client should NOT modify the messages array - it just sends what handler prepared
   - **Consider**: Chat call sending data directly to handler rather than using signals?
8. **LLM responds**: LLM API responds (streaming or complete)
9. **Client sends data/signals**: Client receives response
   - **Option A**: Client emits signals (loosely coupled, no references to other components)
   - **Option B**: Client sends data directly to handler (no signals needed)
10. **Handler processes response**: Handler receives data/signals from client
    - **If signals**: Handler connects to client signals and processes
    - **If direct data**: Handler receives data directly from client
    - Handler calls session methods directly with results
11. **Session handles state**: Session receives chunks via `on_chunk()` and stores them
    - Session persists messages to disk
    - Session calls manager methods directly
12. **Manager emits signal**: Manager receives from session and emits signal (UI connects to manager signals - Manager does NOT have reference to UI)
13. **UI displays response**: UI receives signal and displays response
14. **Handler cleanup**: After request completes, handler calls `session.on_complete()` → Session calls `manager.on_complete()` → handler disposes client

**Streaming Flow:**
1. **UI → Manager**: Chat UI calls manager method with user input
2. **Manager creates handler**: Manager gets active agent, creates handler with session (handler gets client from session)
3. **Manager sends message**: Manager calls `handler.send_message_async(user_input)`
4. **Handler prepares Chat**: Handler creates `Call.Chat` object and prepares messages array (same as detailed flow)
5. **Handler sends to LLM**: Handler calls `call.exec_chat()` which sets up streaming with handler's client
6. **Client streams**: Client streams chunks from LLM API
7. **Client emits signals**: Client emits signals when receiving chunks (for non-agent usage, loosely coupled, no parent reference)
8. **Handler receives data via direct method calls**: Handler does NOT connect to client signals - uses direct method calls (e.g., polling or callbacks) and calls parent methods directly
9. **Direct method calls backwards**: Each chunk: Handler calls `session.on_chunk(chunk)` → Session calls `manager.on_chunk(chunk)` → Manager emits signal (UI connects to manager signals)
10. **Final response**: Handler calls `session.on_complete()` → Session calls `manager.on_complete()` → Manager emits signal (UI connects to manager signals)
11. **Session stores**: Session stores complete response (via `on_chunk()` callbacks)
12. **Handler cleanup**: Handler is disposed (no signal connections to disconnect - uses direct method calls)

**Reply Flow (Subsequent Messages):**
1. **UI → Manager**: Chat UI calls manager method with new user input
2. **Manager creates handler**: Manager gets active agent (from session.agent_name), creates handler with session (handler gets client from session)
3. **Manager sends message**: Manager calls `handler.send_message_async(new_user_input)`
4. **Handler creates Chat**: Handler creates new `Call.Chat` object
5. **Handler rebuilds messages**: Handler calls `agent.fill(call, new_user_input)` / `agent.build_messages(call, new_user_input)`:
   - **Agent builds message array**: Converts session message array and incoming request into array of messages ready to be sent to chat
   - Agent retrieves previous conversation messages from Session (Session maintains conversation state)
   - Agent filters messages from Session to get API-compatible messages (system, user, assistant, tool)
   - Agent generates system prompt (if needed) - regenerated on each call for CodeAssistant
   - Agent generates user prompt for new message
   - Agent adds messages to `chat.messages` array in correct order (system, previous messages, new user message)
6. **Handler sends to LLM**: Handler calls `call.exec_chat()` which sends to LLM via handler's client
7. **Continue normal flow**: Continue with direct method calls backwards (steps 10-16 from detailed flow)

## Naming Considerations

### Rename Agent and AgentHandler

**Consider renaming for clarity:**
- Current `BaseAgent` / `Agent` → **`AgentSchema`** (the template/schema, persistent)
- Current `AgentHandler` → **`Agent`** (the real agent instance, ephemeral per request)

**Rationale:**
- What we currently call "Agent" (BaseAgent) is really an agent schema/template - it defines how an agent works but doesn't handle requests
- What we currently call "AgentHandler" is the real agent instance - it's created per request and actually handles the conversation
- This naming would make the architecture clearer: `AgentSchema.create_agent()` returns `Agent` instance
- Tools would access session via: `this.chat_call.agent.session` (where `agent` is the Agent instance, not the schema)

**Impact:**
- Would require renaming across the codebase
- Better reflects the actual architecture
- Makes it clearer that schemas are persistent and agents are ephemeral

**Status**: ⏳ **TODO** - Consider during refactoring

## Future Enhancements

- Agent-specific tool configurations
- Agent state persistence
- Agent-to-agent communication
- Agent composition (agents that use other agents)
- Agent plugins/extensions
- Agent reply transformation (formatting, filtering, etc.)
- Agent reply caching

