# 1.10. Refactor Agents as Interface Between UI and Client

## Overview

Refactor the agent architecture so that agents act as the interface layer between the UI and the client, rather than being embedded within the client. This separation will make agents more flexible, allow for better UI integration, and enable dynamic agent creation and modification.

## Status

⏳ **TODO** - To be implemented.

## Implementation Todo Plan

### Phase 1: Agent Interface Refactoring
- [ ] Update `BaseAgent` class:
  - [ ] Add private `client` property (wrapped Client instance)
  - [ ] Add `send_message(string user_input)` method - synchronous, returns full response
  - [ ] Add `send_message_async(string user_input, Callback callback)` method - async with streaming support
  - [ ] Add `handle_reply(Response.Chat reply)` method - process and relay reply to UI
  - [ ] Add `handle_stream_chunk(string chunk)` method - process and relay streaming chunks to UI
  - [ ] Add reply callback/signal for UI to receive responses
  - [ ] Add internal method to create and prepare Chat object
  - [ ] Add internal method to build messages array (system + user messages)
  - [ ] Add internal conversation state management (store previous messages)
  - [ ] Remove dependency on client's `prompt_assistant`
  - [ ] Keep client instance private/internal - do not expose via getter
- [ ] Update `CodeAssistant` class:
  - [ ] Initialize with client instance in constructor
  - [ ] Override `send_message()` and `send_message_async()` to add system prompts
  - [ ] Override `handle_reply()` and `handle_stream_chunk()` to process agent-specific responses
  - [ ] Handle tool calls through agent layer
  - [ ] Configure tools for chat (set chat.tools property)
  - [ ] Relay tool results and final responses back to UI
- [ ] Update `JustAsk` class:
  - [ ] Initialize with client instance in constructor
  - [ ] Override `send_message()` and `send_message_async()` to pass through directly
  - [ ] Override `handle_reply()` and `handle_stream_chunk()` to pass through directly (no processing)
  - [ ] Minimal changes needed, mostly pass-through behavior
- [ ] Build and verify Phase 1 compiles

### Phase 2: Client Simplification
- [ ] Update `Client` class:
  - [ ] Remove `prompt_assistant` property
  - [ ] Remove prompt generation logic from client
  - [ ] Update `chat()` method to accept pre-prepared Chat object (or just execute it)
  - [ ] Ensure client does NOT modify messages array (use what agent prepared)
  - [ ] Keep tool execution at client level (client has access to ProjectManager, file system, etc.)
- [ ] Update `Call.Chat` class:
  - [ ] Remove dependency on `client.prompt_assistant`
  - [ ] Ensure `exec_chat()` works with pre-prepared messages array
  - [ ] Ensure `reply()` method can be called by agent to rebuild conversation
- [ ] Build and verify Phase 2 compiles

### Phase 3: Manager Updates
- [ ] Update `History.Manager` class:
  - [ ] Keep agent registration
  - [ ] Update `get_active_agent()` to return agent with client
  - [ ] Remove `active_agent_name` if not needed
  - [ ] Ensure agents are created with client instances
  - [ ] Update `new_client()` method:
    - [ ] Create client instance
    - [ ] Create agent with client instance
    - [ ] Register agent
- [ ] Build and verify Phase 3 compiles

### Phase 4: UI Integration
- [ ] Update `ChatInput` class:
  - [ ] Change to send messages to `manager.get_active_agent().send_message_async()`
  - [ ] Register callback to receive replies from agent
  - [ ] Handle streaming chunks from agent callback
  - [ ] Remove direct client access
  - [ ] Agent handles all client interaction and reply relaying
- [ ] Update `Window` class:
  - [ ] Ensure agents are created with client instances
  - [ ] UI interacts with agents, not clients directly
  - [ ] UI receives replies through agent callbacks/signals
- [ ] Build and verify Phase 4 compiles

### Phase 5: Cleanup
- [ ] Remove old code paths:
  - [ ] Remove `client.prompt_assistant` usage from all files
  - [ ] Remove direct client.chat() calls from UI
  - [ ] Remove any remaining client access from UI components
- [ ] Verify all functionality works with new architecture
- [ ] Build final version and test

## Related Plans

- **1.7** - Agent Management System (current agent implementation)
- **1.11** - libgjs for Agents (dynamic agent creation)
- **1.3.9** - Agent Configuration (agent configuration UI)

## Current Architecture

**Current State:**
- Agents are embedded within the client via `client.prompt_assistant`
- Client directly uses agent's `generate_system_prompt()` and `generate_user_prompt()` methods
- Manager stores agents and sets active agent on client
- UI selects agent, which updates `manager.active_agent_name`, which then sets `client.prompt_assistant`

**Problems:**
- Tight coupling between client and agents
- Agents are passive prompt generators
- Difficult to add agent-specific UI or behavior
- Client must know about agent structure

## Proposed Architecture

**New State:**
- Agents become the primary interface between UI and client
- Agents wrap or own the client instance
- UI interacts with agents, agents interact with client
- Agents can provide UI widgets, handle tool calls, manage state
- Client becomes a lower-level API that agents use

**Benefits:**
- Clear separation of concerns
- Agents can have their own state and behavior
- Easier to add agent-specific features
- Better support for dynamic agent creation
- Agents can manage their own tools and configurations

## Architecture Changes

### Agent Interface

**New Agent Responsibilities:**
- Own or wrap a client instance
- Handle chat requests from UI
- Relay replies from client back to UI
- Manage agent-specific tools
- Provide UI widgets (already implemented via `get_widget()`)
- Handle agent-specific state and configuration
- Process messages before/after client calls
- Handle streaming responses from client to UI

**Agent Methods:**
- `send_message(string user_input)` - Send message through agent to client, returns response
- `send_message_async(string user_input, Callback callback)` - Async version with callback for streaming
- `handle_reply(string reply)` - Process and relay reply from client to UI
- `handle_stream_chunk(string chunk)` - Process and relay streaming chunks from client to UI
- `get_widget()` - Provide UI widget (already exists)

**Note:** Agents should NOT expose their internal client instance or tools directly. All client and tool interactions should be handled internally by the agent. This maintains proper encapsulation and ensures agents are the only interface between UI and client.

### Client Changes

**Client Simplification:**
- Remove `prompt_assistant` property from Client
- Client becomes a lower-level API
- Client focuses on API communication, not prompt generation
- Prompt generation moves to agent layer

**Client Methods:**
- Keep existing API methods (chat, stream, etc.)
- Remove agent-specific logic
- Tools remain at client level (or move to agent level?)

### Manager Changes

**Manager Updates:**
- Keep agent registration and management
- Remove `active_agent_name` (agents manage their own state)
- Manager provides agent selection to UI
- Manager coordinates between agents and sessions

**Manager Methods:**
- `get_active_agent()` - Get currently active agent
- `set_active_agent(BaseAgent agent)` - Set active agent
- `agent_activated` signal - Emit when agent changes (already exists)

### UI Changes

**UI Updates:**
- UI interacts with agents, not directly with client
- Chat input sends messages to active agent
- Agent handles routing to client
- Agent relays replies back to UI (full round-trip: UI → Agent → Client → Agent → UI)
- Agent handles streaming responses to UI
- Agent provides UI widgets (already implemented)

**ChatInput Changes:**
- Send messages to `manager.get_active_agent().send_message_async()`
- Register callback to receive replies from agent
- Agent handles client interaction internally
- Agent processes and relays replies/streams back to UI callback
- Remove direct client access from UI

### Session Changes

**Session Updates:**
- Sessions may need to store agent reference
- Or sessions use manager's active agent
- Agent state may need to be session-specific

## Implementation Details

### Phase 1: Agent Interface Refactoring

**1. Update BaseAgent**
- Add `client` property (owned or wrapped Client instance)
- Add `send_message(string user_input)` method - synchronous, returns full response
- Add `send_message_async(string user_input, Callback callback)` method - async with streaming support
- Add `handle_reply(string reply)` method - process and relay reply to UI
- Add `handle_stream_chunk(string chunk)` method - process and relay streaming chunks to UI
- Add reply callback/signal for UI to receive responses
- Remove dependency on client's `prompt_assistant`
- Keep client instance private/internal - do not expose via getter
- **Agent creates Chat object internally:**
  - Agent creates `Call.Chat` object with client reference
  - Agent sets chat properties (model, options, tools, etc.)
  - Agent generates system/user prompts and builds messages array
  - Agent adds system message to `chat.messages` (if system_content set)
  - Agent adds user message to `chat.messages` (with modified chat_content)
- **Agent maintains conversation state:**
  - Agent stores previous messages for reply context
  - Agent rebuilds messages array for subsequent messages
- **Agent handles tool configuration:**
  - Agent sets `chat.tools` property before calling client
  - Agent can filter/configure which tools are available
- Agent calls `client.chat()` or `client.stream()` with prepared Chat object
- **Important:** Client should NOT modify the messages array - it uses what agent prepared
- Agent receives responses from client and relays to UI

**2. Update CodeAssistant**
- Initialize with client instance
- Override `send_message()` and `send_message_async()` to add system prompts
- Override `handle_reply()` and `handle_stream_chunk()` to process agent-specific responses
- Handle tool calls through agent layer
- Relay tool results and final responses back to UI
- Maintain existing behavior but through new interface

**3. Update JustAsk**
- Initialize with client instance
- Override `send_message()` and `send_message_async()` to pass through directly
- Override `handle_reply()` and `handle_stream_chunk()` to pass through directly (no processing)
- Minimal changes needed, mostly pass-through behavior

### Phase 2: Client Simplification

**1. Remove prompt_assistant from Client**
- Remove `prompt_assistant` property
- Remove prompt generation logic from client
- Client becomes pure API interface

**2. Update Client Methods**
- `chat()` method accepts pre-generated prompts
- Or client methods accept agent context
- Tools remain at client level (or move to agent?)

### Phase 3: Manager Updates

**1. Update Manager**
- Keep agent registration
- Update `get_active_agent()` to return agent with client
- Remove `active_agent_name` if not needed
- Ensure agents have client instances

**2. Update new_client()**
- Create client instance
- Create agent with client instance
- Register agent
- Return agent (or keep client separate?)

### Phase 4: UI Integration

**1. Update ChatInput**
- Send messages to `manager.get_active_agent().send_message_async()`
- Register callback to receive replies from agent
- Handle streaming chunks from agent callback
- Remove direct client access
- Agent handles all client interaction and reply relaying

**2. Update Window**
- Ensure agents are created with client instances
- UI interacts with agents, not clients directly
- UI receives replies through agent callbacks/signals

## Files to Modify

### Core Agent Files
- `libollmchat/Prompt/BaseAgent.vala` - Add client property, send_message method
- `libollmchat/Prompt/CodeAssistant.vala` - Update to use new interface
- `libollmchat/Prompt/JustAsk.vala` - Update to use new interface

### Client Files
- `libollmchat/Client.vala` - Remove prompt_assistant, simplify API
- `libollmchat/Call/Chat.vala` - Update to work without prompt_assistant

### Manager Files
- `libollmchat/History/Manager.vala` - Update agent management, ensure agents have clients

### UI Files
- `libollmchatgtk/ChatInput.vala` - Send messages to agent instead of client
- `ollmchat/Window.vala` - Update agent initialization with client instances

## Migration Strategy

1. **Add new code** - Implement new agent interface methods alongside existing code
2. **Build** - Ensure new code compiles successfully
3. **Replace old calls & remove old code** - Update UI to use new interface, then remove old code paths

## Design Considerations

### Client Ownership
- **Option A**: Agent owns client instance (agent creates/manages client)
- **Option B**: Agent wraps client instance (client created externally, passed to agent)
- **Option C**: Agent references client (client managed separately, agent uses reference)

**Recommendation**: Option B - Agent wraps client, allows for client reuse and better separation

### Tool Management
- **Option A**: Tools remain at client level (shared across agents)
- **Option B**: Tools move to agent level (agent-specific tools)
- **Option C**: Hybrid (base tools at client, agent-specific at agent)

**Recommendation**: Option C - Base tools at client, agent-specific tools at agent level

**How Tools Fit In:**
- Agent creates Chat object and sets `chat.tools` property before calling client
- Agent can filter/configure which tools are available for this specific chat
- When client receives tool_calls in response:
  1. Client executes tools (using tools from chat.tools)
  2. Client creates tool messages and adds to chat.messages array
  3. Client calls `chat.toolsReply()` to continue conversation with tool results
  4. Client returns updated Response.Chat to agent
- Agent receives Response.Chat with tool results
- Agent processes tool results (may filter, transform, or add context)
- Agent rebuilds conversation state including tool messages
- Agent relays final response to UI
- **Key Point:** Agent controls which tools are available and how tool results are processed, but tool execution happens at client level (client has access to ProjectManager, file system, etc.)

### Session-Agent Relationship
- **Option A**: Session stores agent reference
- **Option B**: Session uses manager's active agent
- **Option C**: Each session has its own agent instance

**Recommendation**: Option B - Sessions use manager's active agent, simpler state management

### Reply Handling
- **Option A**: Agent emits signals for replies (UI connects to signals)
- **Option B**: Agent uses callback functions (UI passes callbacks to agent)
- **Option C**: Hybrid (signals for events, callbacks for streaming)

**Recommendation**: Option C - Signals for reply events, callbacks for streaming chunks. Provides flexibility for both synchronous and asynchronous reply handling.

## Message Flow

**Current Flow (Before Refactoring):**
```
UI → Client → LLM API
LLM API → Client → UI
```

**New Flow (After Refactoring):**
```
UI → Agent → Client → LLM API
LLM API → Client → Agent → UI
```

**Detailed Flow:**
1. UI calls `agent.send_message_async(user_input, callback)`
2. Agent creates `Call.Chat` object internally
3. Agent generates system/user prompts and adjusts messages array:
   - Agent calls `generate_system_prompt()` (if needed) → sets `chat.system_content`
   - Agent calls `generate_user_prompt(user_input)` → modifies `chat.chat_content`
   - Agent adds system message to `chat.messages` array (if system_content set)
   - Agent adds user message to `chat.messages` array (with modified chat_content)
4. Agent calls `client.chat()` or `client.stream()` with the prepared Chat object
   - **Important:** The Chat object's messages array is already fully prepared
   - Client should NOT modify the messages array - it just sends what agent prepared
5. Client sends to LLM API (using the pre-prepared messages)
6. LLM API responds (streaming or complete)
7. Client receives response and returns `Response.Chat` to agent
8. Agent processes response (agent-specific logic)
9. Agent rebuilds conversation state:
   - Agent adds assistant response to internal message history
   - Agent maintains conversation context for next message
10. Agent calls UI callback/signal with processed response
11. UI receives and displays response

**Streaming Flow:**
1. UI calls `agent.send_message_async(user_input, stream_callback)`
2. Agent creates `Call.Chat` object and prepares messages array (same as detailed flow)
3. Agent sets up streaming with client (passes prepared Chat object)
4. Client streams chunks from LLM API
5. Each chunk: Client → Agent → UI (via stream_callback)
6. Final response: Client → Agent → UI (via completion callback)
7. Agent rebuilds conversation state with complete response

**Reply Flow (Subsequent Messages):**
1. UI calls `agent.send_message_async(new_user_input, callback)`
2. Agent creates new `Call.Chat` object
3. Agent rebuilds conversation history:
   - Agent retrieves previous conversation messages from internal state
   - Agent adds previous assistant response(s) to `chat.messages` array
   - Agent generates system/user prompts for new message
   - Agent adds new user message to `chat.messages` array
4. Agent calls `client.chat()` or `client.stream()` with rebuilt Chat object
5. Continue with normal flow (steps 5-11 from detailed flow)

## Future Enhancements

- Agent-specific tool configurations
- Agent state persistence
- Agent-to-agent communication
- Agent composition (agents that use other agents)
- Agent plugins/extensions
- Agent reply transformation (formatting, filtering, etc.)
- Agent reply caching

