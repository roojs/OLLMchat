# 1.3. Multiple Client Configuration

## Overview

Add ability to configure multiple clients (e.g., different Ollama instances, OpenAI, etc.) and switch between them. Extends plan 1.4 (Client Configuration Setup) with support for managing multiple server connections.

## Status

✅ **COMPLETE** - All features implemented and complete

## Related Plans

- **1.3** - Configuration Overview
- **1.3.1** - Configuration Classes
- **1.3.2** - Configuration Interface
- **1.4** - Client Configuration Setup (bootstrap and basic config)

## Implementation Details

### Connection Settings
- **Multiple Connections**: Support multiple server connections
- **Connection Properties**:
  - Name/alias (e.g., "Local Ollama", "OpenAI", "Remote Server")
  - URL (e.g., `http://127.0.0.1:11434/api`)
  - API Key (optional, plain text storage)
  - Default connection flag
  - Connection test/validation
- **Keying**: Connections keyed by URL (unlikely to have two systems on same URL)

### Connection Management UI
- **Connections Page**: List view displaying all configured connections
  - Shows connection name, URL, and default status
  - Add button to create new connection
  - Edit button for each connection
  - Delete button for each connection
  - Set Default button for each connection
- **Edit Connection Dialog**: Dialog for creating/editing connections
  - Name/alias field
  - URL field
  - API Key field (optional)
  - Test Connection button (verifies connection before saving)
  - Save/Cancel buttons

### System Models Management UI
- **System Models Page**: Page for managing models used for system services
  - Lists system model configurations: default, title, embed, analysis
  - Shows connection, model name, and options for each
  - Edit button for each system model
- **Model Config Dialog**: Dialog for configuring system models (merged dialog with options)
  - Connection selector (dropdown of available connections)
  - Model selector (dropdown of models from selected connection)
  - Options editor (using Call.Options for runtime options: temperature, top_p, top_k, num_ctx, etc.)
  - Save/Cancel buttons

### Configuration Storage Format (config.2.json)
```json
{
  "connections": {
    "http://127.0.0.1:11434/api": {
      "name": "Local Ollama",
      "url": "http://127.0.0.1:11434/api",
      "api_key": "",
      "default": true
    },
    "https://api.example.com": {
      "name": "Remote Server",
      "url": "https://api.example.com",
      "api_key": "plain_text_key",
      "default": false
    }
  },
  "models": {
    "default": {
      "connection": "http://127.0.0.1:11434/api",
      "model": "",
      "options": {
        "temperature": -1.0,
        "top_p": -1.0,
        "top_k": -1,
        "num_ctx": -1
      }
    },
    "title": {
      "connection": "http://127.0.0.1:11434/api",
      "model": ""
    },
    "embed": {
      "connection": "http://127.0.0.1:11434/api",
      "model": ""
    },
    "analysis": {
      "connection": "http://127.0.0.1:11434/api",
      "model": ""
    }
  },
  "model_options": {
    "default": {
      "temperature": 0.7,
      "top_p": 0.9,
      "top_k": 40,
      "num_ctx": 2048
    },
    "llama3": {
      "temperature": 0.5,
      "num_ctx": 4096
    }
  }
}
```

**Note**: The `default_connection` is determined by finding the connection with `"default": true` in the connections object.

### Security Considerations
- **API Key Storage**: Store API keys as plain text (not sensitive data)
- **Validation**: Test connections before saving

### Multiple Clients Architecture
- Support for multiple clients
- Client selection/switching mechanism
- Each model configuration references a connection by URL
- Default connection determined by connection with `"default": true` flag

### Use Cases
- Connect to different Ollama instances
- Switch between Ollama and OpenAI
- Manage API keys for different services
- Configure different models per client

### Files to Create
- `libollmchat/Config2.vala` - Config reader for version 2 format (config.2.json)
- `libollmchat/Settings/Connection.vala` - Connection configuration object (name, url, api_key, default)
- `libollmchat/Settings/ModelConfig.vala` - Model configuration object (connection, model, options) - for default, title, embed, analysis
- `ollmchat/Settings/ConnectionsPage.vala` - Connections settings page (lists connections)
- `ollmchat/Settings/EditConnectionDialog.vala` - Dialog for creating/editing a connection
- `ollmchat/Settings/SystemModelsPage.vala` - System models settings page (manages default, title, embed, analysis)
- `ollmchat/Settings/ModelConfigDialog.vala` - Dialog for configuring system models (connection, model, options - merged dialog)

**Note**: The `model_options` section uses the existing `Call.Options` class for default and per-model overrides.

### Files to Modify
- `libollmchat/Config.vala` - Extend for multiple connections support, models, model_options using the new settings objects
- `libollmchat/Client.vala` - Support multiple client instances
- `libollmchatgtk/ChatWidget.vala` - Support client switching

### Implementation Notes
- Review current Client creation and configuration
- Design configuration storage format (extends 1.4 config format)
- Add UI for client management
- Update ChatWidget to support client switching

## Completion Summary

✅ **All features complete** - The Multiple Client Configuration system has been fully implemented:
- Multiple connections support with connection management UI
- Connection settings with name, URL, API key, and default flag
- ConnectionsPage UI component for managing connections
- EditConnectionDialog for creating/editing connections
- System models management with ModelConfigDialog
- Configuration storage in Config2 with connections map
- Client switching and multiple client instances support
