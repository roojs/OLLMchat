# 5.4. PDF Extraction (libpoppler)

## Status

⏳ **PENDING** – Outside scope of 2.20.3 for the time being.

## Purpose

Enable indexing and analysis of PDF files by converting them to images and running them through the same vision pipeline as standard images (2.20.3). PDFs become searchable by content via text descriptions generated by vision models.

## Approach

- Use **libpoppler** to render PDF pages to images.
- Treat each rendered page (or selected pages) as an image.
- Run the resulting image(s) through the **same image pipeline** as 2.20.3:
  - Send to vision model (e.g. Ollama vision API).
  - Get text description.
  - Vectorize description and store in `vector_metadata` (or use in chat/analysis as per 2.20.3).
- No separate “PDF text extraction” path: **PDF → image(s) via libpoppler → same image call as a standard image**.

## Flow

1. Detect PDF file (e.g. by extension `.pdf`).
2. Use libpoppler to convert PDF page(s) to image(s) (e.g. one image per page, or first N pages).
3. For each image: pass to the same vision/analysis path as in 2.20.3 (image description, vectorization, or chat with images).
4. Store/use results consistently with image handling (e.g. `element_type = 'image'` or a PDF-specific type with description).

## Dependencies

- **libpoppler** (and likely poppler-glib for Vala bindings).
- Same vision model integration and message/serialization design as 2.20.3 (binary file / image analysis plan).

## Related Plans

- **2.20.3-binary-file-image-analysis.md** – Image analysis, vision API, and chat image support; PDF extraction reuses the same image pipeline.
- 2.20-codebase-scanner-improvements.md – Parent codebase scanner context.
