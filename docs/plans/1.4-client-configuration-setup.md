# 1.4. Client Configuration Setup

## Overview

Configuration system for setting up models, options, and client connections. Includes bootstrap dialog for initial setup and refactored chat options management.

## Status

â³ **TODO** - To be implemented.

## Implementation Details

### Phase 1: Bootstrap Only Section

#### Bootstrap Dialog UI
- **Framework**: Use libadw (Adwaita) preferences dialog
- **Structure**: Single header/preferences page
- **Header Title**: "Set up initial connect"
- **Description**: 
  > First step is to connect to a ollama or openai server (this is really designed for locally hosted LLMs, however you should be able to use online LLMs if you have an account)

#### Dialog Fields
1. **Host Field**
   - Label: "Host"
   - Placeholder: `http://127.0.0.1:11434/api`
   - Input type: Text entry
   - Required: Yes

2. **API Key Field**
   - Label: "API Key"
   - Description: "(optional) only need for online services or if you serve via nginx proxy"
   - Input type: Password entry (or text entry with visibility toggle)
   - Required: No

3. **Next Button**
   - Action: Validate and test connection
   - Behavior:
     - Button locks (disabled) when clicked
     - Shows Adwaita spinner while checking server
     - Calls version endpoint to verify connection
     - On success: Save config and proceed
     - On failure: Show error, unlock button

#### Connection Testing
- **Method**: Use GET `/api/version` endpoint
- **Purpose**: Verify server is reachable and responding
- **Reference**: https://docs.ollama.com/api-reference/get-version
- **Response**: Expects `{ "version": "x.x.x" }` format
- **Error Handling**: 
  - Network errors (connection refused, timeout)
  - Invalid response format
  - Authentication errors (if API key required)

#### Client API Support
- **New Method**: Add `version()` method to `Client` class
- **Implementation**: 
  - Create `Call.Version` class (similar to `Call.Models`)
  - Return version string from server
  - Handle errors appropriately
- **Usage**: Called during bootstrap to verify connection

#### Bootstrap Flow
1. First run: Show bootstrap dialog (libadw preferences dialog)
2. User enters host (with default placeholder)
3. User optionally enters API key
4. User clicks "Next" button
5. Button locks, spinner shows
6. System calls `GET /api/version` to test connection
7. On success: Save config as first default client, close dialog
8. On failure: Show error message, unlock button for retry
- **Scope**: Bootstrap only handles initial client setup, not ongoing configuration

### Phase 2: Chat Options Object

#### ChatOptions Class
- **Purpose**: Separate chat-specific options from Client class
- **Initialization**: Initialize with standard/default options
- **Properties to Extract**:
  - `model` - Model name to use
  - `stream` - Whether to stream responses
  - `format` - Response format (json, schema, etc.)
  - `think` - Whether to return thinking output
  - `keep_alive` - Model keep-alive duration
  - Runtime options (seed, temperature, top_p, top_k, num_predict, repeat_penalty, num_ctx, stop)

#### Standard Options
- Default values should match current Client defaults
- Options should be easily serializable for config storage
- Options should support per-model overrides (future)

#### Integration with Client
- Client class should use ChatOptions object
- Chat methods should accept ChatOptions (with defaults from Client)
- Allow overriding options per-chat call
- Maintain backward compatibility where possible

### Phase 3: Configuration Persistence

#### Save Configuration
- Save any changes made to standard Ollama config
- Persist client connection settings (url, api_key)
- Persist chat options (model, runtime options)
- Save to standard config location (e.g., ~/.config/ollmchat/config.json or similar)
- Auto-save on changes or manual save option

#### Load Configuration
- Load configuration on startup
- Apply saved settings to Client instance
- Handle missing/invalid config gracefully
- Support config migration if format changes

### Phase 4: Single Client Support (Initial)

#### Single Client Implementation
- Support for single client to start with
- Client configuration stored as default/single client
- Simple config structure for single client:
  ```json
  {
    "default_client": {
      "url": "http://localhost:11434/api",
      "api_key": null,
      "chat_options": {
        "model": "",
        "stream": false,
        "temperature": -1.0,
        ...
      }
    }
  }
  ```

#### Client Management
- Single Client instance managed by application
- Client initialized from config on startup
- Changes to Client properties saved to config

### Phase 5: Multiple Clients Support (Future)

#### Multiple Clients Architecture
- Later support for multiple clients
- Per-model options support
- Client selection/switching mechanism
- Config structure expansion:
  ```json
  {
    "clients": {
      "default": { ... },
      "local": { ... },
      "remote": { ... }
    },
    "default_client": "default",
    "model_options": {
      "llama3": { "temperature": 0.7, ... },
      "mistral": { "temperature": 0.5, ... }
    }
  }
  ```

#### Per-Model Options
- Override chat options per model
- Merge model-specific options with client defaults
- Priority: per-chat override > per-model options > client defaults

### Files to Create/Modify

#### New Files
- `libollmchat/ChatOptions.vala` - Chat options class
- `libollmchat/Config.vala` - Configuration management
- `libollmchat/Bootstrap.vala` - Bootstrap dialog logic (or in UI layer)

#### Modified Files
- `libollmchat/Client.vala` - Refactor to use ChatOptions, add `version()` method
- `libollmchat/Call/Chat.vala` - Update to use ChatOptions
- `libollmchat/Call/Version.vala` - New call class for version endpoint (or add to existing Call structure)
- Configuration storage system
- Bootstrap dialog UI - libadw preferences dialog implementation

### Integration
- Works with 1.3 (Multiple Client Configuration) - Phase 5 aligns with this
- Config format designed to support multiple clients from the start (even if Phase 4 only uses one)
- Bootstrap is separate concern from ongoing configuration management
