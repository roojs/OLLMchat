# 2.10. Codebase Search Tool

## Overview

Implementation of a semantic codebase search tool using vector embeddings and FAISS. The code will be migrated from the existing `VectorSearch/` directory into a new `libocvector` library with two main components: **Indexing** and **Search**. The library uses `libocfiles` (OLLMfiles namespace) for file tracking and project management, providing file management without GTK/git dependencies.

**Architecture Reference:** See `docs/plans/2.10-vector-storage-architecture.md` for detailed information about:
- What's stored in FAISS vs SQL database
- Minimum schema requirements (6 fields)
- Why certain fields are/aren't stored
- Data flow and query patterns

## Status

üöß **IN PROGRESS** - Foundation and FAISS migration completed. Core indexing and search components pending.

## Todo List

### Phase 1: Foundation & Structure
- [x] Create `libocvector/` directory structure
- [x] Set up `libocvector/meson.build` for the library
- [x] Create namespace structure (`OLLMvector.Indexing`, `OLLMvector.Search`, `OLLMvector.Tools.Search`, `OLLMvector.Tool`) - *Partially done: OLLMvector namespace exists, subdirectories not yet created*
- [x] Add `libocfiles` dependency to `libocvector/meson.build` - *Uses OLLMfiles namespace for file tracking*

### Phase 2: FAISS Migration
- [x] Migrate `VectorSearch/Index.vala` ‚Üí `libocvector/Index.vala` (FAISS namespace)
- [x] Migrate `VectorSearch/Database.vala` ‚Üí `libocvector/Database.vala`
- [x] Update Database namespace to `OLLMvector`
- [x] Create FAISS C++ wrapper (`faiss_c_wrapper.cpp`) - *Additional work not in original plan*
- [ ] Integrate Database with `OLLMfiles.File` for metadata tracking - *TODOs in code indicate this is pending*

### Phase 3: Analysis Layer Implementation
- [x] Create `libocvector/Indexing/Analysis.vala`
- [x] Create `resources/ocvector/result-schema.json` with JSON schema for structured outputs
- [x] Add `format_obj` property to `Call.Chat` class (type: `Json.Object?`)
- [x] Update `Call.Chat.serialize_property()` to use `format_obj` when set (output JSON object instead of string `format`)
- [x] Implement helper method to load JSON schema from `resources/ocvector/result-schema.json`
- [x] Implement LLM API integration with structured outputs (using `format_obj`)
- [x] Implement prompt generation for code analysis
- [x] Implement JSON response parsing and validation
- [x] Integrate with `OLLMfiles` for file tracking
- [x] Add error handling and fallback strategies

### Phase 4: Vector Building Implementation
**Note:** This phase works on **one file at a time** (processes `CodeFile` from Analysis layer). Phase 5 (Indexer Orchestration) will handle multiple files and project-wide indexing.

**Reference:** See `docs/plans/2.10-vector-storage-architecture.md` for detailed schema and architecture decisions.

- [ ] Create `libocvector/Indexing/VectorBuilder.vala`
  - Takes `CodeFile` from Analysis layer (single file with elements)
  - Formats each `CodeElement` into document for vectorization
  - Generates embeddings and stores in FAISS
  - Stores metadata in SQL database
- [ ] Implement document formatting for vectorization
  - Format: type, name, file, lines, description, parameters, return type, dependencies, code snippet
  - See plan lines 239-323 for detailed format specification
  - Apply smart code snippet truncation based on element type (classes vs methods)
- [x] Implement Ollama embeddings API integration (`/api/embeddings`)
  - ‚úÖ Done: `Database.vala` uses `ollama.embed()` method
  - ‚úÖ Done: `libollmchat.Client.embed()` and `embed_array()` available
- [ ] Implement batch processing for vector generation
  - ‚ö†Ô∏è Partially done: `Database.add_documents()` accepts multiple texts
  - ‚ö†Ô∏è Currently processes embeddings one-by-one in loop
  - ‚ö†Ô∏è Should use `embed_array()` for true batch processing (10-20 documents per batch)
- [x] Implement FAISS vector storage
  - ‚úÖ Done: `libocvector/Index.vala` implements FAISS with `add_vectors()`
  - ‚úÖ Done: `Database.vala` uses `index.add_vectors(vector_batch)`
- [ ] Implement metadata storage in SQL database
  - Schema: `vector_id`, `file_id`, `start_line`, `end_line`, `element_type`, `element_name`
  - See `docs/plans/2.10-vector-storage-architecture.md` for minimal schema (6 fields)
  - Integrate with `libocsqlite` for SQL storage
  - Store metadata when vectors are added (link vector_id to file_id + line range)
  - Implement lookup for search results (vector_id ‚Üí file path + code snippet)

### Phase 5: Indexer Orchestration
- [ ] Create `libocvector/Indexing/Indexer.vala`
- [ ] Integrate Analysis and VectorBuilder components
- [ ] Implement incremental update logic
- [ ] Implement file change detection using `OLLMfiles.File.mtime`
- [ ] Implement project-wide indexing using `OLLMfiles.Folder`

### Phase 6: Search Layer Implementation
- [ ] Create `libocvector/Search/Searcher.vala`
- [ ] Migrate and refactor `VectorSearch/CodeSearch.vala`
- [ ] Implement query vectorization (convert queries to embeddings)
- [ ] Implement FAISS similarity search
- [ ] Add GPU support detection and usage
- [ ] Implement CPU fallback
- [ ] Create `libocvector/Search/QueryProcessor.vala`
- [ ] Implement query type detection and routing
- [ ] Implement result ranking and formatting

### Phase 7: File Tracking Integration
- [x] Add `libocfiles` dependency to `libocvector/meson.build` - *Uses OLLMfiles namespace*
- [ ] Integrate with `OLLMfiles.File` and `OLLMfiles.Folder` for file tracking
- [ ] Add vector indexing metadata fields to `OLLMfiles.File` (or create extension/wrapper if needed)
- [ ] Implement metadata storage in database (link vector IDs to file IDs)
- [ ] Store vector position, indexing status, and timestamps per file
- [ ] Implement change detection using `OLLMfiles.File.mtime`
- [ ] Use `OLLMfiles.ProjectManager` for project-wide file discovery

### Phase 8: Command-Line Tools
- [x] Create `examples/oc-vector-index.vala` (single file indexing tool)
- [ ] Create `libocvector/Tools/SearchTool.vala`
- [ ] Create `examples/oc-vector-search.vala` (search tool executable)
- [x] Implement command-line argument parsing - *Basic version implemented in oc-vector-index*
- [ ] Add progress display for indexing
- [ ] Add result formatting for search output

### Phase 9: OLLM Tool Integration
- [ ] Create `libocvector/Tool/CodebaseSearchTool.vala`
- [ ] Extend `OLLMchat.Tool.Interface`
- [ ] Implement `execute()` method for tool calling
- [ ] Implement structured result format for LLM agents
- [ ] Add to `libollmchat` tool registry
- [ ] Integrate with permission system

### Phase 10: Build System & Dependencies
- [x] Update root `meson.build` to include `libocvector` subdirectory
- [x] Add dependencies to `libocvector/meson.build` (libocsqlite, libollmchat, libocfiles, FAISS)
- [x] Note: `libocfiles` is used as a dependency (no need to copy FileBase structure)
- [x] Generate VAPI files for `libocvector` - *Generated via meson.build*
- [ ] Generate GIR files for `libocvector` - *Commented out in meson.build, pending implementation*
- [x] Update library dependencies in consuming projects - *examples/meson.build updated*
- [x] Update VAPI dependencies

### Phase 11: Testing
- [ ] Test indexing with various codebases (Vala, Python, JavaScript, etc.)
- [ ] Test search functionality with different query types
- [ ] Test file change detection and re-indexing
- [ ] Test command-line tools (`oc-vector-index`, `oc-vector-search`)
- [ ] Test OLLM tool integration
- [ ] Test GPU vs CPU search performance
- [ ] Test incremental updates
- [ ] Test structured outputs reliability
- [ ] Test batch processing for vectorization
- [ ] Test error handling and fallbacks

### Phase 12: Cleanup & Documentation
- [ ] Remove or deprecate `VectorSearch/` directory
- [ ] Update project documentation
- [ ] Add code comments and documentation
- [ ] Create usage examples
- [ ] Document API for library consumers

## Architecture

### Library Structure: `libocvector`

The vector search functionality will be organized as a new library `libocvector` with the following structure:

```
libocvector/
‚îú‚îÄ‚îÄ meson.build
‚îú‚îÄ‚îÄ Files/                      # FileBase structure (copied from liboccoder, no dependency)
‚îÇ   ‚îú‚îÄ‚îÄ FileBase.vala          # Base class for File and Folder
‚îÇ   ‚îú‚îÄ‚îÄ File.vala              # File class
‚îÇ   ‚îî‚îÄ‚îÄ Folder.vala            # Folder class
‚îú‚îÄ‚îÄ Indexing/
‚îÇ   ‚îú‚îÄ‚îÄ Analysis.vala          # Code and documentation analysis
‚îÇ   ‚îú‚îÄ‚îÄ VectorBuilder.vala      # Vector generation and FAISS storage
‚îÇ   ‚îî‚îÄ‚îÄ Indexer.vala            # Main indexing orchestrator
‚îú‚îÄ‚îÄ Search/
‚îÇ   ‚îú‚îÄ‚îÄ Searcher.vala           # Search functionality with GPU support
‚îÇ   ‚îî‚îÄ‚îÄ QueryProcessor.vala     # Query processing and result formatting
‚îî‚îÄ‚îÄ Tool/
    ‚îî‚îÄ‚îÄ CodebaseSearchTool.vala  # OLLM tool integration
```

**Note**: The `Files/` directory contains a copy of the FileBase structure from `liboccoder`. This avoids dependency issues while maintaining the same file/folder tracking capabilities. The code is based on `liboccoder.Files` but exists independently in `libocvector.Files` namespace.

### Component 1: Indexing

The indexing component consists of two layers:

#### Layer 1: Analysis
- **Purpose**: Process code files and send them to LLM to generate structured JSON data for vector generation
- **Input**: 
  - Code files (via `OLLMfiles.File` and `OLLMfiles.Folder`)
  - Code documentation (markdown, comments, etc.) - *Note: Documentation handling to be determined (may include downloaded content)*
- **Output**: Structured JSON data from LLM that can be used for vector generation
- **Responsibilities**:
  - Read source files from the codebase
  - Send source file content to LLM with a prompt requesting structured JSON output
  - LLM analyzes the code and returns JSON containing semantic elements (classes, functions, methods, etc.)
  - Extract and process the JSON response from LLM
  - Format the JSON data into vector-friendly text representations
  - Handle multiple programming languages
  - Track file metadata (path, modification time via OLLMfiles.File)

##### Analysis Prompt Details

The Analysis layer sends code files to the LLM with a specific prompt designed to extract structured semantic information. The prompt is stored in `resources/ocvector/ocvector-prompt.txt` and includes:

- Instructions for extracting file-level information (language, summary, imports)
- Instructions for extracting code elements (classes, functions, methods, properties, fields, etc.)
- Requirements for each element: type, name, access modifier, line numbers, signature, description
- Parameter extraction for functions/methods (with types)
- Property/field extraction for classes/structs (with types and accessors)
- Relationship tracking (inheritance, implementations, dependencies)
- JSON schema example embedded in the prompt

**Note**: The prompt includes the JSON schema as a string to ground the model's response. The actual schema enforcement is handled by Ollama's `format` parameter (see LLM API Call section below), which ensures reliable structured output even if the model doesn't perfectly follow the prompt.

**LLM API Call**:
- **Endpoint**: `/api/chat` (preferred for structured outputs) or `/api/generate`
- **Model**: Code-aware model (e.g., `codellama`, `deepseek-coder`, `qwen2.5-coder`)
- **Messages**: Single user message with the formatted analysis prompt from `resources/ocvector/ocvector-prompt.txt`
- **Format Parameter**: JSON schema object to enforce structured output. The schema is:
  - Stored in `resources/ocvector/result-schema.json` as a JSON file (~100 lines)
  - Loaded as a `Json.Object?` when needed
  - Passed to `Call.Chat` via a `format_obj` property
  - When `Call.Chat` serializes the request, if `format_obj != null`, it will serialize that `Json.Object` instead of the string `format` property
  
  The JSON schema structure includes:
  - **File-level**: `file-path`, `language`, `summary`, `imports` (array with module and line)
  - **Elements array**: Each element includes:
    - `property-type`: enum including class, function, method, property, field, struct, interface, enum, namespace, constructor, delegate, signal, constant
    - `name`, `access-modifier`, `start-line`, `end-line`, `signature`, `description` (required)
    - `parameters`: array of objects with `name` and `type` (for functions/methods)
    - `return-type`: string (for functions/methods)
    - `properties`: array of objects with `name`, `type`, `accessors` (for classes/structs)
    - `dependencies`: array of objects with `type` and `target` (relationships)
  
  The schema is designed to be comprehensive but focused (~100 lines), capturing essential information for semantic search without excessive metadata.
- **Options**: Set `temperature: 0` for more deterministic structured outputs
- **Response Format**: JSON string containing structured analysis (enforced by format schema)

**Implementation Notes**:
- The JSON schema file will be created at `resources/ocvector/result-schema.json`
- `Call.Chat` will have a new `format_obj` property of type `Json.Object?`
- When serializing the chat call, if `format_obj != null`, the serialization will output the JSON object instead of the string `format` property
- This modification will likely be done in `serialize_property` method or in the method that calls serialization (e.g., `get_request_body()`)

**Analysis Output Processing**:
1. Parse JSON response from LLM
2. Validate structure (file_path, language, elements array)
3. For each element in the JSON:
   - Extract code snippet from original file using line numbers
   - Validate element data (type, name, line numbers)
   - Create `CodeElement` structure with all fields
4. Create `CodeFile` structure containing all elements
5. Pass structured data to Vector Building layer

**Error Handling**:
- Structured outputs via `format` parameter significantly reduce JSON parsing errors
- If LLM still returns invalid JSON (rare with structured outputs), validate and retry once
- If schema validation fails, check for partial matches and extract valid elements
- If analysis fails completely, fall back to basic element extraction (function/class names only) using AST parsing
- Log analysis errors for debugging but continue indexing other files
- Set `temperature: 0` in API options for more deterministic structured outputs

#### Layer 2: Vector Building
- **Purpose**: Convert structured JSON data (from Analysis layer) into vectors and store in FAISS
- **Input**: Structured JSON data from Analysis layer (LLM output)
- **Output**: Vectors stored in FAISS index
- **Responsibilities**:
  - Generate embeddings using LLM embedding API
  - Store vectors in FAISS index
  - Maintain mapping between vectors and source files/elements
  - Handle batch processing for efficiency
  - Support incremental updates (add/update/remove vectors)

##### Vectorization Process Details

The vectorization process converts structured code analysis into searchable text documents that are sent to Ollama's vectorize API. Each code element (class, function, method, struct, interface, etc.) becomes a separate document for vectorization.

**Document Format for Vectorization**:

For each code element extracted by the Analysis layer, a searchable text document is created with the following structure:

```
{property-type}: {name}
Access: {access-modifier}
File: {file_path}
Lines: {start_line}-{end_line}
Signature: {signature}
Description: {detailed_description}
Parameters: {name: argument-type, name: argument-type, ...}
Returns: {return_type}
Properties: {name: value-type [get/set], name: value-type [get/set], ...}
Dependencies: {relationship-type}: {target}, {relationship-type}: {target}, ...
Code:
{code_snippet}
```

**File-Level Context** (included in document metadata, not in vectorized text):
- Imports: {module} (line {line}), {module} (line {line}), ...

**Specific Fields Sent to Ollama Vectorize API**:

1. **Element Type and Name** (`{property-type}: {name}`)
   - Examples: `class: DatabaseManager`, `function: parse_json`, `method: initialize_connection`, `property: user_name`, `field: connection_pool`
   - Property types include: class, function, method, property, field, struct, interface, enum, namespace, constructor, delegate, signal, constant
   - Provides semantic context about what kind of code element this is

2. **Access Modifier** (`Access: {access-modifier}`)
   - Visibility level: public, private, protected, internal, package, default
   - Helps filter searches by accessibility (e.g., "public API methods")

3. **File Location** (`File: {file_path}`)
   - Full path to the source file
   - Enables location-based filtering and result display

4. **Line Range** (`Lines: {start_line}-{end_line}`)
   - Exact line numbers where the element is defined (1-indexed)
   - Critical for precise code navigation

5. **Signature** (`Signature: {signature}`)
   - Full declaration signature of the element
   - Includes modifiers, return type, parameter types, etc.
   - Enables exact signature matching and API discovery

6. **Description** (`Description: {detailed_description}`)
   - Natural language description of the element's purpose and functionality
   - Generated by LLM analysis, includes semantic understanding of what the code does
   - This is the primary semantic content for search matching

7. **Parameters** (`Parameters: {name: argument-type}, ...`)
   - List of function/method parameters with their types
   - Format: `name: type` pairs (e.g., `email: string, timeout: int`)
   - Only included for functions, methods, constructors, delegates
   - Helps match queries about specific APIs or signatures

8. **Return Type** (`Returns: {return_type}`)
   - Return type information (or "void"/"None" for no return)
   - Only included for functions, methods, properties with getters
   - Aids in finding code that returns specific types

9. **Properties** (`Properties: {name: value-type [accessors]}, ...`)
   - Properties and fields for classes/structs
   - Format: `name: type [get/set/init]` (e.g., `user_name: string [get, set]`)
   - Only included for classes, structs, interfaces
   - Helps find classes with specific properties or fields

10. **Dependencies** (`Dependencies: {relationship-type}: {target}, ...`)
    - Relationships to other code elements with relationship types
    - Relationship types: inherits, implements, uses, calls, references, imports
    - Format: `relationship-type: target` (e.g., `inherits: BaseClass`, `calls: Database.connect`)
    - Enables relationship-based searches (e.g., "classes that implement InterfaceX")

11. **Code Snippet** (`Code:\n{code_snippet}`)
    - The actual source code for the element, but with smart truncation for nested structures
    - **For classes/structs/interfaces**: Include only the class declaration and property/field declarations (first ~30-50 lines or until first method). Do NOT include method bodies since methods are extracted as separate elements.
    - **For methods/functions/constructors**: Include the full method/function implementation (all lines from start_line to end_line).
    - **For properties/fields**: Include only the property/field declaration (typically 1-5 lines).
    - **For enums**: Include all enum values and any enum-specific methods.
    - **For namespaces**: Include only the namespace declaration and any top-level declarations (not nested class bodies).
    - **Maximum snippet size**: Limit to ~100 lines to prevent extremely large snippets that don't add semantic value.
    - Provides concrete implementation details for context
    - Helps match queries that reference specific code patterns or implementations
    - **Note**: Since nested elements (methods, properties) are extracted as separate elements, the parent class snippet should focus on structure rather than duplicating nested content.

**File-Level Context** (stored in metadata, not vectorized):
- **Imports**: List of imported modules with line numbers
  - Format: `module (line number)`
  - Helps understand file dependencies and module relationships

**Example Document for Vectorization**:

```
class: DatabaseManager
Access: public
File: /path/to/project/src/database.vala
Lines: 45-120
Signature: public class DatabaseManager : Object
Description: Manages database connections and provides methods for executing queries. Handles connection pooling, transaction management, and error recovery. Automatically retries failed connections and maintains connection health status.
Properties: connection_pool: Gee.ArrayList<Connection> [get], max_connections: int [get, set], timeout: int [get, set]
Dependencies: inherits: Object, uses: libocsqlite.Database, uses: OLLMfiles.File
Code:
public class DatabaseManager : Object {
  private Gee.ArrayList<Connection> connection_pool;
  private int max_connections = 10;
  private int timeout = 30;
  
  public int max_connections {
    get { return this.max_connections; }
    set { this.max_connections = value; }
  }
  
  // ... (methods are extracted as separate elements, not included here)
}
```

**Note**: The class snippet is truncated to show only the class structure (declaration and properties). Individual methods like `execute_query()`, `acquire_connection()`, etc. are extracted as separate elements with their own full code snippets.

**Code Snippet Extraction Strategy**:

The Vector Building layer should implement smart snippet extraction based on element type:

1. **For classes/structs/interfaces** (`property-type: "class"`, `"struct"`, `"interface"`):
   - Extract only the class declaration and property/field declarations
   - Stop at the first method definition (methods are separate elements)
   - Maximum ~50 lines to show structure without duplicating nested content
   - Example: Show `public class X { ... properties ... }` but not method bodies

2. **For methods/functions/constructors** (`property-type: "method"`, `"function"`, `"constructor"`):
   - Extract the full implementation (all lines from start_line to end_line)
   - These are typically self-contained and not nested within other elements
   - No truncation needed unless exceeding ~200 lines (very rare)

3. **For properties/fields** (`property-type: "property"`, `"field"`):
   - Extract only the property/field declaration (typically 1-10 lines)
   - Include getter/setter if present in the same declaration block
   - Example: `public string name { get; set; default = ""; }`

4. **For enums** (`property-type: "enum"`):
   - Extract all enum values and any enum-specific methods
   - Usually compact enough to include fully

5. **For namespaces** (`property-type: "namespace"`):
   - Extract only the namespace declaration and any top-level using/import statements
   - Do not include nested class/method bodies (extracted separately)

6. **General truncation rule**:
   - If any snippet exceeds ~100 lines, truncate with `// ... (truncated)` comment
   - This prevents extremely large snippets that don't add semantic value to vector search
   - The full code is always available via file path and line numbers

**Implementation Note**: The `extract_code_snippet()` method in `Analysis.vala` currently extracts full code. The Vector Building layer should apply the truncation logic when formatting documents for vectorization, or the `extract_code_snippet()` method should be enhanced to accept element type and apply appropriate truncation.

**Example for a Method**:

```
method: execute_query
Access: public
File: /path/to/project/src/database.vala
Lines: 85-105
Signature: public async string? execute_query(string sql, GLib.Cancellable? cancellable = null) throws GLib.Error
Description: Executes a SQL query asynchronously and returns the result. Handles connection acquisition, query execution, and error handling. Returns null on error.
Parameters: sql: string, cancellable: GLib.Cancellable?
Returns: string?
Dependencies: calls: Connection.acquire, calls: Connection.execute, references: GLib.Error
Code:
public async string? execute_query(string sql, GLib.Cancellable? cancellable = null) throws GLib.Error {
  var conn = yield this.acquire_connection(cancellable);
  return yield conn.execute(sql);
}
```
    private string connection_string;
    private int pool_size;
    private int timeout;
    
    public DatabaseManager(string connection_string, int pool_size = 10, int timeout = 30) {
        this.connection_string = connection_string;
        this.pool_size = pool_size;
        this.timeout = timeout;
    }
    
    public async bool initialize() throws Error {
        // Connection initialization logic
    }
}
```

**Vectorization API Call**:

Each document (as formatted above) is sent to Ollama's `/api/embeddings` endpoint (or equivalent vectorize API) with:

- **Model**: The embedding model to use (e.g., `nomic-embed-text`, `all-minilm`, or model-specific embedding endpoint)
- **Input**: The complete formatted document string
- **Response**: Vector embedding (array of floats)

**Batch Processing**:

- Multiple documents can be vectorized in a single batch request if the API supports it
- Documents are grouped by file to maintain locality
- Batch size is configurable (default: 10-20 documents per batch)

**Document Metadata Storage**:

Alongside each vector, the following metadata is stored in the database (NOT in FAISS, which only stores vectors):
- Original file path
- Element type and name
- Line range (start_line, end_line)
- Vector ID in FAISS index
- Timestamp of vectorization

**Important**: Original document text is NOT stored. Code snippets are read from the filesystem when needed for result display. This approach:
- Avoids duplication (files already exist in filesystem or are referenced in SQL database)
- Reduces storage requirements
- Ensures results always show current file content
- Enables precise result location (file + line numbers)
- Supports incremental updates (re-vectorizing only changed elements)

### Component 2: Search

The search component provides semantic search capabilities:

- **Purpose**: Perform semantic search on indexed codebase
- **Features**:
  - Use local GPU for search operations when available
  - Fallback to CPU if GPU unavailable
  - Return ranked results with similarity scores
  - Support various query types (functionality search, pattern search, etc.)
- **Responsibilities**:
  - Convert search queries to embedding vectors
  - Perform similarity search in FAISS index
  - Rank and filter results
  - Return formatted results with context

### File Tracking System

The vector indexing system uses `libocfiles` (OLLMfiles namespace) for file tracking:

- **Track Indexed Files**: Store vector metadata linked to `OLLMfiles.File` objects
- **Detect Changes**: Use file modification times (`mtime`) from `OLLMfiles.File` to detect when files need re-indexing
- **Incremental Updates**: Update vectors when code or documentation changes
- **File Management**: Use `OLLMfiles.ProjectManager` and `OLLMfiles.Folder` for project-wide file discovery and hierarchy

**Note**: `libocvector` depends on `libocfiles` which provides file management without GTK/git dependencies. The `OLLMfiles` namespace provides all necessary file tracking capabilities.

Metadata storage (integrated with `OLLMfiles.File`):
- File path and ID (via `OLLMfiles.File`)
- File modification time (`mtime`) for change detection
- Last indexed timestamp
- Vector position in FAISS index
- Indexing status (indexed, needs update, error, etc.)

### Command-Line Tools

Command-line tools will be created in the `examples/` directory for testing:

#### Indexing Example (`examples/oc-vector-index.vala`)
- **Purpose**: Test single file indexing from command line
- **Features**:
  - Index a single file for testing
  - Show indexing progress
  - Simple interface for development/testing

#### Search Tool (`oc-vector-search`)
- **Namespace**: `OLLMvector.Tools.Search`
- **Purpose**: Search indexed codebases from command line
- **Features**:
  - Execute semantic search queries
  - Display ranked results
  - Filter by file type, language, etc.
  - Export results in various formats

### OLLM Library Tool Integration

A tool class will be created for use with the `libollmchat` tool system:

- **Class**: `OLLMvector.Tool.CodebaseSearchTool` (extends `OLLMchat.Tool.Interface`)
- **Purpose**: Provide semantic codebase search as a tool for LLM agents
- **Integration**: 
  - Implements `OLLMchat.Tool.Interface`
  - Provides `execute()` method for tool calling
  - Returns search results in structured format
  - Supports permission system integration

## Migration Plan: VectorSearch ‚Üí libocvector

### Phase 1: Create libocvector Structure
1. Create `libocvector/` directory
2. Set up `meson.build` for the library
3. Create namespace structure (`OLLMvector.Indexing`, `OLLMvector.Search`, `OLLMvector.Tools.Search`, `OLLMvector.Tool`)

### Phase 2: Migrate FAISS Components
1. **Migrate FAISS Integration**:
   - Move `VectorSearch/Index.vala` ‚Üí `libocvector/Index.vala`
   - Keep namespace as `Faiss` (or appropriate FAISS namespace)
   - Keep FAISS functionality intact

2. **Migrate Database**:
   - Move `VectorSearch/Database.vala` ‚Üí `libocvector/Database.vala`
   - Update namespace to `OLLMvector`
   - Integrate with `OLLMfiles.File` for metadata tracking

### Phase 3: Refactor Analysis Layer
1. **Create Analysis Component**:
   - Extract analysis logic from `VectorSearch/CodeImport.vala`
   - Create `libocvector/Indexing/Analysis.vala`
   - Implement LLM-based analysis: send source files to LLM, receive JSON output
   - Process JSON response to extract semantic elements
   - Integrate with `OLLMfiles` for file tracking
   - *Note: Documentation handling (markdown, downloaded content) to be determined*

2. **Create Vector Builder**:
   - Extract vector generation from `VectorSearch/Database.vala`
   - Create `libocvector/Indexing/VectorBuilder.vala`
   - Separate embedding generation from storage
   - Add batch processing support

3. **Create Indexer**:
   - Refactor `VectorSearch/CodeIndexer.vala` ‚Üí `libocvector/Indexing/Indexer.vala`
   - Combine Analysis and VectorBuilder
   - Add integration with `OLLMfiles` for file tracking
   - Implement incremental update logic

### Phase 4: Refactor Search Layer
1. **Create Searcher**:
   - Refactor `VectorSearch/CodeSearch.vala` ‚Üí `libocvector/Search/Searcher.vala`
   - Add GPU support detection and usage
   - Enhance result formatting

2. **Create Query Processor**:
   - Extract query processing logic
   - Create `libocvector/Search/QueryProcessor.vala`
   - Add query type detection and routing

### Phase 5: File Tracking Integration
1. **Integrate with libocfiles**:
   - Add `libocfiles` dependency to `libocvector/meson.build`
   - Use `OLLMfiles.File`, `OLLMfiles.Folder`, and `OLLMfiles.ProjectManager` for file tracking
   - Add vector indexing metadata fields (or create extension/wrapper if needed)
   - Store vector position and indexing status in database (link to file IDs)
   - Use `OLLMfiles.File.mtime` for change detection

### Phase 6: Create Command-Line Tools
1. **Create Indexing Example**:
   - Create `examples/oc-vector-index.vala`
   - Simple command-line tool for testing single file indexing
   - Focus on development/testing use cases

2. **Create Search Tool**:
   - Create `libocvector/Tools/SearchTool.vala`
   - Implement command-line interface
   - Add to `examples/` directory as `oc-vector-search.vala`
   - Create `oc-vector-search` executable

### Phase 7: Create OLLM Tool Integration
1. **Create CodebaseSearchTool**:
   - Create `libocvector/Tool/CodebaseSearchTool.vala`
   - Extend `OLLMchat.Tool.Interface`
   - Implement tool interface methods
   - Add to `libollmchat` tool registry

### Phase 8: Update Dependencies and Build
1. Update `meson.build`:
   - Add `libocvector` subdirectory
   - Add dependencies (libocsqlite, libollmchat, libocfiles, FAISS)
   - Note: `libocfiles` is used as a dependency for file tracking
   - Create library, VAPI, and GIR files

2. Update library dependencies:
   - Add `libocvector` to libraries that need it
   - Update VAPI dependencies (include ocfiles VAPI)

### Phase 9: Testing and Cleanup
1. Test indexing with various codebases
2. Test search functionality
3. Test command-line tools
4. Test OLLM tool integration
5. Remove or deprecate `VectorSearch/` directory
6. Update documentation

## Existing Infrastructure

The project already has a `VectorSearch/` directory with:
- **FAISS Integration** (`Index.vala`, `Database.vala`) - Vector search using FAISS
- **Code Analysis** (`CodeImport.vala`, `CodeIndexer.vala`) - Code file analysis
- **Code Search** (`CodeSearch.vala`) - Search functionality
- **Code Elements** (`CodeElement.vala`, `CodeFile.vala`) - Code structure representation

This code will be migrated and refactored into the new `libocvector` structure.

## Dependencies

- **FAISS library** (already integrated via `vapi/fiass.vapi`)
- **libocsqlite** - For metadata storage
- **libollmchat** - For LLM client access and tool integration
- **libocfiles** - For file tracking and project management (provides `OLLMfiles` namespace)
- **libocagent** - For agent integration (if needed)

**Note**: `libocvector` depends on `libocfiles` for file tracking. The `libocfiles` library provides file management without GTK/git dependencies, using the `OLLMfiles` namespace.

## Files to Create

### Library Files
- `libocvector/meson.build`
- `libocvector/Index.vala` (FAISS namespace)
- `libocvector/Database.vala`
- `libocvector/Indexing/Analysis.vala`
- `libocvector/Indexing/VectorBuilder.vala`
- `libocvector/Indexing/Indexer.vala`
- `libocvector/Search/Searcher.vala`
- `libocvector/Search/QueryProcessor.vala`
- `libocvector/Tool/CodebaseSearchTool.vala`
- `libocvector/Tools/SearchTool.vala`

**Note**: File tracking is provided by `libocfiles` dependency (OLLMfiles namespace), so no Files/ directory is needed in `libocvector`.

### Example/Test Tools
- `examples/oc-vector-index.vala` (simple single-file indexing for testing)
- `examples/oc-vector-search.vala` (uses `libocvector/Tools/SearchTool.vala`)

## Features

- Semantic code search using FAISS vectors
- Support for both code and documentation indexing
- GPU-accelerated search (with CPU fallback)
- Incremental indexing with change detection
- File tracking via `libocfiles` dependency (OLLMfiles namespace)
- Command-line tools for testing and manual operations
- OLLM library tool integration for LLM agents
- Permission system integration

## Testing

- Test indexing with various codebases and languages
- Test search functionality with different query types
- Test file change detection and re-indexing
- Test command-line tools
- Test OLLM tool integration
- Test GPU vs CPU search performance
- Test incremental updates
- Add to meson.build
