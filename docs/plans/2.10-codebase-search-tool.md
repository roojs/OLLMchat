# 2.10. Codebase Search Tool

## Overview

Implementation of a semantic codebase search tool using vector embeddings and FAISS. The code will be migrated from the existing `VectorSearch/` directory into a new `libocvector` library with two main components: **Indexing** and **Search**. The library uses `libocfiles` (OLLMfiles namespace) for file tracking and project management, providing file management without GTK/git dependencies.

**Architecture Reference:** See `docs/plans/2.10-vector-storage-architecture.md` for detailed information about:
- What's stored in FAISS vs SQL database
- Minimum schema requirements (6 fields)
- Why certain fields are/aren't stored
- Data flow and query patterns

## Status

ðŸš§ **IN PROGRESS** - Foundation, FAISS migration, Tree layer (Phase 3a), and Analysis layer (Phase 3) completed. Vector Building refactoring and Search layer pending.

## Todo List

### Phase 1: Foundation & Structure
- [x] Create `libocvector/` directory structure
- [x] Set up `libocvector/meson.build` for the library
- [x] Create namespace structure (`OLLMvector.Indexing`, `OLLMvector.Search`, `OLLMvector.Tools.Search`, `OLLMvector.Tool`) - *Partially done: OLLMvector namespace exists, subdirectories not yet created*
- [x] Add `libocfiles` dependency to `libocvector/meson.build` - *Uses OLLMfiles namespace for file tracking*

### Phase 2: FAISS Migration
- [x] Migrate `VectorSearch/Index.vala` â†’ `libocvector/Index.vala` (FAISS namespace)
- [x] Migrate `VectorSearch/Database.vala` â†’ `libocvector/Database.vala`
- [x] Update Database namespace to `OLLMvector`
- [x] Create FAISS C++ wrapper (`faiss_c_wrapper.cpp`) - *Additional work not in original plan*
- [ ] Integrate Database with `OLLMfiles.File` for metadata tracking - *TODOs in code indicate this is pending*

### Phase 3a: Tree Layer Implementation
- [x] Create `libocvector/Indexing/Tree.vala`
- [x] Implement tree-sitter parser integration using `TreeSitter` namespace from `vapi/tree-sitter.vapi`
- [x] Implement language detection and tree-sitter language selection based on file language
- [x] Implement AST traversal to extract code elements (classes, functions, methods, etc.)
- [x] Create `VectorMetadata` objects from tree-sitter nodes with line numbers
- [x] Extract code documentation blocks using tree-sitter API (doc comments, JSDoc, etc.) related to each element
- [x] Add `codedoc_start` and `codedoc_end` properties to `VectorMetadata` class (line numbers only, not stored in DB, used for analysis)
- [x] Tree class: Constructor takes `OLLMfiles.File` as argument, stores as property
- [x] Tree class: Add `elements` property (Gee.ArrayList<VectorMetadata>) to store VectorMetadata array
- [x] Tree class: Add `lines` property (string[]) containing file content split into lines
- [x] Tree class: Add `lines_to_string(int start_line, int end_line)` method using Vala string range syntax `lines[start:end]`
- [x] **Additional**: Added `signature` property to `VectorMetadata` for method/function signatures
- [x] **Additional**: Added `namespace` property to `VectorMetadata` to track namespace context
- [x] **Additional**: Added `parent_class` property to `VectorMetadata` to track parent class/struct/interface for methods, properties, fields
- [x] **Additional**: Implemented enum value relationship tracking (enum values prefixed with parent enum name, e.g., `FormatType.NONE`)
- [x] **Additional**: Implemented signature extraction with whitespace cleaning for multi-line signatures
- [x] **Additional**: Implemented property accessor extraction (get/set/default) in signatures
- [x] **Additional**: Added debug output for dropped elements to help diagnose extraction issues

### Phase 3: Analysis Layer Implementation
- [x] Create `libocvector/Indexing/Analysis.vala`
- [x] Refactor Analysis constructor to receive `Tree` object as argument (via `analyze_tree()` method)
- [x] Analysis iterates over `Tree.elements` and updates VectorMetadata descriptions
- [x] Load prompt templates from resources (use `---` separator between system and user prompts)
- [x] Implement simple LLM call that sends code + documentation for summarization
- [x] Return one-line text descriptions (not structured JSON)
- [x] Store descriptions in `VectorMetadata` objects as property (not stored in DB, used by VectorBuilder)
- [x] Integrate with `OLLMfiles` for file tracking (via `Tree.file` property)
- [x] Add error handling and fallback strategies

### Phase 4: Vector Building Implementation
**Note:** This phase works on **one file at a time** (processes `Tree` object from Analysis layer). Phase 5 (Indexer Orchestration) will handle multiple files and project-wide indexing.

**Reference:** See `docs/plans/2.10-vector-storage-architecture.md` for detailed schema and architecture decisions.

- [x] Create `libocvector/Indexing/VectorBuilder.vala`
  - âœ… Done: Takes `VectorMetadata[]` from Analysis layer (with descriptions populated)
  - âœ… Done: Refactor: Updated to receive `Tree` object as argument
  - âœ… Done: Refactor: Uses `Tree.elements` for VectorMetadata array
  - âœ… Done: Refactor: Uses `Tree.lines_to_string()` method for code snippet extraction
  - âœ… Done: Formats each element into document for vectorization
  - âœ… Done: Generates embeddings and stores in FAISS
  - âœ… Done: Stores metadata in SQL database
- [x] Implement document formatting for vectorization
  - âœ… Done: Format: type, name, file, lines, description, parameters, return type, dependencies, code snippet
  - âœ… Done: Follows plan lines 239-323 for detailed format specification
  - âœ… Done: Applies smart code snippet truncation based on element type (classes vs methods)
- [x] Implement Ollama embeddings API integration (`/api/embeddings`)
  - âœ… Done: `Database.vala` uses `ollama.embed()` method
  - âœ… Done: `libollmchat.Client.embed()` and `embed_array()` available
- [x] Implement batch processing for vector generation
  - âœ… Done: `VectorBuilder.vala` uses `embed_array()` for true batch processing (15 documents per batch)
  - âœ… Done: Processes embeddings in batches of 10-20 documents
- [x] Implement FAISS vector storage
  - âœ… Done: `libocvector/Index.vala` implements FAISS with `add_vectors()`
  - âœ… Done: `Database.vala` uses `index.add_vectors(vector_batch)`
- [x] Implement metadata storage in SQL database
  - âœ… Done: Schema: `vector_id`, `file_id`, `start_line`, `end_line`, `element_type`, `element_name`
  - âœ… Done: Follows `docs/plans/2.10-vector-storage-architecture.md` minimal schema (6 fields)
  - âœ… Done: Integrated with `libocsqlite` for SQL storage
  - âœ… Done: Stores metadata when vectors are added (link vector_id to file_id + line range)
  - âœ… Done: `VectorMetadata` class created following FileBase pattern with `initDB`, `saveToDB`, `lookup` methods
  - âš ï¸ Lookup for search results (vector_id â†’ file path + code snippet) - pending in Search layer

**Additional Improvements:**
- âœ… Tree layer extracts all structure: Tree layer uses tree-sitter to extract element type, name, signature, namespace, parent class, line numbers, documentation ranges - no LLM needed for structure extraction
- âœ… Code snippet optimization: Using `string[]` arrays and Vala array slicing (`array[start:end]`) throughout
- âœ… Coding standards: Applied throughout (removed single-use variables, proper string concatenation, line breaking)
- âœ… Database properties: Refactored `dimension` and `vector_count` to read-only properties
- [x] **NEW**: Tree layer will use tree-sitter to create `VectorMetadata` objects directly (replacing CodeFile/CodeElement flow)
- [x] **NEW**: `VectorMetadata` will have `codedoc_start` and `codedoc_end` properties (line numbers only, not stored in DB) for documentation blocks
- [x] **NEW**: `VectorMetadata` has `signature`, `namespace`, and `parent_class` properties (not stored in DB, used for analysis and code block generation)

### Phase 5: Indexer Orchestration
- [x] Add `last_scan` field to `filebase` table
  - Add `last_scan INT64 NOT NULL DEFAULT 0` to filebase table schema
  - Add `last_scan` property to `FileBase` class
  - Implement database migration for existing databases (ALTER TABLE)
  - For files: `last_scan` = timestamp when scan completed (after successful vectorization)
  - For folders: `last_scan` = timestamp when scan started (to prevent re-recursion during same scan)
- [x] Create `libocvector/Indexing/Indexer.vala`
- [x] Integrate Tree, Analysis, and VectorBuilder components
  - Create Tree(file), call Tree.parse()
  - Pass Tree to Analysis, which updates Tree.elements
  - Pass Tree to VectorBuilder, which uses Tree.elements and Tree.lines_to_string()
- [x] Implement incremental update logic
  - Check `file.last_scan` vs `file.mtime_on_disk()` for files
  - Skip files where `last_scan >= mtime_on_disk()` (not modified since last scan)
  - Note: Cannot do mtime check on folders (folders don't have reliable mtime)
  - For folders: check `folder.last_scan` to avoid re-recursion during same scan session
  - Update `file.last_scan` after successful indexing (time of completion)
  - Update `folder.last_scan` at start of folder scan (time of start, before processing children)
- [x] Implement folder-based indexing
  - Starting point: folder in database (must exist in database, query by path)
  - Option to recurse into subfolders (controlled by `--recurse` flag)
  - Use `OLLMfiles.Folder` and `OLLMfiles.ProjectManager` for traversal
  - Only process files that exist in database (don't scan filesystem directly)
  - Process files in folder: iterate through `folder.children.items` and filter for `File` objects
  - For recursion: recursively process subfolders, checking `folder.last_scan` to avoid duplicates
- [x] Update `oc-vector-index` example tool
  - Use `~/.local/share/ollmchat/files.sqlite` as database path (existing ollmchat database)
  - Accept either file path or folder path as argument
  - If file: process single file (existing behavior)
  - If folder: process all files in folder, with optional recursion
  - Add `--recurse` / `-r` flag for recursive indexing (only applies when folder is specified)
  - Store vector database at `~/.local/share/ollmchat/codedb.faiss.vectors`
  - Load folder from database as starting point (must exist in database)
  - Output vectorized summaries: show descriptions for each element being vectorized
  - Add line break after each file's vectorization completes (for readability)

### Phase 6: Search Layer Implementation
- [ ] Create `libocvector/Search/Searcher.vala`
- [ ] Migrate and refactor `VectorSearch/CodeSearch.vala`
- [ ] Implement query vectorization (convert queries to embeddings)
- [ ] Implement FAISS similarity search
- [ ] Add GPU support detection and usage
- [ ] Implement CPU fallback
- [ ] Create `libocvector/Search/QueryProcessor.vala`
- [ ] Implement query type detection and routing
- [ ] Implement result ranking and formatting

### Phase 7: File Tracking Integration
- [x] Add `libocfiles` dependency to `libocvector/meson.build` - *Uses OLLMfiles namespace*
- [ ] Integrate with `OLLMfiles.File` and `OLLMfiles.Folder` for file tracking
- [ ] Add vector indexing metadata fields to `OLLMfiles.File` (or create extension/wrapper if needed)
- [ ] Implement metadata storage in database (link vector IDs to file IDs)
- [ ] Store vector position, indexing status, and timestamps per file
- [ ] Implement change detection using `OLLMfiles.File.mtime`
- [ ] Use `OLLMfiles.ProjectManager` for project-wide file discovery

### Phase 8: Command-Line Tools
- [x] Create `examples/oc-vector-index.vala` (single file indexing tool)
- [ ] Create `libocvector/Tools/SearchTool.vala`
- [ ] Create `examples/oc-vector-search.vala` (search tool executable)
- [x] Implement command-line argument parsing - *Basic version implemented in oc-vector-index*
- [ ] Add progress display for indexing
- [ ] Add result formatting for search output

### Phase 9: OLLM Tool Integration
- [ ] Create `libocvector/Tool/CodebaseSearchTool.vala`
- [ ] Extend `OLLMchat.Tool.Interface`
- [ ] Implement `execute()` method for tool calling
- [ ] Implement structured result format for LLM agents
- [ ] Add to `libollmchat` tool registry
- [ ] Integrate with permission system

### Phase 10: Build System & Dependencies
- [x] Update root `meson.build` to include `libocvector` subdirectory
- [x] Add dependencies to `libocvector/meson.build` (libocsqlite, libollmchat, libocfiles, FAISS)
- [x] Note: `libocfiles` is used as a dependency (no need to copy FileBase structure)
- [x] Generate VAPI files for `libocvector` - *Generated via meson.build*
- [ ] Generate GIR files for `libocvector` - *Commented out in meson.build, pending implementation*
- [x] Update library dependencies in consuming projects - *examples/meson.build updated*
- [x] Update VAPI dependencies

### Phase 11: Testing
- [ ] Test indexing with various codebases (Vala, Python, JavaScript, etc.)
- [ ] Test search functionality with different query types
- [ ] Test file change detection and re-indexing
- [ ] Test command-line tools (`oc-vector-index`, `oc-vector-search`)
- [ ] Test OLLM tool integration
- [ ] Test GPU vs CPU search performance
- [ ] Test incremental updates
- [ ] Test structured outputs reliability
- [ ] Test batch processing for vectorization
- [ ] Test error handling and fallbacks

### Phase 12: Cleanup & Documentation
- [ ] Remove or deprecate `VectorSearch/` directory
- [ ] Update project documentation
- [ ] Add code comments and documentation
- [ ] Create usage examples
- [ ] Document API for library consumers

## Architecture

### Library Structure: `libocvector`

The vector search functionality will be organized as a new library `libocvector` with the following structure:

```
libocvector/
â”œâ”€â”€ meson.build
â”œâ”€â”€ Files/                      # FileBase structure (copied from liboccoder, no dependency)
â”‚   â”œâ”€â”€ FileBase.vala          # Base class for File and Folder
â”‚   â”œâ”€â”€ File.vala              # File class
â”‚   â””â”€â”€ Folder.vala            # Folder class
â”œâ”€â”€ Indexing/
â”‚   â”œâ”€â”€ Tree.vala               # Tree-sitter AST parsing and VectorMetadata creation
â”‚   â”œâ”€â”€ Analysis.vala           # LLM-based code summarization
â”‚   â”œâ”€â”€ VectorBuilder.vala      # Vector generation and FAISS storage
â”‚   â””â”€â”€ Indexer.vala            # Main indexing orchestrator
â”œâ”€â”€ Search/
â”‚   â”œâ”€â”€ Searcher.vala           # Search functionality with GPU support
â”‚   â””â”€â”€ QueryProcessor.vala     # Query processing and result formatting
â””â”€â”€ Tool/
    â””â”€â”€ CodebaseSearchTool.vala  # OLLM tool integration
```

**Note**: The `Files/` directory contains a copy of the FileBase structure from `liboccoder`. This avoids dependency issues while maintaining the same file/folder tracking capabilities. The code is based on `liboccoder.Files` but exists independently in `libocvector.Files` namespace.

### Component 1: Indexing

The indexing component consists of three layers:

#### Layer 1: Tree (Tree-sitter AST Parsing)
- **Purpose**: Parse source code files using tree-sitter to extract code elements and create `VectorMetadata` objects
- **Input**: 
  - Code files (via `OLLMfiles.File`)
- **Output**: Array of `VectorMetadata` objects with code element information and documentation
- **Responsibilities**:
  - Use tree-sitter parser to parse source code files
  - Traverse AST to identify code elements (classes, functions, methods, properties, etc.)
  - Extract line numbers (start_line, end_line) for each element
  - Extract code documentation blocks (doc comments, JSDoc, etc.) associated with each element
  - Create `VectorMetadata` objects for each code element
  - Extract code snippets from file using line numbers
  - Pass array of `VectorMetadata` objects to Analysis layer

**Tree Layer Implementation Details**:

The Tree layer uses the `TreeSitter` namespace from `vapi/tree-sitter.vapi` to parse source code files. Core implementation includes:

**Core Code Structure**:

```vala
namespace OLLMvector.Indexing {
    public class Tree : Object {
        // Properties
        public OLLMfiles.File file { get; private set; }
        public Gee.ArrayList<VectorMetadata> elements { get; private set; }
        public string[] lines { get; private set; }
        
        private TreeSitter.Parser parser;
        private TreeSitter.Language? language;
        
        // Constructor: takes File as argument
        public Tree(OLLMfiles.File file) throws GLib.Error;
        
        // Main entry point: parse file and populate elements array
        public async void parse() throws GLib.Error;
        
        // Extract string from lines array using Vala string range syntax
        public string lines_to_string(int start_line, int end_line);
        
        // Language detection and tree-sitter language selection
        private TreeSitter.Language? get_language_for_file();
        
        // Parse source code using tree-sitter
        private TreeSitter.Tree? parse_code(string code, TreeSitter.Language lang);
        
        // Traverse AST and extract code elements
        private void traverse_ast(TreeSitter.Node node);
        
        // Extract code element information from AST node
        private VectorMetadata? extract_element_metadata(TreeSitter.Node node);
        
        // Extract documentation block line numbers using tree-sitter API
        private void extract_documentation_lines(TreeSitter.Node node, out int? codedoc_start, out int? codedoc_end);
        
        // Determine element type from tree-sitter node type
        private string get_element_type(TreeSitter.Node node, TreeSitter.Language lang);
        
        // Get element name from AST node
        private string? get_element_name(TreeSitter.Node node);
    }
}
```

**Key Methods**:

1. **Constructor `Tree(OLLMfiles.File file)`**:
   - Stores `file` as property
   - Initializes `elements` as empty ArrayList
   - Reads file content and splits into `lines` array

2. **`parse()`**: Main entry point that:
   - Detects file language
   - Loads appropriate tree-sitter language parser
   - Parses file content
   - Traverses AST to extract elements
   - Populates `elements` array with `VectorMetadata` objects

3. **`lines_to_string(int start_line, int end_line)`**: Extracts string from lines array:
   - Uses Vala string range syntax: `lines[start_line:end_line]`
   - Joins array slice with newlines
   - Returns code snippet or documentation text
   - Used by Analysis and VectorBuilder layers

4. **`traverse_ast()`**: Recursively traverses tree-sitter AST:
   - Identifies code element nodes (class, function, method, etc.)
   - Extracts line numbers from node positions
   - Calls `extract_element_metadata()` for each element
   - Adds `VectorMetadata` objects to `elements` array

5. **`extract_element_metadata()`**: Creates `VectorMetadata` object:
   - Extracts element type, name, line numbers
   - Extracts documentation block line numbers using tree-sitter API (if available)
   - Sets `file_id` from `this.file.id`
   - Sets `codedoc_start` and `codedoc_end` properties (line numbers only, not stored in DB)
   - Returns `VectorMetadata` object to be added to `elements` array

6. **`extract_documentation_lines()`**: Finds documentation comment line numbers using tree-sitter:
   - Uses tree-sitter API to locate doc comment nodes before element
   - Returns start and end line numbers for documentation block
   - Used to populate `codedoc_start` and `codedoc_end` properties in `VectorMetadata`

**VectorMetadata Extensions**:

The `VectorMetadata` class is extended with:
- `codedoc_start` property (int, not stored in DB): Starting line number of documentation block
- `codedoc_end` property (int, not stored in DB): Ending line number of documentation block
  - Both populated by Tree layer using tree-sitter API to locate doc comment nodes
  - Used by Analysis layer to extract documentation text for LLM context
- `signature` property (string, not stored in DB): Full element signature (e.g., "public async void parse() throws GLib.Error")
  - Populated by Tree layer from tree-sitter AST
  - Used by VectorBuilder layer in vectorization documents
- `namespace` property (string, not stored in DB): Namespace containing the element (e.g., "OLLMvector.Indexing")
  - Populated by Tree layer during AST traversal
  - Used by VectorBuilder layer in vectorization documents
- `parent_class` property (string, not stored in DB): Parent class/struct/interface for methods, properties, fields
  - Populated by Tree layer during AST traversal
  - Used by VectorBuilder layer in vectorization documents
- `description` property (string, not stored in DB): Contains LLM-generated one-line text description
  - Populated by Analysis layer (one-line text, only for complex elements)
  - Empty string for simple elements that skip LLM analysis
  - Used by VectorBuilder layer to create vectorization documents

**Language Support**:

Tree layer will support multiple languages via tree-sitter:
- Vala (if tree-sitter grammar available)
- Python, JavaScript, Java, C++, Rust, etc.
- Language detection based on `OLLMfiles.File.language` property
- Fallback to generic parsing if language-specific parser unavailable

#### Layer 2: Analysis
- **Purpose**: Generate one-line text descriptions for code elements using LLM (structure is already extracted by Tree layer)
- **Input**: 
  - `Tree` object from Tree layer (contains `elements` array with VectorMetadata objects that already have structure: type, name, signature, namespace, parent_class, etc.)
- **Output**: `Tree` object with `elements` array updated (each `VectorMetadata.description` populated)
- **Responsibilities**:
  - Receive `Tree` object from Tree layer (structure already extracted by tree-sitter)
  - Iterate over `Tree.elements` array
  - For each `VectorMetadata` object:
    - Skip LLM for simple elements (enum types without docs, simple properties, enum values, fields without docs)
    - For complex elements: Extract code snippet using `Tree.lines_to_string(start_line, end_line)`
    - Extract documentation using `Tree.lines_to_string(codedoc_start, codedoc_end)` (if available)
    - Send code snippet + documentation to LLM
  - LLM generates one-line text description of what the code does
  - Store description in `VectorMetadata.description` property (not stored in DB)
  - Handle batch processing for efficiency
  - Track file metadata via `Tree.file`

##### Analysis Implementation Details

The Analysis layer receives `VectorMetadata[]` from the Tree layer (with all structure already extracted by tree-sitter) and generates simple text descriptions using LLM. The Tree layer provides all structural information (element type, name, signature, namespace, parent class, line numbers, documentation ranges), so the LLM only needs to generate a one-line description.

**LLM API Call**:
- **Endpoint**: `/api/chat`
- **Model**: Code-aware model (e.g., `codellama`, `deepseek-coder`, `qwen2.5-coder`)
- **Messages**: 
  - Load prompt template from resources (e.g., `resources/ocvector/analysis-prompt.txt`)
  - Template uses `---` separator: content before `---` is system message, content after is user message template
  - System message: Instructions for generating one-line code summaries
  - User message: Code snippet + documentation (extracted using `codedoc_start`/`codedoc_end` line numbers) wrapped in `<code>` tags
- **Options**: Set `temperature: 0` for more deterministic outputs
- **Response Format**: One-line text description (not JSON)

**Analysis Process**:
1. Receive `Tree` object from Tree layer
2. Load prompt template from resources (split on `---` for system/user messages)
3. Iterate over `Tree.elements` array:
   - For each `VectorMetadata` object:
     - Extract code snippet using `Tree.lines_to_string(start_line, end_line)`
     - Extract documentation text using `Tree.lines_to_string(codedoc_start, codedoc_end)` (if available)
     - Send to LLM with prompt template (code + documentation)
     - Store LLM response as one-line description in `VectorMetadata.description` property (not stored in DB)
4. Return updated `Tree` object with `elements` array populated with descriptions

**Error Handling**:
- If LLM call fails, set description to empty string and continue
- Log analysis errors for debugging but continue processing other elements
- Batch processing: Process multiple elements in parallel for efficiency

#### Layer 3: Vector Building
- **Purpose**: Convert `VectorMetadata` objects (from Analysis layer) into vectors and store in FAISS
- **Input**: `Tree` object from Analysis layer (with `elements` array containing VectorMetadata with descriptions populated)
- **Output**: Vectors stored in FAISS index
- **Responsibilities**:
  - Receive `Tree` object from Analysis layer
  - Iterate over `Tree.elements` array
  - For each `VectorMetadata`, extract code snippets using `Tree.lines_to_string(start_line, end_line)`
  - Format documents for vectorization (using descriptions from VectorMetadata)
  - Generate embeddings using LLM embedding API
  - Store vectors in FAISS index
  - Maintain mapping between vectors and source files/elements
  - Handle batch processing for efficiency
  - Support incremental updates (add/update/remove vectors)

##### Vectorization Process Details

The vectorization process converts code elements (with structure from Tree layer and descriptions from Analysis layer) into searchable text documents that are sent to Ollama's vectorize API. Each code element (class, function, method, struct, interface, etc.) becomes a separate document for vectorization.

**Document Format for Vectorization**:

For each code element (structure extracted by Tree layer, description from Analysis layer), a searchable text document is created with the following structure:

```
{property-type}: {name}
Access: {access-modifier}
File: {file_path}
Lines: {start_line}-{end_line}
Signature: {signature}
Description: {detailed_description}
Parameters: {name: argument-type, name: argument-type, ...}
Returns: {return_type}
Properties: {name: value-type [get/set], name: value-type [get/set], ...}
Dependencies: {relationship-type}: {target}, {relationship-type}: {target}, ...
Code:
{code_snippet}
```

**File-Level Context** (included in document metadata, not in vectorized text):
- Imports: {module} (line {line}), {module} (line {line}), ...

**Specific Fields Sent to Ollama Vectorize API**:

1. **Element Type and Name** (`{property-type}: {name}`)
   - Examples: `class: DatabaseManager`, `function: parse_json`, `method: initialize_connection`, `property: user_name`, `field: connection_pool`
   - Property types include: class, function, method, property, field, struct, interface, enum, namespace, constructor, delegate, signal, constant
   - Provides semantic context about what kind of code element this is

2. **Access Modifier** (`Access: {access-modifier}`)
   - Visibility level: public, private, protected, internal, package, default
   - Helps filter searches by accessibility (e.g., "public API methods")

3. **File Location** (`File: {file_path}`)
   - Full path to the source file
   - Enables location-based filtering and result display

4. **Line Range** (`Lines: {start_line}-{end_line}`)
   - Exact line numbers where the element is defined (1-indexed)
   - Critical for precise code navigation

5. **Signature** (`Signature: {signature}`)
   - Full declaration signature of the element
   - Includes modifiers, return type, parameter types, etc.
   - Enables exact signature matching and API discovery

6. **Description** (`Description: {detailed_description}`)
   - Natural language description of the element's purpose and functionality
   - Generated by LLM analysis, includes semantic understanding of what the code does
   - This is the primary semantic content for search matching

7. **Parameters** (`Parameters: {name: argument-type}, ...`)
   - List of function/method parameters with their types
   - Format: `name: type` pairs (e.g., `email: string, timeout: int`)
   - Only included for functions, methods, constructors, delegates
   - Helps match queries about specific APIs or signatures

8. **Return Type** (`Returns: {return_type}`)
   - Return type information (or "void"/"None" for no return)
   - Only included for functions, methods, properties with getters
   - Aids in finding code that returns specific types

9. **Properties** (`Properties: {name: value-type [accessors]}, ...`)
   - Properties and fields for classes/structs
   - Format: `name: type [get/set/init]` (e.g., `user_name: string [get, set]`)
   - Only included for classes, structs, interfaces
   - Helps find classes with specific properties or fields

10. **Dependencies** (`Dependencies: {relationship-type}: {target}, ...`)
    - Relationships to other code elements with relationship types
    - Relationship types: inherits, implements, uses, calls, references, imports
    - Format: `relationship-type: target` (e.g., `inherits: BaseClass`, `calls: Database.connect`)
    - Enables relationship-based searches (e.g., "classes that implement InterfaceX")

11. **Code Snippet** (`Code:\n{code_snippet}`)
    - The actual source code for the element, but with smart truncation for nested structures
    - **For classes/structs/interfaces**: Include only the class declaration and property/field declarations (first ~30-50 lines or until first method). Do NOT include method bodies since methods are extracted as separate elements.
    - **For methods/functions/constructors**: Include the full method/function implementation (all lines from start_line to end_line).
    - **For properties/fields**: Include only the property/field declaration (typically 1-5 lines).
    - **For enums**: Include all enum values and any enum-specific methods.
    - **For namespaces**: Include only the namespace declaration and any top-level declarations (not nested class bodies).
    - **Maximum snippet size**: Limit to ~100 lines to prevent extremely large snippets that don't add semantic value.
    - Provides concrete implementation details for context
    - Helps match queries that reference specific code patterns or implementations
    - **Note**: Since nested elements (methods, properties) are extracted as separate elements, the parent class snippet should focus on structure rather than duplicating nested content.

**File-Level Context** (stored in metadata, not vectorized):
- **Imports**: List of imported modules with line numbers
  - Format: `module (line number)`
  - Helps understand file dependencies and module relationships

**Example Document for Vectorization**:

```
class: DatabaseManager
Access: public
File: /path/to/project/src/database.vala
Lines: 45-120
Signature: public class DatabaseManager : Object
Description: Manages database connections and provides methods for executing queries. Handles connection pooling, transaction management, and error recovery. Automatically retries failed connections and maintains connection health status.
Properties: connection_pool: Gee.ArrayList<Connection> [get], max_connections: int [get, set], timeout: int [get, set]
Dependencies: inherits: Object, uses: libocsqlite.Database, uses: OLLMfiles.File
Code:
public class DatabaseManager : Object {
  private Gee.ArrayList<Connection> connection_pool;
  private int max_connections = 10;
  private int timeout = 30;
  
  public int max_connections {
    get { return this.max_connections; }
    set { this.max_connections = value; }
  }
  
  // ... (methods are extracted as separate elements, not included here)
}
```

**Note**: The class snippet is truncated to show only the class structure (declaration and properties). Individual methods like `execute_query()`, `acquire_connection()`, etc. are extracted as separate elements with their own full code snippets.

**Code Snippet Extraction Strategy**:

The Vector Building layer should implement smart snippet extraction based on element type:

1. **For classes/structs/interfaces** (`property-type: "class"`, `"struct"`, `"interface"`):
   - Extract only the class declaration and property/field declarations
   - Stop at the first method definition (methods are separate elements)
   - Maximum ~50 lines to show structure without duplicating nested content
   - Example: Show `public class X { ... properties ... }` but not method bodies

2. **For methods/functions/constructors** (`property-type: "method"`, `"function"`, `"constructor"`):
   - Extract the full implementation (all lines from start_line to end_line)
   - These are typically self-contained and not nested within other elements
   - No truncation needed unless exceeding ~200 lines (very rare)

3. **For properties/fields** (`property-type: "property"`, `"field"`):
   - Extract only the property/field declaration (typically 1-10 lines)
   - Include getter/setter if present in the same declaration block
   - Example: `public string name { get; set; default = ""; }`

4. **For enums** (`property-type: "enum"`):
   - Extract all enum values and any enum-specific methods
   - Usually compact enough to include fully

5. **For namespaces** (`property-type: "namespace"`):
   - Extract only the namespace declaration and any top-level using/import statements
   - Do not include nested class/method bodies (extracted separately)

6. **General truncation rule**:
   - If any snippet exceeds ~100 lines, truncate with `// ... (truncated)` comment
   - This prevents extremely large snippets that don't add semantic value to vector search
   - The full code is always available via file path and line numbers

**Implementation Note**: The Vector Building layer uses `Tree.lines_to_string(start_line, end_line)` to extract code snippets. Truncation logic should be applied when formatting documents for vectorization based on element type (classes vs methods, etc.).

**Example for a Method**:

```
method: execute_query
Access: public
File: /path/to/project/src/database.vala
Lines: 85-105
Signature: public async string? execute_query(string sql, GLib.Cancellable? cancellable = null) throws GLib.Error
Description: Executes a SQL query asynchronously and returns the result. Handles connection acquisition, query execution, and error handling. Returns null on error.
Parameters: sql: string, cancellable: GLib.Cancellable?
Returns: string?
Dependencies: calls: Connection.acquire, calls: Connection.execute, references: GLib.Error
Code:
public async string? execute_query(string sql, GLib.Cancellable? cancellable = null) throws GLib.Error {
  var conn = yield this.acquire_connection(cancellable);
  return yield conn.execute(sql);
}
```
    private string connection_string;
    private int pool_size;
    private int timeout;
    
    public DatabaseManager(string connection_string, int pool_size = 10, int timeout = 30) {
        this.connection_string = connection_string;
        this.pool_size = pool_size;
        this.timeout = timeout;
    }
    
    public async bool initialize() throws Error {
        // Connection initialization logic
    }
}
```

**Vectorization API Call**:

Each document (as formatted above) is sent to Ollama's `/api/embeddings` endpoint (or equivalent vectorize API) with:

- **Model**: The embedding model to use (e.g., `nomic-embed-text`, `all-minilm`, or model-specific embedding endpoint)
- **Input**: The complete formatted document string
- **Response**: Vector embedding (array of floats)

**Batch Processing**:

- Multiple documents can be vectorized in a single batch request if the API supports it
- Documents are grouped by file to maintain locality
- Batch size is configurable (default: 10-20 documents per batch)

**Document Metadata Storage**:

Alongside each vector, the following metadata is stored in the database (NOT in FAISS, which only stores vectors):
- Original file path
- Element type and name
- Line range (start_line, end_line)
- Vector ID in FAISS index
- Timestamp of vectorization

**Important**: Original document text is NOT stored. Code snippets are read from the filesystem when needed for result display. This approach:
- Avoids duplication (files already exist in filesystem or are referenced in SQL database)
- Reduces storage requirements
- Ensures results always show current file content
- Enables precise result location (file + line numbers)
- Supports incremental updates (re-vectorizing only changed elements)

### Component 2: Search

The search component provides semantic search capabilities:

- **Purpose**: Perform semantic search on indexed codebase
- **Features**:
  - Use local GPU for search operations when available
  - Fallback to CPU if GPU unavailable
  - Return ranked results with similarity scores
  - Support various query types (functionality search, pattern search, etc.)
- **Responsibilities**:
  - Convert search queries to embedding vectors
  - Perform similarity search in FAISS index
  - Rank and filter results
  - Return formatted results with context

### File Tracking System

The vector indexing system uses `libocfiles` (OLLMfiles namespace) for file tracking:

- **Track Indexed Files**: Store vector metadata linked to `OLLMfiles.File` objects
- **Detect Changes**: Use file modification times (`mtime`) from `OLLMfiles.File` to detect when files need re-indexing
- **Incremental Updates**: Update vectors when code or documentation changes
- **File Management**: Use `OLLMfiles.ProjectManager` and `OLLMfiles.Folder` for project-wide file discovery and hierarchy

**Note**: `libocvector` depends on `libocfiles` which provides file management without GTK/git dependencies. The `OLLMfiles` namespace provides all necessary file tracking capabilities.

Metadata storage (integrated with `OLLMfiles.File`):
- File path and ID (via `OLLMfiles.File`)
- File modification time (`mtime`) for change detection
- Last indexed timestamp
- Vector position in FAISS index
- Indexing status (indexed, needs update, error, etc.)

### Command-Line Tools

Command-line tools will be created in the `examples/` directory for testing:

#### Indexing Example (`examples/oc-vector-index.vala`)
- **Purpose**: Test single file indexing from command line
- **Features**:
  - Index a single file for testing
  - Show indexing progress
  - Simple interface for development/testing

#### Search Tool (`oc-vector-search`)
- **Namespace**: `OLLMvector.Tools.Search`
- **Purpose**: Search indexed codebases from command line
- **Features**:
  - Execute semantic search queries
  - Display ranked results
  - Filter by file type, language, etc.
  - Export results in various formats

### OLLM Library Tool Integration

A tool class will be created for use with the `libollmchat` tool system:

- **Class**: `OLLMvector.Tool.CodebaseSearchTool` (extends `OLLMchat.Tool.Interface`)
- **Purpose**: Provide semantic codebase search as a tool for LLM agents
- **Integration**: 
  - Implements `OLLMchat.Tool.Interface`
  - Provides `execute()` method for tool calling
  - Returns search results in structured format
  - Supports permission system integration

## Migration Plan: VectorSearch â†’ libocvector

### Phase 1: Create libocvector Structure
1. Create `libocvector/` directory
2. Set up `meson.build` for the library
3. Create namespace structure (`OLLMvector.Indexing`, `OLLMvector.Search`, `OLLMvector.Tools.Search`, `OLLMvector.Tool`)

### Phase 2: Migrate FAISS Components
1. **Migrate FAISS Integration**:
   - Move `VectorSearch/Index.vala` â†’ `libocvector/Index.vala`
   - Keep namespace as `Faiss` (or appropriate FAISS namespace)
   - Keep FAISS functionality intact

2. **Migrate Database**:
   - Move `VectorSearch/Database.vala` â†’ `libocvector/Database.vala`
   - Update namespace to `OLLMvector`
   - Integrate with `OLLMfiles.File` for metadata tracking

### Phase 3: Refactor Analysis Layer
1. **Create Tree Component**:
   - Create `libocvector/Indexing/Tree.vala`
   - Implement tree-sitter parser integration
   - Implement AST traversal to extract code elements
   - Create `VectorMetadata` objects with code snippets and documentation
   - Add `codedoc_start` and `codedoc_end` properties to `VectorMetadata` class (line numbers only)

2. **Refactor Analysis Component**:
   - Refactor `libocvector/Indexing/Analysis.vala` constructor to receive `Tree` object
   - Analysis iterates over `Tree.elements` and updates VectorMetadata descriptions
   - Update prompt template loading to use `---` separator (system message before `---`, user message template after)
   - Use `Tree.lines_to_string()` to extract code snippets and documentation
   - Implement simple LLM summarization (code + doc â†’ one-line text description)
   - Store descriptions in `VectorMetadata.description` property (not stored in DB)

3. **Create Vector Builder**:
   - Extract vector generation from `VectorSearch/Database.vala`
   - Create `libocvector/Indexing/VectorBuilder.vala` with constructor receiving `Tree` object
   - Use `Tree.elements` for VectorMetadata array
   - Use `Tree.lines_to_string()` for code snippet extraction
   - Separate embedding generation from storage
   - Add batch processing support

4. **Create Indexer**:
   - Refactor `VectorSearch/CodeIndexer.vala` â†’ `libocvector/Indexing/Indexer.vala`
   - Combine Tree, Analysis, and VectorBuilder layers:
     - Create `Tree(file)`, call `Tree.parse()` to populate `Tree.elements`
     - Pass `Tree` to `Analysis`, which updates `Tree.elements` with descriptions
     - Pass `Tree` to `VectorBuilder`, which uses `Tree.elements` and `Tree.lines_to_string()`
   - Add integration with `OLLMfiles` for file tracking
   - Implement incremental update logic

### Phase 4: Refactor Search Layer
1. **Create Searcher**:
   - Refactor `VectorSearch/CodeSearch.vala` â†’ `libocvector/Search/Searcher.vala`
   - Add GPU support detection and usage
   - Enhance result formatting

2. **Create Query Processor**:
   - Extract query processing logic
   - Create `libocvector/Search/QueryProcessor.vala`
   - Add query type detection and routing

### Phase 5: File Tracking Integration
1. **Integrate with libocfiles**:
   - Add `libocfiles` dependency to `libocvector/meson.build`
   - Use `OLLMfiles.File`, `OLLMfiles.Folder`, and `OLLMfiles.ProjectManager` for file tracking
   - Add vector indexing metadata fields (or create extension/wrapper if needed)
   - Store vector position and indexing status in database (link to file IDs)
   - Use `OLLMfiles.File.mtime` for change detection

### Phase 6: Create Command-Line Tools
1. **Create Indexing Example**:
   - Create `examples/oc-vector-index.vala`
   - Simple command-line tool for testing single file indexing
   - Focus on development/testing use cases

2. **Create Search Tool**:
   - Create `libocvector/Tools/SearchTool.vala`
   - Implement command-line interface
   - Add to `examples/` directory as `oc-vector-search.vala`
   - Create `oc-vector-search` executable

### Phase 7: Create OLLM Tool Integration
1. **Create CodebaseSearchTool**:
   - Create `libocvector/Tool/CodebaseSearchTool.vala`
   - Extend `OLLMchat.Tool.Interface`
   - Implement tool interface methods
   - Add to `libollmchat` tool registry

### Phase 8: Update Dependencies and Build
1. Update `meson.build`:
   - Add `libocvector` subdirectory
   - Add dependencies (libocsqlite, libollmchat, libocfiles, FAISS)
   - Note: `libocfiles` is used as a dependency for file tracking
   - Create library, VAPI, and GIR files

2. Update library dependencies:
   - Add `libocvector` to libraries that need it
   - Update VAPI dependencies (include ocfiles VAPI)

### Phase 9: Testing and Cleanup
1. Test indexing with various codebases
2. Test search functionality
3. Test command-line tools
4. Test OLLM tool integration
5. Remove or deprecate `VectorSearch/` directory
6. Update documentation

## Existing Infrastructure

The project already has a `VectorSearch/` directory with:
- **FAISS Integration** (`Index.vala`, `Database.vala`) - Vector search using FAISS
- **Code Analysis** (`CodeImport.vala`, `CodeIndexer.vala`) - Code file analysis
- **Code Search** (`CodeSearch.vala`) - Search functionality
- **Tree Layer** (`Tree.vala`) - Extracts code structure using tree-sitter (replaces old CodeElement/CodeFile flow)

This code will be migrated and refactored into the new `libocvector` structure.

## Dependencies

- **FAISS library** (already integrated via `vapi/fiass.vapi`)
- **libocsqlite** - For metadata storage
- **libollmchat** - For LLM client access and tool integration
- **libocfiles** - For file tracking and project management (provides `OLLMfiles` namespace)
- **libocagent** - For agent integration (if needed)

**Note**: `libocvector` depends on `libocfiles` for file tracking. The `libocfiles` library provides file management without GTK/git dependencies, using the `OLLMfiles` namespace.

## Files to Create

### Library Files
- `libocvector/meson.build`
- `libocvector/Index.vala` (FAISS namespace)
- `libocvector/Database.vala`
- `libocvector/Indexing/Tree.vala`
- `libocvector/Indexing/Analysis.vala`
- `libocvector/Indexing/VectorBuilder.vala`
- `libocvector/Indexing/Indexer.vala`
- `libocvector/Search/Searcher.vala`
- `libocvector/Search/QueryProcessor.vala`
- `libocvector/Tool/CodebaseSearchTool.vala`
- `libocvector/Tools/SearchTool.vala`

**Note**: File tracking is provided by `libocfiles` dependency (OLLMfiles namespace), so no Files/ directory is needed in `libocvector`.

### Example/Test Tools
- `examples/oc-vector-index.vala` (simple single-file indexing for testing)
- `examples/oc-vector-search.vala` (uses `libocvector/Tools/SearchTool.vala`)

## Features

- Semantic code search using FAISS vectors
- Support for both code and documentation indexing
- GPU-accelerated search (with CPU fallback)
- Incremental indexing with change detection
- File tracking via `libocfiles` dependency (OLLMfiles namespace)
- Command-line tools for testing and manual operations
- OLLM library tool integration for LLM agents
- Permission system integration

## Testing

- Test indexing with various codebases and languages
- Test search functionality with different query types
- Test file change detection and re-indexing
- Test command-line tools
- Test OLLM tool integration
- Test GPU vs CPU search performance
- Test incremental updates
- Add to meson.build
