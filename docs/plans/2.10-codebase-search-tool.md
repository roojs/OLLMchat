# 2.10. Codebase Search Tool

## Overview

Implementation of a semantic codebase search tool using vector embeddings and FAISS. The code will be migrated from the existing `VectorSearch/` directory into a new `libocvector` library with two main components: **Indexing** and **Search**. The library uses `libocfiles` (OLLMfiles namespace) for file tracking and project management, providing file management without GTK/git dependencies.

**Architecture Reference:** See `docs/plans/2.10-vector-storage-architecture.md` for detailed information about:
- What's stored in FAISS vs SQL database
- Minimum schema requirements (6 fields)
- Why certain fields are/aren't stored
- Data flow and query patterns

## Status

ðŸš§ **IN PROGRESS** - Foundation, FAISS migration, Tree layer (Phase 3a), Analysis layer (Phase 3), Vector Building (Phase 4), Indexer Orchestration (Phase 5), and Search layer (Phase 6 - Search and SearchResult completed, SearchBuilder pending) completed. File Tracking Integration (Phase 7) and OLLM Tool Integration (Phase 9) pending.

## Todo List

### Phase 1: Foundation & Structure
- [x] Create `libocvector/` directory structure
- [x] Set up `libocvector/meson.build` for the library
- [x] Create namespace structure (`OLLMvector.Indexing`, `OLLMvector.Search`, `OLLMvector.Tools.Search`, `OLLMvector.Tool`) - *Partially done: OLLMvector namespace exists, subdirectories not yet created*
- [x] Add `libocfiles` dependency to `libocvector/meson.build` - *Uses OLLMfiles namespace for file tracking*

### Phase 2: FAISS Migration
- [x] Migrate `VectorSearch/Index.vala` â†’ `libocvector/Index.vala` (FAISS namespace)
- [x] Migrate `VectorSearch/Database.vala` â†’ `libocvector/Database.vala`
- [x] Update Database namespace to `OLLMvector`
- [x] Create FAISS C++ wrapper (`faiss_c_wrapper.cpp`) - *Additional work not in original plan*
- [ ] Integrate Database with `OLLMfiles.File` for metadata tracking - *TODOs in code indicate this is pending*

### Phase 3a: Tree Layer Implementation
- [x] Create `libocvector/Indexing/Tree.vala`
- [x] Implement tree-sitter parser integration using `TreeSitter` namespace from `vapi/tree-sitter.vapi`
- [x] Implement language detection and tree-sitter language selection based on file language
- [x] Implement AST traversal to extract code elements (classes, functions, methods, etc.)
- [x] Create `VectorMetadata` objects from tree-sitter nodes with line numbers
- [x] Extract code documentation blocks using tree-sitter API (doc comments, JSDoc, etc.) related to each element
- [x] Add `codedoc_start` and `codedoc_end` properties to `VectorMetadata` class (line numbers only, not stored in DB, used for analysis)
- [x] Tree class: Constructor takes `OLLMfiles.File` as argument, stores as property
- [x] Tree class: Add `elements` property (Gee.ArrayList<VectorMetadata>) to store VectorMetadata array
- [x] Tree class: Add `lines` property (string[]) containing file content split into lines
- [x] Tree class: Add `lines_to_string(int start_line, int end_line)` method using Vala string range syntax `lines[start:end]`
- [x] **Additional**: Added `signature` property to `VectorMetadata` for method/function signatures
- [x] **Additional**: Added `namespace` property to `VectorMetadata` to track namespace context
- [x] **Additional**: Added `parent_class` property to `VectorMetadata` to track parent class/struct/interface for methods, properties, fields
- [x] **Additional**: Implemented enum value relationship tracking (enum values prefixed with parent enum name, e.g., `FormatType.NONE`)
- [x] **Additional**: Implemented signature extraction with whitespace cleaning for multi-line signatures
- [x] **Additional**: Implemented property accessor extraction (get/set/default) in signatures
- [x] **Additional**: Added debug output for dropped elements to help diagnose extraction issues

### Phase 3: Analysis Layer Implementation
### Phase 3a: Tree Layer Implementation
- [x] Create `libocvector/Indexing/Tree.vala`
- [x] Implement tree-sitter parser integration using `TreeSitter` namespace from `vapi/tree-sitter.vapi`
- [x] Implement language detection and tree-sitter language selection based on file language
- [x] Implement AST traversal to extract code elements (classes, functions, methods, etc.)
- [x] Create `VectorMetadata` objects from tree-sitter nodes with line numbers
- [x] Extract code documentation blocks using tree-sitter API (doc comments, JSDoc, etc.) related to each element
- [x] Add `codedoc_start` and `codedoc_end` properties to `VectorMetadata` class (line numbers only, not stored in DB, used for analysis)
- [x] Tree class: Constructor takes `OLLMfiles.File` as argument, stores as property
- [x] Tree class: Add `elements` property (Gee.ArrayList<VectorMetadata>) to store VectorMetadata array
- [x] Tree class: Add `lines` property (string[]) containing file content split into lines
- [x] Tree class: Add `lines_to_string(int start_line, int end_line)` method using Vala string range syntax `lines[start:end]`
- [x] **Additional**: Added `signature` property to `VectorMetadata` for method/function signatures
- [x] **Additional**: Added `namespace` property to `VectorMetadata` to track namespace context
- [x] **Additional**: Added `parent_class` property to `VectorMetadata` to track parent class/struct/interface for methods, properties, fields
- [x] **Additional**: Implemented enum value relationship tracking (enum values prefixed with parent enum name, e.g., `FormatType.NONE`)
- [x] **Additional**: Implemented signature extraction with whitespace cleaning for multi-line signatures
- [x] **Additional**: Implemented property accessor extraction (get/set/default) in signatures
- [x] **Additional**: Added debug output for dropped elements to help diagnose extraction issues

### Phase 3: Analysis Layer Implementation
- [x] Create `libocvector/Indexing/Analysis.vala`
- [x] Refactor Analysis constructor to receive `Tree` object as argument (via `analyze_tree()` method)
- [x] Analysis iterates over `Tree.elements` and updates VectorMetadata descriptions
- [x] Load prompt templates from resources (use `---` separator between system and user prompts)
- [x] Implement simple LLM call that sends code + documentation for summarization
- [x] Return one-line text descriptions (not structured JSON)
- [x] Store descriptions in `VectorMetadata` objects as property (not stored in DB, used by VectorBuilder)
- [x] Integrate with `OLLMfiles` for file tracking (via `Tree.file` property)
- [x] Add error handling and fallback strategies

### Phase 4: Vector Building Implementation
**Note:** This phase works on **one file at a time** (processes `Tree` object from Analysis layer). Phase 5 (Indexer Orchestration) will handle multiple files and project-wide indexing.

**Reference:** See `docs/plans/2.10-vector-storage-architecture.md` for detailed schema and architecture decisions.

- [x] Create `libocvector/Indexing/VectorBuilder.vala`
  - âœ… Done: Takes `VectorMetadata[]` from Analysis layer (with descriptions populated)
  - âœ… Done: Refactor: Updated to receive `Tree` object as argument
  - âœ… Done: Refactor: Uses `Tree.elements` for VectorMetadata array
  - âœ… Done: Refactor: Uses `Tree.lines_to_string()` method for code snippet extraction
  - âœ… Done: Formats each element into document for vectorization
  - âœ… Done: Generates embeddings and stores in FAISS
  - âœ… Done: Stores metadata in SQL database
- [x] Implement document formatting for vectorization
  - âœ… Done: Format: type, name, file, lines, description, parameters, return type, dependencies, code snippet
  - âœ… Done: Follows plan lines 239-323 for detailed format specification
  - âœ… Done: Applies smart code snippet truncation based on element type (classes vs methods)
- [x] Implement Ollama embeddings API integration (`/api/embeddings`)
  - âœ… Done: `Database.vala` uses `ollama.embed()` method
  - âœ… Done: `libollmchat.Client.embed()` and `embed_array()` available
- [x] Implement batch processing for vector generation
  - âœ… Done: `VectorBuilder.vala` uses `embed_array()` for true batch processing (15 documents per batch)
  - âœ… Done: Processes embeddings in batches of 10-20 documents
- [x] Implement FAISS vector storage
  - âœ… Done: `libocvector/Index.vala` implements FAISS with `add_vectors()`
  - âœ… Done: `Database.vala` uses `index.add_vectors(vector_batch)`
- [x] Implement metadata storage in SQL database
  - âœ… Done: Schema: `vector_id`, `file_id`, `start_line`, `end_line`, `element_type`, `element_name`
  - âœ… Done: Follows `docs/plans/2.10-vector-storage-architecture.md` minimal schema (6 fields)
  - âœ… Done: Integrated with `libocsqlite` for SQL storage
  - âœ… Done: Stores metadata when vectors are added (link vector_id to file_id + line range)
  - âœ… Done: `VectorMetadata` class created following FileBase pattern with `initDB`, `saveToDB`, `lookup` methods
  - âš ï¸ Lookup for search results (vector_id â†’ file path + code snippet) - pending in Search layer

**Additional Improvements:**
- âœ… Tree layer extracts all structure: Tree layer uses tree-sitter to extract element type, name, signature, namespace, parent class, line numbers, documentation ranges - no LLM needed for structure extraction
- âœ… Code snippet optimization: Using `string[]` arrays and Vala array slicing (`array[start:end]`) throughout
- âœ… Coding standards: Applied throughout (removed single-use variables, proper string concatenation, line breaking)
- âœ… Database properties: Refactored `dimension` and `vector_count` to read-only properties
- [x] **NEW**: Tree layer will use tree-sitter to create `VectorMetadata` objects directly (replacing CodeFile/CodeElement flow)
- [x] **NEW**: `VectorMetadata` will have `codedoc_start` and `codedoc_end` properties (line numbers only, not stored in DB) for documentation blocks
- [x] **NEW**: `VectorMetadata` has `signature`, `namespace`, and `parent_class` properties (not stored in DB, used for analysis and code block generation)

### Phase 5: Indexer Orchestration
- [x] Add `last_scan` field to `filebase` table
  - Add `last_scan INT64 NOT NULL DEFAULT 0` to filebase table schema
  - Add `last_scan` property to `FileBase` class
  - Implement database migration for existing databases (ALTER TABLE)
  - For files: `last_scan` = timestamp when scan completed (after successful vectorization)
  - For folders: `last_scan` = timestamp when scan started (to prevent re-recursion during same scan)
- [x] Create `libocvector/Indexing/Indexer.vala`
- [x] Integrate Tree, Analysis, and VectorBuilder components
  - Create Tree(file), call Tree.parse()
  - Pass Tree to Analysis, which updates Tree.elements
  - Pass Tree to VectorBuilder, which uses Tree.elements and Tree.lines_to_string()
- [x] Implement incremental update logic
  - Check `file.last_scan` vs `file.mtime_on_disk()` for files
  - Skip files where `last_scan >= mtime_on_disk()` (not modified since last scan)
  - Note: Cannot do mtime check on folders (folders don't have reliable mtime)
  - For folders: check `folder.last_scan` to avoid re-recursion during same scan session
  - Update `file.last_scan` after successful indexing (time of completion)
  - Update `folder.last_scan` at start of folder scan (time of start, before processing children)
- [x] Implement folder-based indexing
  - Starting point: folder in database (must exist in database, query by path)
  - Option to recurse into subfolders (controlled by `--recurse` flag)
  - Use `OLLMfiles.Folder` and `OLLMfiles.ProjectManager` for traversal
  - Only process files that exist in database (don't scan filesystem directly)
  - Process files in folder: iterate through `folder.children.items` and filter for `File` objects
  - For recursion: recursively process subfolders, checking `folder.last_scan` to avoid duplicates
- [x] Update `oc-vector-index` example tool
  - Use `~/.local/share/ollmchat/files.sqlite` as database path (existing ollmchat database)
  - Accept either file path or folder path as argument
  - If file: process single file (existing behavior)
  - If folder: process all files in folder, with optional recursion
  - Add `--recurse` / `-r` flag for recursive indexing (only applies when folder is specified)
  - Store vector database at `~/.local/share/ollmchat/codedb.faiss.vectors`
  - Load folder from database as starting point (must exist in database)
  - Output vectorized summaries: show descriptions for each element being vectorized
  - Add line break after each file's vectorization completes (for readability)

### Phase 6: Search Layer Implementation
- [ ] **OPTIONAL**: Create `libocvector/Search/SearchBuilder.vala` - *Not strictly needed*
  - **Analysis**: The `Search` class already accepts all required parameters directly via constructor
  - **Current approach**: Filtering logic (folder, language, element_type) can be done via helper methods or directly in tool implementations
  - **Example**: `oc-vector-search.vala` demonstrates filtering by building SQL queries and passing `filtered_vector_ids` to `Search` constructor
  - **Decision**: SearchBuilder is optional - can be added later if a cleaner builder API is desired, but not required for functionality
  - **Alternative**: Create static helper methods in `Search` class for common filtering patterns (e.g., `Search.filter_by_folder()`, `Search.filter_by_language()`)
- [x] Create `libocvector/Search/Search.vala`
  - âœ… Done: Executes the actual search operation
  - âœ… Done: Constructor takes all required dependencies directly
  - âœ… Done: Dependencies:
    - `OLLMvector.Database` - Vector database for FAISS search
    - `SQ.Database` - SQL database for metadata and filtering
    - `OLLMchat.Client` - Embedding client for query vectorization
    - `OLLMfiles.Folder` - For file operations (passed to SearchResult for code snippet extraction)
  - âœ… Done: Methods:
    - `async execute()` - Runs the search and returns SearchResult[] array
  - âœ… Done: Implementation:
    - Query preprocessing (basic normalization)
    - Query vectorization (convert text to embeddings using embedding client)
    - Filtered vector_ids support (via IDSelector for FAISS native filtering)
    - Perform FAISS similarity search (on filtered vector set if possible, or filter results after)
    - Lookup metadata for result vector_ids
    - Create SearchResult[] array, passing SQ.Database and Folder to each SearchResult constructor
    - Return SearchResult[] array (SearchResult objects contain formatting methods)
  - âœ… Done: GPU/CPU support:
    - **NOTE**: GPU support not available at present - FAISS library was only built with CPU support
    - Uses CPU-only operations
    - Structured to support future GPU fallback when GPU support becomes available
    - Logs which backend (CPU/GPU) is being used for debugging
- [x] Create `libocvector/Search/SearchResult.vala`
  - âœ… Done: Represents a single search result
  - âœ… Done: Constructor dependencies:
    - `SQ.Database` - SQL database for file lookup and VectorMetadata access
    - `OLLMfiles.Folder` - For file operations (to read code snippets)
  - âœ… Done: Properties:
    - `vector_id` (int64) - FAISS vector ID
    - `similarity_score` (float) - FAISS similarity score
    - `metadata` (VectorMetadata) - Code location metadata
    - `code_snippet()` - Method: Extracts code snippet from file_path + line_range on demand
      - Uses metadata.file_id to lookup File via Folder.project_files
      - Reads file content and extracts lines using metadata.start_line and metadata.end_line
    - `file_path()` - Method: Gets file path from metadata.file_id
  - âœ… Done: Methods:
    - `code_snippet()` - Extracts code snippet from file
    - `file_path()` - Gets file path
    - Implements `Json.Serializable` for JSON serialization
    - Note: `to_string()` and `to_json()` can be added if needed, or formatting done in command-line tool

### Phase 7: Background Scanning Integration

**Note**: We are NOT implementing file tracking integration. Instead, we're implementing a background scanning system that automatically indexes files when projects are activated or files are saved.

- [x] Create `libocvector/BackgroundScan.vala`
  - **Purpose**: Background thread that manages automatic file indexing
  - **Thread Management**: 
    - Runs as a background thread with its own MainLoop (similar to `PullManagerThread` pattern)
    - Thread is started lazily on first use (via `ensure_thread()`)
    - Thread remains running for the lifetime of the application
  - **Queue System**:
    - Maintains a queue of files to scan using `Gee.ArrayQueue<BackgroundScanItem>`
    - `BackgroundScanItem` class stores both `project_path` and `file_path` (needed to locate files in database)
    - Queue is accessed only from background thread context (main thread dispatches via `IdleSource` callbacks attached to `worker_context`)
    - No mutex needed - all queue operations happen in background thread context
    - Queue processing runs in background thread context
  - **Methods** (called from main thread):
    - `scanProject(OLLMfiles.Folder project)` - Called when user switches to a project in UI
      - If background thread not running, start it (via `ensure_thread()`)
      - Extracts `project.path` (thread-safe string) before creating callback
      - Dispatches `queueProject(string path)` to background thread via `IdleSource` attached to `worker_context`
    - `scanFile(OLLMfiles.File file, OLLMfiles.Folder project)` - Called when a file is saved
      - If background thread not running, start it (via `ensure_thread()`)
      - Extracts `file.path` and `project.path` (thread-safe strings) before creating callback
      - Dispatches `queueFile(BackgroundScanItem)` to background thread via `IdleSource` attached to `worker_context`
  - **Methods** (executed in background thread):
    - `queueProject(string path)` - Processes project queue item (async)
      - Ensures `ProjectManager` exists in background thread context
      - Loads projects from database via `ProjectManager`
      - Finds project by path using `path_map` (O(1) lookup)
      - Sets active project and loads files from database (via `set_active_project_and_load()`)
      - Iterates through `project.project_files` (flat list)
      - For each file, checks if modified since last scan (`file.last_scan >= file.mtime_on_disk()` - negative test)
      - For files that need scanning, creates `BackgroundScanItem` and calls `queueFile()`
    - `queueFile(BackgroundScanItem item)` - Adds file to scan queue
      - Lazy initializes queue if needed
      - Adds item to queue (no mutex needed - already in background thread context)
      - Starts `startQueue()` if not already processing (async method)
    - `startQueue()` - Processes file queue (async)
      - Runs in background thread context (async method called via IdleSource)
      - Sets `queue_processing` flag to prevent multiple concurrent runs
      - Continuously polls items from file queue until empty
      - For each item:
        - Finds project by `item.project_path` using `path_map`
        - Sets active project and reloads files from database (state may have changed)
        - Finds file in project's `project_files.child_map` by `item.file_path`
        - Emits `scan_update` signal with current queue size and file path
        - Lazily creates/reuses `Indexer` instance
        - Calls `indexer.index_file(file)` to scan the file (async operation)
      - When queue is empty, emits `scan_update(0, "")` and stops processing
  - **Additional Implementation Details**:
    - `ensure_project_manager()` - Creates `ProjectManager` instance in background thread context (lazy initialization)
    - `set_active_project()` - Manages active project in background thread, clears data from previous project to free memory
    - `set_active_project_and_load()` - Combines setting active project and loading files from database
    - `emit_scan_update()` - Emits signal on main thread via `main_context.invoke()`
    - `stop()` - Gracefully stops background thread (optional, thread lives for app lifetime)
  - **Dependencies**:
    - Requires `OLLMchat.Client` for analysis and embedding clients
    - Requires `OLLMvector.Database` for vector storage
    - Requires `SQ.Database` for metadata storage
    - Requires `OLLMfiles.ProjectManager` for file operations (created in background thread context)
  - **Signals**:
    - `scan_update(int queue_size, string current_file)` - Emitted when a file scan starts and when queue becomes empty
      - `queue_size`: Current number of files remaining in queue
      - `current_file`: Path of file currently being scanned (empty string "" when queue is empty)
- [ ] Window Integration
  - **Window Initialization**: 
    - When window starts, create `BackgroundScan` instance
    - Store `BackgroundScan` instance in window (thread starts automatically when items are added to queue)
  - **Project Switching**:
    - Connect to `ProjectManager.active_project_changed` signal
    - When project changes, call `background_scan.scanProject(project)`
  - **File Saving**:
    - Window connects to ProjectManager signals:
      - `file_metadata_changed(File file)` - emitted when file metadata changes (cursor, scroll, last_viewed) - Window does NOT trigger background scanning
      - `file_contents_changed(File file)` - emitted when file content changes (saved, edited) - Window calls `background_scan.scanFile(file, active_project)`
    - **Current callers that should use `on_file_metadata_change()`**:
      - `SourceView.save_current_file_state()` - called when switching files or scrolling (metadata only)
      - `SourceView.open_file()` - called when opening a file (metadata only)
      - `SourceView` scroll timeout - called when scroll position changes (metadata only)
    - **Current callers that should use `on_file_contents_change()`**:
      - `SourceView.save_file()` - when user saves file via save button
      - `FileBuffer.write()` / `FileBuffer.apply_edits()` - when file content is written
      - `RequestEditMode.apply_all_changes()` - when edit mode applies changes
- [ ] ProjectManager Integration
  - **Split `notify_file_changed()` into two methods**:
    - `on_file_metadata_change(File file)` - replaces current `notify_file_changed()` for metadata-only updates
      - Saves file to database
      - Emits `file_metadata_changed(File file)` signal
    - `on_file_contents_change(File file)` - new method for content changes
      - Saves file to database
      - Emits `file_contents_changed(File file)` signal
  - **Add signals to ProjectManager**:
    - `file_metadata_changed(File file)` - signal emitted when file metadata changes
    - `file_contents_changed(File file)` - signal emitted when file content changes
  - **Window Integration**:
    - Window connects to `ProjectManager.file_contents_changed` signal
    - When signal is emitted, Window calls `background_scan.scanFile(file, project_manager.active_project)`
    - Window does NOT connect to `file_metadata_changed` (no background scanning needed for metadata)
  - **Update FileBuffer Integration**:
    - `FileBuffer.update_file_metadata_after_write()` currently calls `file.changed()` signal
    - **Note**: Nothing currently listens to `file.changed()` signal (no connections found in codebase)
    - Should replace `file.changed()` call with `file.manager.on_file_contents_change(file)` after writing content
    - This ensures both `sync_to_file()` and `write()` trigger the ProjectManager signal
    - Can keep `file.changed()` signal for backward compatibility if needed, but it's not currently used
  - **Edit Mode Integration**:
    - **No changes needed** - Edit mode uses `FileBuffer.write()` and `FileBuffer.apply_edits()` which both call `update_file_metadata_after_write()`
    - Since `FileBuffer.update_file_metadata_after_write()` will call `on_file_contents_change()`, edit mode will automatically trigger the signal
    - No need to add explicit `on_file_contents_change()` call in `RequestEditMode.apply_all_changes()` - it happens automatically when file content is written
- [x] Build System Updates
  - `libocvector/BackgroundScan.vala` is already added to `libocvector/meson.build` (line 69)
  - All dependencies are available (libocvector, libocfiles, libollmchat, libocsqlite)

### Phase 8: Command-Line Tools
- [x] Create `examples/oc-vector-index.vala` (single file indexing tool)
- [ ] Create `libocvector/Tools/SearchTool.vala` - *Not needed yet, Search class used directly*
- [x] Create `examples/oc-vector-search.vala` (search tool executable)
  - âœ… Done: Command-line argument parsing with options for debug, json output, folder filter, language filter, element-type filter, max-results
  - âœ… Done: Result formatting for search output (text and JSON formats)
  - âœ… Done: Integration with Search class and SearchResult formatting
- [x] Implement command-line argument parsing - *Implemented in both oc-vector-index and oc-vector-search*
- [x] Add progress display for indexing - *Implemented in oc-vector-index*
- [x] Add result formatting for search output - *Implemented in oc-vector-search with text and JSON output*

### Phase 9: OLLM Tool Integration

**Location**: `liboccoder/Tool/CodebaseSearchTool.vala` (NOT in `libocvector`)

**Rationale**: 
- `liboccoder` has `ProjectManager` which manages the active project
- The tool needs access to `ProjectManager.active_project` to get the current project folder
- `liboccoder` is the appropriate layer for tools that integrate with the code editor/project management system
- `libocvector` is a lower-level library focused on vector operations, not tool integration

#### 9.1: Tool Class Structure

- [ ] Create `liboccoder/Tool/CodebaseSearchTool.vala`
  - **Namespace**: `OLLMcoder.Tool`
  - **Extends**: `OLLMchat.Tool.Interface`
  - **Constructor dependencies**:
    - `OLLMchat.Client client` - Required by base class
    - `OLLMfiles.ProjectManager manager` - For accessing active project and database (via `manager.db`)
    - `OLLMvector.Database vector_db` - Vector database for FAISS search
    - `OLLMchat.Client embedding_client` - Embedding client for query vectorization (may be same as `client`)
  - **Properties**:
    - `name` (override): `"codebase_search"`
    - `description` (override): Tool description explaining semantic codebase search
    - `parameter_description` (override): Parameter documentation
  - **Methods**:
    - `deserialize()` - Creates `RequestCodebaseSearch` from JSON parameters

#### 9.2: Request Class Structure

- [ ] Create `liboccoder/Tool/RequestCodebaseSearch.vala`
  - **Namespace**: `OLLMcoder.Tool`
  - **Extends**: `OLLMchat.Tool.RequestBase`
  - **Parameter properties** (from LLM function call):
    - `query` (string, required) - Search query text
    - `language` (string?, optional) - Filter by File.language property (e.g., "vala", "python")
    - `element_type` (string?, optional) - Filter by element type (e.g., "class", "method", "function")
    - `max_results` (int, optional, default: 10) - Maximum number of results to return
  - **Properties**:
    - Reference to Tool: `RequestCodebaseSearch` has access to `CodebaseSearchTool` via `this.tool` property (inherited from `RequestBase`)
  - **Methods**:
    - `execute_request()` - Executes the search and returns formatted results
      - Gets active project from `ProjectManager.active_project`
      - Validates active project exists (error if null)
      - Builds filtered vector IDs using SQL queries (similar to `oc-vector-search.vala`)
      - Creates `OLLMvector.Search.Search` instance
      - Executes search and formats results for LLM consumption

#### 9.3: Search Execution Flow

- [ ] Implement search execution in `RequestCodebaseSearch.execute_request()`
  - **Step 1**: Get active project from `ProjectManager`
    ```vala
    var active_project = this.get_project_manager().active_project;
    if (active_project == null) {
      throw new GLib.IOError.FAILED("No active project. Please open a project first.");
    }
    ```
    - **Note**: ProjectManager is responsible for loading files - they should already be loaded when project is active
  - **Step 2**: Get file IDs from project_files (with optional language filter)
    ```vala
    var language_filter = this.language != null ? this.language : "";
    var file_ids = active_project.project_files.get_ids(language_filter);
    
    if (file_ids.size == 0) {
      if (language_filter != "") {
        throw new GLib.IOError.FAILED("No files found in folder matching language filter: " + language_filter);
      } else {
        throw new GLib.IOError.FAILED("No files found in folder");
      }
    }
    ```
    - Uses `project_files.get_ids(language_filter)` which handles language filtering automatically
  - **Step 3**: Build filtered vector IDs using SQL query (exactly as `oc-vector-search.vala` does)
    ```vala
    var filtered_vector_ids = new Gee.ArrayList<int>();
    
    // Build SQL query string (file_ids joined directly, not parameterized)
    var file_id_list = string.joinv(",", file_ids.to_array());
    var sql = "SELECT DISTINCT vector_id FROM vector_metadata WHERE file_id IN (" + file_id_list + ")";
    
    if (this.element_type != null) {
      sql = sql + " AND element_type = $element_type";
    }
    
    // Use VectorMetadata.query() helper
    var sql_db = this.get_project_manager().db;
    var vector_query = OLLMvector.VectorMetadata.query(sql_db);
    var vector_stmt = vector_query.selectPrepare(sql);
    
    if (this.element_type != null) {
      vector_stmt.bind_text(
        vector_stmt.bind_parameter_index("$element_type"), this.element_type);
    }
    
    // Fetch vector IDs as strings and parse to int
    foreach (var vector_id_str in vector_query.fetchAllString(vector_stmt)) {
      filtered_vector_ids.add((int)int64.parse(vector_id_str));
    }
    ```
    - **Note**: Follows exact pattern from `oc-vector-search.vala` lines 228-251
    - File IDs are joined directly into SQL string (not parameterized for IN clause)
    - Uses `VectorMetadata.query()` helper method
    - Uses `fetchAllString()` to get results as strings, then parses to int
  - **Step 4**: Create and execute search (exactly as `oc-vector-search.vala` does)
    ```vala
    var search = new OLLMvector.Search.Search(
      this.vector_db,
      this.get_project_manager().db,  // Access database via ProjectManager
      this.embedding_client,
      active_project,
      this.query,
      (uint64)this.max_results,
      filtered_vector_ids
    );
    var results = yield search.execute();
    ```
    - **Note**: Follows exact pattern from `oc-vector-search.vala` lines 255-281
  - **Step 5**: Format results for LLM consumption
    - Format each result using citation format: `startLine:endLine:filepath`
    - Include code snippet with proper formatting
    - Return formatted string
    - Format each result using citation format: `startLine:endLine:filepath`
    - Include code snippet with proper formatting
    - Return formatted string

#### 9.4: Result Formatting

- [ ] Implement result formatting for LLM agents
  - **Format**: Text string with code citations (matching citation format requirements)
  - **Structure**:
    ```
    Found {count} result(s) for "{query}":
    
    1. {element_name} ({element_type}) - {file_path}:{start_line}-{end_line}
    Description: {description}
    ```{start_line}:{end_line}:{file_path}
    {code_snippet}
    ```
    
    2. {element_name} ({element_type}) - {file_path}:{start_line}-{end_line}
    Description: {description}
    ```{start_line}:{end_line}:{file_path}
    {code_snippet}
    ```
    ...
    ```
  - **Code snippet**: Use `SearchResult.code_snippet()` method (truncate to reasonable size, e.g., 50 lines max)
  - **Description**: Include element description from `SearchResult.metadata.description` (may be empty for simple elements)
  - **Element info**: Include element name and type for context
  - **File path**: Use absolute path for citations

#### 9.5: ProjectManager Integration

- [ ] Access ProjectManager from Request class
  - **Solution**: Store `ProjectManager` in `CodebaseSearchTool` as private property, access via `this.tool` in Request
  - **Note**: `RequestCodebaseSearch` has a reference to the Tool via `this.tool` property (inherited from `RequestBase`)
    ```vala
    // In CodebaseSearchTool
    private OLLMfiles.ProjectManager manager;
    
    // In RequestCodebaseSearch
    private OLLMfiles.ProjectManager get_project_manager() {
      return ((OLLMcoder.Tool.CodebaseSearchTool)this.tool).manager;
    }
    ```
  - **Database access**: Access SQL database via `this.get_project_manager().db` (ProjectManager has `db` property)

#### 9.6: Tool Registration

- [ ] Add tool to tool registry
  - **Location**: Where tools are registered (likely in `ollmchat/` application code or `liboccoder` initialization)
  - **Registration**: Add `CodebaseSearchTool` instance to `Client.tools` HashMap
  - **Dependencies**: Ensure `libocvector` is linked to `liboccoder` in `meson.build`
  - **Initialization**: Create tool instance with required dependencies:
    ```vala
    var codebase_search_tool = new OLLMcoder.Tool.CodebaseSearchTool(
      client,
      project_manager,
      vector_db,
      embedding_client
    );
    client.tools.set("codebase_search", codebase_search_tool);
    ```

#### 9.7: Permission System Integration

- [ ] **No permissions needed** - Codebase search is a read-only operation that doesn't require permission prompts
  - Search operations are safe and don't modify files or system state
  - No `build_perm_question()` method needed
  - Request can proceed directly to `execute_request()`

#### 9.8: Error Handling

- [ ] Implement error handling
  - **No active project**: Return clear error message
  - **No files in project**: Return informative message
  - **No results found**: Return "No results found for '{query}'" (not an error)
  - **Search execution errors**: Catch and return formatted error messages
  - **Database errors**: Handle SQL query failures gracefully

#### 9.9: Build System Updates

- [ ] Update `liboccoder/meson.build`
  - Add `libocvector` dependency
  - Add new source files:
    - `Tool/CodebaseSearchTool.vala`
    - `Tool/RequestCodebaseSearch.vala`
  - Ensure VAPI dependencies include `libocvector`

#### 9.10: Testing

- [ ] Test tool integration
  - Test with active project set
  - Test with no active project (should return error)
  - Test with various query types
  - Test with language and element_type filters
  - Test permission system integration
  - Test result formatting (citation format)
  - Test error handling

### Phase 10: Build System & Dependencies
- [x] Update root `meson.build` to include `libocvector` subdirectory
- [x] Add dependencies to `libocvector/meson.build` (libocsqlite, libollmchat, libocfiles, FAISS)
- [x] Note: `libocfiles` is used as a dependency (no need to copy FileBase structure)
- [x] Generate VAPI files for `libocvector` - *Generated via meson.build*
- [ ] Generate GIR files for `libocvector` - *Commented out in meson.build, pending implementation*
- [x] Update library dependencies in consuming projects - *examples/meson.build updated*
- [x] Update VAPI dependencies

### Phase 11: Testing
- [ ] Test indexing with various codebases (Vala, Python, JavaScript, etc.)
- [ ] Test search functionality with different query types
- [ ] Test file change detection and re-indexing
- [ ] Test command-line tools (`oc-vector-index`, `oc-vector-search`)
- [ ] Test OLLM tool integration
- [ ] Test GPU vs CPU search performance
- [ ] Test incremental updates
- [ ] Test structured outputs reliability
- [ ] Test batch processing for vectorization
- [ ] Test error handling and fallbacks

### Phase 12: Cleanup & Documentation
- [ ] Remove or deprecate `VectorSearch/` directory
- [ ] Update project documentation
- [ ] Add code comments and documentation
- [ ] Create usage examples
- [ ] Document API for library consumers

## Architecture

### Library Structure: `libocvector`

The vector search functionality will be organized as a new library `libocvector` with the following structure:

```
libocvector/
â”œâ”€â”€ meson.build
â”œâ”€â”€ Files/                      # FileBase structure (copied from liboccoder, no dependency)
â”‚   â”œâ”€â”€ FileBase.vala          # Base class for File and Folder
â”‚   â”œâ”€â”€ File.vala              # File class
â”‚   â””â”€â”€ Folder.vala            # Folder class
â”œâ”€â”€ Indexing/
â”‚   â”œâ”€â”€ Tree.vala               # Tree-sitter AST parsing and VectorMetadata creation
â”‚   â”œâ”€â”€ Analysis.vala           # LLM-based code summarization
â”‚   â”œâ”€â”€ VectorBuilder.vala      # Vector generation and FAISS storage
â”‚   â””â”€â”€ Indexer.vala            # Main indexing orchestrator
â”œâ”€â”€ Search/
â”‚   â”œâ”€â”€ SearchBuilder.vala      # OPTIONAL: Builder for creating and configuring searches (not required)
â”‚   â”œâ”€â”€ Search.vala             # Executes search operations (manages search flow)
â”‚   â””â”€â”€ SearchResult.vala        # Search result object with formatting methods
â””â”€â”€ Tool/
    â””â”€â”€ (No tools in libocvector - tools are in liboccoder/Tool/)
```

**Note**: The `Files/` directory contains a copy of the FileBase structure from `liboccoder`. This avoids dependency issues while maintaining the same file/folder tracking capabilities. The code is based on `liboccoder.Files` but exists independently in `libocvector.Files` namespace.

### Component 1: Indexing

The indexing component consists of three layers:

#### Layer 1: Tree (Tree-sitter AST Parsing)
- **Purpose**: Parse source code files using tree-sitter to extract code elements and create `VectorMetadata` objects
- **Input**: 
  - Code files (via `OLLMfiles.File`)
- **Output**: Array of `VectorMetadata` objects with code element information and documentation
- **Responsibilities**:
  - Use tree-sitter parser to parse source code files
  - Traverse AST to identify code elements (classes, functions, methods, properties, etc.)
  - Extract line numbers (start_line, end_line) for each element
  - Extract code documentation blocks (doc comments, JSDoc, etc.) associated with each element
  - Create `VectorMetadata` objects for each code element
  - Extract code snippets from file using line numbers
  - Pass array of `VectorMetadata` objects to Analysis layer

**Tree Layer Implementation Details**:

The Tree layer uses the `TreeSitter` namespace from `vapi/tree-sitter.vapi` to parse source code files. Core implementation includes:

**Core Code Structure**:

```vala
namespace OLLMvector.Indexing {
    public class Tree : Object {
        // Properties
        public OLLMfiles.File file { get; private set; }
        public Gee.ArrayList<VectorMetadata> elements { get; private set; }
        public string[] lines { get; private set; }
        
        private TreeSitter.Parser parser;
        private TreeSitter.Language? language;
        
        // Constructor: takes File as argument
        public Tree(OLLMfiles.File file) throws GLib.Error;
        
        // Main entry point: parse file and populate elements array
        public async void parse() throws GLib.Error;
        
        // Extract string from lines array using Vala string range syntax
        public string lines_to_string(int start_line, int end_line);
        
        // Language detection and tree-sitter language selection
        private TreeSitter.Language? get_language_for_file();
        
        // Parse source code using tree-sitter
        private TreeSitter.Tree? parse_code(string code, TreeSitter.Language lang);
        
        // Traverse AST and extract code elements
        private void traverse_ast(TreeSitter.Node node);
        
        // Extract code element information from AST node
        private VectorMetadata? extract_element_metadata(TreeSitter.Node node);
        
        // Extract documentation block line numbers using tree-sitter API
        private void extract_documentation_lines(TreeSitter.Node node, out int? codedoc_start, out int? codedoc_end);
        
        // Determine element type from tree-sitter node type
        private string get_element_type(TreeSitter.Node node, TreeSitter.Language lang);
        
        // Get element name from AST node
        private string? get_element_name(TreeSitter.Node node);
    }
}
```

**Key Methods**:

1. **Constructor `Tree(OLLMfiles.File file)`**:
   - Stores `file` as property
   - Initializes `elements` as empty ArrayList
   - Reads file content and splits into `lines` array

2. **`parse()`**: Main entry point that:
   - Detects file language
   - Loads appropriate tree-sitter language parser
   - Parses file content
   - Traverses AST to extract elements
   - Populates `elements` array with `VectorMetadata` objects

3. **`lines_to_string(int start_line, int end_line)`**: Extracts string from lines array:
   - Uses Vala string range syntax: `lines[start_line:end_line]`
   - Joins array slice with newlines
   - Returns code snippet or documentation text
   - Used by Analysis and VectorBuilder layers

4. **`traverse_ast()`**: Recursively traverses tree-sitter AST:
   - Identifies code element nodes (class, function, method, etc.)
   - Extracts line numbers from node positions
   - Calls `extract_element_metadata()` for each element
   - Adds `VectorMetadata` objects to `elements` array

5. **`extract_element_metadata()`**: Creates `VectorMetadata` object:
   - Extracts element type, name, line numbers
   - Extracts documentation block line numbers using tree-sitter API (if available)
   - Sets `file_id` from `this.file.id`
   - Sets `codedoc_start` and `codedoc_end` properties (line numbers only, not stored in DB)
   - Returns `VectorMetadata` object to be added to `elements` array

6. **`extract_documentation_lines()`**: Finds documentation comment line numbers using tree-sitter:
   - Uses tree-sitter API to locate doc comment nodes before element
   - Returns start and end line numbers for documentation block
   - Used to populate `codedoc_start` and `codedoc_end` properties in `VectorMetadata`

**VectorMetadata Extensions**:

The `VectorMetadata` class is extended with:
- `codedoc_start` property (int, not stored in DB): Starting line number of documentation block
- `codedoc_end` property (int, not stored in DB): Ending line number of documentation block
  - Both populated by Tree layer using tree-sitter API to locate doc comment nodes
  - Used by Analysis layer to extract documentation text for LLM context
- `signature` property (string, not stored in DB): Full element signature (e.g., "public async void parse() throws GLib.Error")
  - Populated by Tree layer from tree-sitter AST
  - Used by VectorBuilder layer in vectorization documents
- `namespace` property (string, not stored in DB): Namespace containing the element (e.g., "OLLMvector.Indexing")
  - Populated by Tree layer during AST traversal
  - Used by VectorBuilder layer in vectorization documents
- `parent_class` property (string, not stored in DB): Parent class/struct/interface for methods, properties, fields
  - Populated by Tree layer during AST traversal
  - Used by VectorBuilder layer in vectorization documents
- `description` property (string, not stored in DB): Contains LLM-generated one-line text description
  - Populated by Analysis layer (one-line text, only for complex elements)
  - Empty string for simple elements that skip LLM analysis
  - Used by VectorBuilder layer to create vectorization documents

**Language Support**:

Tree layer will support multiple languages via tree-sitter:
- Vala (if tree-sitter grammar available)
- Python, JavaScript, Java, C++, Rust, etc.
- Language detection based on `OLLMfiles.File.language` property
- Fallback to generic parsing if language-specific parser unavailable

#### Layer 2: Analysis
- **Purpose**: Generate one-line text descriptions for code elements using LLM (structure is already extracted by Tree layer)
- **Input**: 
  - `Tree` object from Tree layer (contains `elements` array with VectorMetadata objects that already have structure: type, name, signature, namespace, parent_class, etc.)
- **Output**: `Tree` object with `elements` array updated (each `VectorMetadata.description` populated)
- **Responsibilities**:
  - Receive `Tree` object from Tree layer (structure already extracted by tree-sitter)
  - Iterate over `Tree.elements` array
  - For each `VectorMetadata` object:
    - Skip LLM for simple elements (enum types without docs, simple properties, enum values, fields without docs)
    - For complex elements: Extract code snippet using `Tree.lines_to_string(start_line, end_line)`
    - Extract documentation using `Tree.lines_to_string(codedoc_start, codedoc_end)` (if available)
    - Send code snippet + documentation to LLM
  - LLM generates one-line text description of what the code does
  - Store description in `VectorMetadata.description` property (not stored in DB)
  - Handle batch processing for efficiency
  - Track file metadata via `Tree.file`

##### Analysis Implementation Details

The Analysis layer receives `VectorMetadata[]` from the Tree layer (with all structure already extracted by tree-sitter) and generates simple text descriptions using LLM. The Tree layer provides all structural information (element type, name, signature, namespace, parent class, line numbers, documentation ranges), so the LLM only needs to generate a one-line description.

**LLM API Call**:
- **Endpoint**: `/api/chat`
- **Model**: Code-aware model (e.g., `codellama`, `deepseek-coder`, `qwen2.5-coder`)
- **Messages**: 
  - Load prompt template from resources (e.g., `resources/ocvector/analysis-prompt.txt`)
  - Template uses `---` separator: content before `---` is system message, content after is user message template
  - System message: Instructions for generating one-line code summaries
  - User message: Code snippet + documentation (extracted using `codedoc_start`/`codedoc_end` line numbers) wrapped in `<code>` tags
- **Options**: Set `temperature: 0` for more deterministic outputs
- **Response Format**: One-line text description (not JSON)

**Analysis Process**:
1. Receive `Tree` object from Tree layer
2. Load prompt template from resources (split on `---` for system/user messages)
3. Iterate over `Tree.elements` array:
   - For each `VectorMetadata` object:
     - Extract code snippet using `Tree.lines_to_string(start_line, end_line)`
     - Extract documentation text using `Tree.lines_to_string(codedoc_start, codedoc_end)` (if available)
     - Send to LLM with prompt template (code + documentation)
     - Store LLM response as one-line description in `VectorMetadata.description` property (not stored in DB)
4. Return updated `Tree` object with `elements` array populated with descriptions

**Error Handling**:
- If LLM call fails, set description to empty string and continue
- Log analysis errors for debugging but continue processing other elements
- Batch processing: Process multiple elements in parallel for efficiency

#### Layer 3: Vector Building
- **Purpose**: Convert `VectorMetadata` objects (from Analysis layer) into vectors and store in FAISS
- **Input**: `Tree` object from Analysis layer (with `elements` array containing VectorMetadata with descriptions populated)
- **Output**: Vectors stored in FAISS index
- **Responsibilities**:
  - Receive `Tree` object from Analysis layer
  - Iterate over `Tree.elements` array
  - For each `VectorMetadata`, extract code snippets using `Tree.lines_to_string(start_line, end_line)`
  - Format documents for vectorization (using descriptions from VectorMetadata)
  - Generate embeddings using LLM embedding API
  - Store vectors in FAISS index
  - Maintain mapping between vectors and source files/elements
  - Handle batch processing for efficiency
  - Support incremental updates (add/update/remove vectors)

##### Vectorization Process Details

The vectorization process converts code elements (with structure from Tree layer and descriptions from Analysis layer) into searchable text documents that are sent to Ollama's vectorize API. Each code element (class, function, method, struct, interface, etc.) becomes a separate document for vectorization.

**Document Format for Vectorization**:

For each code element (structure extracted by Tree layer, description from Analysis layer), a searchable text document is created with the following structure:

```
{property-type}: {name}
Access: {access-modifier}
File: {file_path}
Lines: {start_line}-{end_line}
Signature: {signature}
Description: {detailed_description}
Parameters: {name: argument-type, name: argument-type, ...}
Returns: {return_type}
Properties: {name: value-type [get/set], name: value-type [get/set], ...}
Dependencies: {relationship-type}: {target}, {relationship-type}: {target}, ...
Code:
{code_snippet}
```

**File-Level Context** (included in document metadata, not in vectorized text):
- Imports: {module} (line {line}), {module} (line {line}), ...

**Specific Fields Sent to Ollama Vectorize API**:

1. **Element Type and Name** (`{property-type}: {name}`)
   - Examples: `class: DatabaseManager`, `function: parse_json`, `method: initialize_connection`, `property: user_name`, `field: connection_pool`
   - Property types include: class, function, method, property, field, struct, interface, enum, namespace, constructor, delegate, signal, constant
   - Provides semantic context about what kind of code element this is

2. **Access Modifier** (`Access: {access-modifier}`)
   - Visibility level: public, private, protected, internal, package, default
   - Helps filter searches by accessibility (e.g., "public API methods")

3. **File Location** (`File: {file_path}`)
   - Full path to the source file
   - Enables location-based filtering and result display

4. **Line Range** (`Lines: {start_line}-{end_line}`)
   - Exact line numbers where the element is defined (1-indexed)
   - Critical for precise code navigation

5. **Signature** (`Signature: {signature}`)
   - Full declaration signature of the element
   - Includes modifiers, return type, parameter types, etc.
   - Enables exact signature matching and API discovery

6. **Description** (`Description: {detailed_description}`)
   - Natural language description of the element's purpose and functionality
   - Generated by LLM analysis, includes semantic understanding of what the code does
   - This is the primary semantic content for search matching

7. **Parameters** (`Parameters: {name: argument-type}, ...`)
   - List of function/method parameters with their types
   - Format: `name: type` pairs (e.g., `email: string, timeout: int`)
   - Only included for functions, methods, constructors, delegates
   - Helps match queries about specific APIs or signatures

8. **Return Type** (`Returns: {return_type}`)
   - Return type information (or "void"/"None" for no return)
   - Only included for functions, methods, properties with getters
   - Aids in finding code that returns specific types

9. **Properties** (`Properties: {name: value-type [accessors]}, ...`)
   - Properties and fields for classes/structs
   - Format: `name: type [get/set/init]` (e.g., `user_name: string [get, set]`)
   - Only included for classes, structs, interfaces
   - Helps find classes with specific properties or fields

10. **Dependencies** (`Dependencies: {relationship-type}: {target}, ...`)
    - Relationships to other code elements with relationship types
    - Relationship types: inherits, implements, uses, calls, references, imports
    - Format: `relationship-type: target` (e.g., `inherits: BaseClass`, `calls: Database.connect`)
    - Enables relationship-based searches (e.g., "classes that implement InterfaceX")

11. **Code Snippet** (`Code:\n{code_snippet}`)
    - The actual source code for the element, but with smart truncation for nested structures
    - **For classes/structs/interfaces**: Include only the class declaration and property/field declarations (first ~30-50 lines or until first method). Do NOT include method bodies since methods are extracted as separate elements.
    - **For methods/functions/constructors**: Include the full method/function implementation (all lines from start_line to end_line).
    - **For properties/fields**: Include only the property/field declaration (typically 1-5 lines).
    - **For enums**: Include all enum values and any enum-specific methods.
    - **For namespaces**: Include only the namespace declaration and any top-level declarations (not nested class bodies).
    - **Maximum snippet size**: Limit to ~100 lines to prevent extremely large snippets that don't add semantic value.
    - Provides concrete implementation details for context
    - Helps match queries that reference specific code patterns or implementations
    - **Note**: Since nested elements (methods, properties) are extracted as separate elements, the parent class snippet should focus on structure rather than duplicating nested content.

**File-Level Context** (stored in metadata, not vectorized):
- **Imports**: List of imported modules with line numbers
  - Format: `module (line number)`
  - Helps understand file dependencies and module relationships

**Example Document for Vectorization**:

```
class: DatabaseManager
Access: public
File: /path/to/project/src/database.vala
Lines: 45-120
Signature: public class DatabaseManager : Object
Description: Manages database connections and provides methods for executing queries. Handles connection pooling, transaction management, and error recovery. Automatically retries failed connections and maintains connection health status.
Properties: connection_pool: Gee.ArrayList<Connection> [get], max_connections: int [get, set], timeout: int [get, set]
Dependencies: inherits: Object, uses: libocsqlite.Database, uses: OLLMfiles.File
Code:
public class DatabaseManager : Object {
  private Gee.ArrayList<Connection> connection_pool;
  private int max_connections = 10;
  private int timeout = 30;
  
  public int max_connections {
    get { return this.max_connections; }
    set { this.max_connections = value; }
  }
  
  // ... (methods are extracted as separate elements, not included here)
}
```

**Note**: The class snippet is truncated to show only the class structure (declaration and properties). Individual methods like `execute_query()`, `acquire_connection()`, etc. are extracted as separate elements with their own full code snippets.

**Code Snippet Extraction Strategy**:

The Vector Building layer should implement smart snippet extraction based on element type:

1. **For classes/structs/interfaces** (`property-type: "class"`, `"struct"`, `"interface"`):
   - Extract only the class declaration and property/field declarations
   - Stop at the first method definition (methods are separate elements)
   - Maximum ~50 lines to show structure without duplicating nested content
   - Example: Show `public class X { ... properties ... }` but not method bodies

2. **For methods/functions/constructors** (`property-type: "method"`, `"function"`, `"constructor"`):
   - Extract the full implementation (all lines from start_line to end_line)
   - These are typically self-contained and not nested within other elements
   - No truncation needed unless exceeding ~200 lines (very rare)

3. **For properties/fields** (`property-type: "property"`, `"field"`):
   - Extract only the property/field declaration (typically 1-10 lines)
   - Include getter/setter if present in the same declaration block
   - Example: `public string name { get; set; default = ""; }`

4. **For enums** (`property-type: "enum"`):
   - Extract all enum values and any enum-specific methods
   - Usually compact enough to include fully

5. **For namespaces** (`property-type: "namespace"`):
   - Extract only the namespace declaration and any top-level using/import statements
   - Do not include nested class/method bodies (extracted separately)

6. **General truncation rule**:
   - If any snippet exceeds ~100 lines, truncate with `// ... (truncated)` comment
   - This prevents extremely large snippets that don't add semantic value to vector search
   - The full code is always available via file path and line numbers

**Implementation Note**: The Vector Building layer uses `Tree.lines_to_string(start_line, end_line)` to extract code snippets. Truncation logic should be applied when formatting documents for vectorization based on element type (classes vs methods, etc.).

**Example for a Method**:

```
method: execute_query
Access: public
File: /path/to/project/src/database.vala
Lines: 85-105
Signature: public async string? execute_query(string sql, GLib.Cancellable? cancellable = null) throws GLib.Error
Description: Executes a SQL query asynchronously and returns the result. Handles connection acquisition, query execution, and error handling. Returns null on error.
Parameters: sql: string, cancellable: GLib.Cancellable?
Returns: string?
Dependencies: calls: Connection.acquire, calls: Connection.execute, references: GLib.Error
Code:
public async string? execute_query(string sql, GLib.Cancellable? cancellable = null) throws GLib.Error {
  var conn = yield this.acquire_connection(cancellable);
  return yield conn.execute(sql);
}
```
    private string connection_string;
    private int pool_size;
    private int timeout;
    
    public DatabaseManager(string connection_string, int pool_size = 10, int timeout = 30) {
        this.connection_string = connection_string;
        this.pool_size = pool_size;
        this.timeout = timeout;
    }
    
    public async bool initialize() throws Error {
        // Connection initialization logic
    }
}
```

**Vectorization API Call**:

Each document (as formatted above) is sent to Ollama's `/api/embeddings` endpoint (or equivalent vectorize API) with:

- **Model**: The embedding model to use (e.g., `nomic-embed-text`, `all-minilm`, or model-specific embedding endpoint)
- **Input**: The complete formatted document string
- **Response**: Vector embedding (array of floats)

**Batch Processing**:

- Multiple documents can be vectorized in a single batch request if the API supports it
- Documents are grouped by file to maintain locality
- Batch size is configurable (default: 10-20 documents per batch)

**Document Metadata Storage**:

Alongside each vector, the following metadata is stored in the database (NOT in FAISS, which only stores vectors):
- Original file path
- Element type and name
- Line range (start_line, end_line)
- Vector ID in FAISS index
- Timestamp of vectorization

**Important**: Original document text is NOT stored. Code snippets are read from the filesystem when needed for result display. This approach:
- Avoids duplication (files already exist in filesystem or are referenced in SQL database)
- Reduces storage requirements
- Ensures results always show current file content
- Enables precise result location (file + line numbers)
- Supports incremental updates (re-vectorizing only changed elements)

### Component 2: Search

The search component provides semantic search capabilities:

- **Purpose**: Perform semantic search on indexed codebase
- **Features**:
  - Use local GPU for search operations when available
  - Fallback to CPU if GPU unavailable
  - Return ranked results with FAISS similarity scores (no additional ranking)
  - Support filtering by folder (project), language, element type
- **Responsibilities**:
  - Convert search queries to embedding vectors
  - Apply filters to reduce vector set before search (via SQL metadata queries)
  - Perform similarity search in FAISS index (on filtered vector set)
  - Return formatted results with context

### File Tracking System

The vector indexing system uses `libocfiles` (OLLMfiles namespace) for file tracking:

- **Track Indexed Files**: Store vector metadata linked to `OLLMfiles.File` objects
- **Detect Changes**: Use file modification times (`mtime`) from `OLLMfiles.File` to detect when files need re-indexing
- **Incremental Updates**: Update vectors when code or documentation changes
- **File Management**: Use `OLLMfiles.ProjectManager` and `OLLMfiles.Folder` for project-wide file discovery and hierarchy

**Note**: `libocvector` depends on `libocfiles` which provides file management without GTK/git dependencies. The `OLLMfiles` namespace provides all necessary file tracking capabilities.

Metadata storage (integrated with `OLLMfiles.File`):
- File path and ID (via `OLLMfiles.File`)
- File modification time (`mtime`) for change detection
- Last indexed timestamp
- Vector position in FAISS index
- Indexing status (indexed, needs update, error, etc.)

### Command-Line Tools

Command-line tools will be created in the `examples/` directory for testing:

#### Indexing Example (`examples/oc-vector-index.vala`)
- **Purpose**: Test single file indexing from command line
- **Features**:
  - Index a single file for testing
  - Show indexing progress
  - Simple interface for development/testing

#### Search Tool (`oc-vector-search`)
- **Namespace**: `OLLMvector.Tools.Search`
- **Purpose**: Search indexed codebases from command line
- **Features**:
  - Execute semantic search queries
  - Display results ranked by FAISS similarity score
  - Filter by folder (project), language, element type
  - Export results in various formats

### OLLM Library Tool Integration

A tool class will be created for use with the `libollmchat` tool system:

- **Class**: `OLLMcoder.Tool.CodebaseSearchTool` (extends `OLLMchat.Tool.Interface`)
- **Location**: `liboccoder/Tool/CodebaseSearchTool.vala` (NOT in `libocvector`)
- **Purpose**: Provide semantic codebase search as a tool for LLM agents
- **Integration**: 
  - Implements `OLLMchat.Tool.Interface`
  - Uses `libocvector` library for search operations
  - Uses `OLLMfiles.ProjectManager` to access active project
  - Provides `execute()` method for tool calling
  - Returns search results in structured format with code citations
  - Supports permission system integration

## Migration Plan: VectorSearch â†’ libocvector

### Phase 1: Create libocvector Structure
1. Create `libocvector/` directory
2. Set up `meson.build` for the library
3. Create namespace structure (`OLLMvector.Indexing`, `OLLMvector.Search`, `OLLMvector.Tools.Search`, `OLLMvector.Tool`)

### Phase 2: Migrate FAISS Components
1. **Migrate FAISS Integration**:
   - Move `VectorSearch/Index.vala` â†’ `libocvector/Index.vala`
   - Keep namespace as `Faiss` (or appropriate FAISS namespace)
   - Keep FAISS functionality intact

2. **Migrate Database**:
   - Move `VectorSearch/Database.vala` â†’ `libocvector/Database.vala`
   - Update namespace to `OLLMvector`
   - Integrate with `OLLMfiles.File` for metadata tracking

### Phase 3: Refactor Analysis Layer
1. **Create Tree Component**:
   - Create `libocvector/Indexing/Tree.vala`
   - Implement tree-sitter parser integration
   - Implement AST traversal to extract code elements
   - Create `VectorMetadata` objects with code snippets and documentation
   - Add `codedoc_start` and `codedoc_end` properties to `VectorMetadata` class (line numbers only)

2. **Refactor Analysis Component**:
   - Refactor `libocvector/Indexing/Analysis.vala` constructor to receive `Tree` object
   - Analysis iterates over `Tree.elements` and updates VectorMetadata descriptions
   - Update prompt template loading to use `---` separator (system message before `---`, user message template after)
   - Use `Tree.lines_to_string()` to extract code snippets and documentation
   - Implement simple LLM summarization (code + doc â†’ one-line text description)
   - Store descriptions in `VectorMetadata.description` property (not stored in DB)

3. **Create Vector Builder**:
   - Extract vector generation from `VectorSearch/Database.vala`
   - Create `libocvector/Indexing/VectorBuilder.vala` with constructor receiving `Tree` object
   - Use `Tree.elements` for VectorMetadata array
   - Use `Tree.lines_to_string()` for code snippet extraction
   - Separate embedding generation from storage
   - Add batch processing support

4. **Create Indexer**:
   - Refactor `VectorSearch/CodeIndexer.vala` â†’ `libocvector/Indexing/Indexer.vala`
   - Combine Tree, Analysis, and VectorBuilder layers:
     - Create `Tree(file)`, call `Tree.parse()` to populate `Tree.elements`
     - Pass `Tree` to `Analysis`, which updates `Tree.elements` with descriptions
     - Pass `Tree` to `VectorBuilder`, which uses `Tree.elements` and `Tree.lines_to_string()`
   - Add integration with `OLLMfiles` for file tracking
   - Implement incremental update logic

### Phase 4: Refactor Search Layer
1. **Create SearchBuilder**:
   - Create `libocvector/Search/SearchBuilder.vala`
   - Builder pattern for configuring search with filters, query, max results, etc.

2. **Create Search**:
   - Refactor `VectorSearch/CodeSearch.vala` â†’ `libocvector/Search/Search.vala`
   - Manages search flow: query vectorization, filtering, FAISS search, metadata lookup
   - Add GPU support detection and usage (when available)

3. **Create SearchResult**:
   - Create `libocvector/Search/SearchResult.vala`
   - Search result object with formatting methods (to_string(), to_json())
### Phase 5: File Tracking Integration
1. **Integrate with libocfiles**:
   - Add `libocfiles` dependency to `libocvector/meson.build`
   - Use `OLLMfiles.File`, `OLLMfiles.Folder`, and `OLLMfiles.ProjectManager` for file tracking
   - Add vector indexing metadata fields (or create extension/wrapper if needed)
   - Store vector position and indexing status in database (link to file IDs)
   - Use `OLLMfiles.File.mtime` for change detection

### Phase 6: Create Command-Line Tools
1. **Create Indexing Example**:
   - Create `examples/oc-vector-index.vala`
   - Simple command-line tool for testing single file indexing
   - Focus on development/testing use cases

2. **Create Search Tool**:
   - Create `libocvector/Tools/SearchTool.vala`
   - Implement command-line interface
   - Add to `examples/` directory as `oc-vector-search.vala`
   - Create `oc-vector-search` executable

### Phase 7: Create OLLM Tool Integration
1. **Create CodebaseSearchTool**:
   - Create `liboccoder/Tool/CodebaseSearchTool.vala` (NOT in `libocvector`)
   - Create `liboccoder/Tool/RequestCodebaseSearch.vala`
   - Extend `OLLMchat.Tool.Interface`
   - Use `OLLMfiles.ProjectManager` to access active project
   - Use `libocvector.Search.Search` for search operations
   - Implement tool interface methods
   - Add to `libollmchat` tool registry
   - See Phase 9 for detailed implementation plan

### Phase 8: Update Dependencies and Build
1. Update `meson.build`:
   - Add `libocvector` subdirectory
   - Add dependencies (libocsqlite, libollmchat, libocfiles, FAISS)
   - Note: `libocfiles` is used as a dependency for file tracking
   - Create library, VAPI, and GIR files

2. Update library dependencies:
   - Add `libocvector` to libraries that need it
   - Update VAPI dependencies (include ocfiles VAPI)

### Phase 9: Testing and Cleanup
1. Test indexing with various codebases
2. Test search functionality
3. Test command-line tools
4. Test OLLM tool integration
5. Remove or deprecate `VectorSearch/` directory
6. Update documentation

## Existing Infrastructure

The project already has a `VectorSearch/` directory with:
- **FAISS Integration** (`Index.vala`, `Database.vala`) - Vector search using FAISS
- **Code Analysis** (`CodeImport.vala`, `CodeIndexer.vala`) - Code file analysis
- **Code Search** (`CodeSearch.vala`) - Search functionality
- **Tree Layer** (`Tree.vala`) - Extracts code structure using tree-sitter (replaces old CodeElement/CodeFile flow)

This code will be migrated and refactored into the new `libocvector` structure.

## Dependencies

- **FAISS library** (already integrated via `vapi/fiass.vapi`)
- **libocsqlite** - For metadata storage
- **libollmchat** - For LLM client access and tool integration
- **libocfiles** - For file tracking and project management (provides `OLLMfiles` namespace)
- **libocagent** - For agent integration (if needed)

**Note**: `libocvector` depends on `libocfiles` for file tracking. The `libocfiles` library provides file management without GTK/git dependencies, using the `OLLMfiles` namespace.

## Files to Create

### Library Files
- `libocvector/meson.build`
- `libocvector/Index.vala` (FAISS namespace)
- `libocvector/Database.vala`
- `libocvector/Indexing/Tree.vala`
- `libocvector/Indexing/Analysis.vala`
- `libocvector/Indexing/VectorBuilder.vala`
- `libocvector/Indexing/Indexer.vala`
- `libocvector/Search/SearchBuilder.vala` (OPTIONAL)
- `libocvector/Search/Search.vala`
- `libocvector/Search/SearchResult.vala`

**Tool Integration** (in `liboccoder`, not `libocvector`):
- `liboccoder/Tool/CodebaseSearchTool.vala`
- `liboccoder/Tool/RequestCodebaseSearch.vala`

**Note**: File tracking is provided by `libocfiles` dependency (OLLMfiles namespace), so no Files/ directory is needed in `libocvector`.

**Note**: File tracking is provided by `libocfiles` dependency (OLLMfiles namespace), so no Files/ directory is needed in `libocvector`.

### Example/Test Tools
- `examples/oc-vector-index.vala` (simple single-file indexing for testing)
- `examples/oc-vector-search.vala` (uses `libocvector/Tools/SearchTool.vala`)

## Features

- Semantic code search using FAISS vectors
- Support for both code and documentation indexing
- GPU-accelerated search (with CPU fallback)
- Incremental indexing with change detection
- File tracking via `libocfiles` dependency (OLLMfiles namespace)
- Command-line tools for testing and manual operations
- OLLM library tool integration for LLM agents
- Permission system integration

## Testing

- Test indexing with various codebases and languages
- Test search functionality with different query types
- Test file change detection and re-indexing
- Test command-line tools
- Test OLLM tool integration
- Test GPU vs CPU search performance
- Test incremental updates
- Add to meson.build

## TODO: FAISS Packaging Investigation

- [ ] Investigate FAISS packaging in Debian/Ubuntu repositories
- [ ] Determine if we can modify the Debian build to include GPU support
- [ ] Research building FAISS from source with GPU support
- [ ] Evaluate alternative packaging approaches (e.g., custom PPA, static builds)
- [ ] Document findings and recommendations for GPU support implementation
