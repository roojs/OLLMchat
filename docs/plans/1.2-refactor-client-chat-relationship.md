# 1.2. Refactor Client and Chat Relationship

## Overview

Refactor the Client and Chat relationship to make Chat Options a real object rather than a realized one, and ensure that creating new chats copies options from the Client. Use Client values as defaults when creating Chat.

## Status

⏳ **TODO** - Refactoring needed.

## Ideal Interface Design

### Architecture Overview

The ideal architecture separates concerns into three main layers:

1. **Connection** - Stores server connection configuration
2. **Client** - Thin HTTP communication layer with signals
3. **Chat** - Request-specific configuration and execution

### Object Responsibilities

#### Connection (`Settings.Connection`)
**Purpose**: Stores connection configuration and can create clients.

**Responsibilities**:
- Store connection details (URL, API key, name, is_default)
- Create HTTP messages with proper headers (`soup_message()`)
- Manage HTTP session (Soup.Session) - shared across all Clients using this Connection
- Manage HTTP timeout (non-serialized runtime property)
- Manage `available_models` cache (populated when models are fetched via Client)
- Connection is immutable configuration - shared across clients (except non-serialized runtime properties)

**Properties**:
- `name` (string) - Connection alias
- `url` (string) - Server URL
- `api_key` (string) - API key for authentication
- `is_default` (bool) - Whether this is the default connection
- `hidden_models` (ArrayList<string>) - Models to hide from UI
- `timeout` (uint) - HTTP request timeout in seconds (default: 300)
  - **Note**: Non-serialized property (runtime state, not saved to config)
  - **Note**: Used by Call.Base to set `session.timeout` when making requests
- `session` (Soup.Session?) - HTTP session (created lazily by Call.Base when needed)
  - **Note**: Shared across all Clients using this Connection (connection pooling)
  - **Note**: Non-serialized property (runtime state, not saved to config)
- `available_models` (HashMap<string, Response.Model>) - Cached model info for this connection
  - **Note**: Connection-specific (models available on that server)
  - **Note**: Non-serialized property (runtime cache, not saved to config)
  - **Note**: Connection manages its own cache - Client updates it when fetching models

**Methods**:
- `clone()` - Create a copy
- `soup_message(method, url, body?)` - Create HTTP message with auth headers
- `create_client()` - Factory method to create a Client instance (optional convenience)
- `fetch_all_model_details()` - Fetch all model details and populate `available_models` cache
  - **Note**: Creates temporary Client internally to make HTTP requests
  - Populates Connection's own `available_models` cache

#### Client (`OLLMchat.Client`)
**Purpose**: Thin wrapper around Connection for HTTP communication. Should NOT hold options or settings that are not directly related to connecting to the server.

**Responsibilities** (What Client DOES):
- Convenience wrapper providing simple API methods (ps, models, version, show_model, chat, embed, generate)
- Creates Call objects and delegates HTTP execution to Call.Base
- **Note**: Call.Base takes Connection directly (not Client) - Client is just a convenience wrapper

**Properties** (What Client KEEPS):
- `connection` (Settings.Connection) - Connection configuration
  - **Used by Client**: Passed to Call constructors (Call.Base takes Connection directly)

**Properties** (What Client REMOVES - where they go):
- ❌ `model` → **Moves to Chat/Embed/Generate** (request-specific)
- ❌ `stream` → **Moves to Chat** (request-specific)
- ❌ `format` → **Moves to Chat** (request-specific)
- ❌ `think` → **Moves to Chat** (request-specific)
- ❌ `keep_alive` → **Moves to Chat** (request-specific)
- ❌ `options` (Call.Options) → **Moves to Chat/Embed/Generate** (request-specific)
- ❌ `tools` (HashMap<string, Tool.BaseTool>) → **Moves to Chat** (conversation-specific, caller manages)
- ❌ `permission_provider` (ChatPermission.Provider) → **Moves to Session** (UI/session-specific)
- ❌ `config` (Settings.Config2?) → **Remove or pass model_options to Call constructors** (only model_options used)
- ❌ `streaming_response` (Response.Chat?) → **Moves to Chat** (session-specific state)
- ❌ `session` (Soup.Session?) → **Moves to Connection** (connection-specific, shared across Clients)
- ❌ `timeout` (uint) → **Moves to Connection** (connection-specific, non-serialized)
- ❌ `available_models` (HashMap<string, Response.Model>) → **Moves to Connection** (connection-specific, non-serialized)
- ❌ `fetch_all_model_details()` → **Moves to Connection** (Connection manages its own cache)

**Signals** (What Client REMOVES - all signals move to Chat):
- ❌ `stream_chunk(string, bool, Response.Chat)` → **Moves to Chat** - Chat orchestrates conversation, emits signals
- ❌ `stream_start()` → **Moves to Chat** - Chat emits when streaming starts
- ❌ `tool_message(Message)` → **Moves to Chat** - Chat emits tool status messages
- ❌ `chat_send(Call.Chat)` → **Remove** - caller knows when they call `send()`
- ❌ `message_created(Message, ChatContentInterface?)` → **Remove** - caller creates messages, they know when
- ❌ `stream_content(string, Response.Chat)` → **Remove** - redundant, use `stream_chunk` with `is_thinking` check

**Methods** (What Client KEEPS):
- `ps()` - List running models
- `models()` - List available models
- `version()` - Get server version
- `show_model(string)` - Get model details

**Methods** (Simple convenience methods - create Call objects internally):
- `chat(string, Cancellable?)` - Simple chat (creates `Call.Chat` internally with defaults)
- `embed(string model, string input, ...)` - Simple embeddings (creates `Call.Embed` internally)
  - **Note**: Currently exists, needs update to take `model` parameter (currently uses `this.model`)
- `embed_array(string model, ArrayList<string> input_array, ...)` - Simple embeddings for array (creates `Call.Embed` internally)
  - **Note**: Currently exists, needs update to take `model` parameter (currently uses `this.model`)
- `generate(string model, string prompt, string system = "", ...)` - Simple generation (creates `Call.Generate` internally)
  - **Note**: Currently exists, needs update to take `model` parameter (currently uses `this.model`)

**Methods** (What Client REMOVES):
- ❌ `add_tool(Tool.BaseTool)` → **Remove** - tools managed by caller on Chat

**What Client Should NOT Have**:
- ❌ `model` - Request-specific, belongs in Chat/Embed/Generate
- ❌ `stream` - Request-specific, belongs in Chat
- ❌ `format` - Request-specific, belongs in Chat
- ❌ `think` - Request-specific, belongs in Chat
- ❌ `keep_alive` - Request-specific, belongs in Chat
- ❌ `options` (Call.Options) - Request-specific, belongs in Chat/Embed/Generate
- ❌ `tools` (HashMap<string, Tool.BaseTool>) - Conversation-specific, belongs in Chat/Session
- ❌ `permission_provider` (ChatPermission.Provider) - Session/UI-specific, belongs in Session

#### Chat (`OLLMchat.Call.Chat`)
**Purpose**: Request-specific configuration and execution. Holds all settings for a specific chat request.

**Responsibilities**:
- Store request configuration (model, options, stream, format, think, keep_alive)
- Send chat requests (uses pre-prepared messages array from agent)
- Manage conversation history (messages array)
- Handle tool execution and recursion
- Call agent methods directly during execution (if agent reference is set)
- Emit signals for loosely coupled components (UI/Manager)

**Properties** (Request configuration):
- `model` (string) - Model name (required)
- `options` (Call.Options) - Runtime options (temperature, top_p, etc.)
- `stream` (bool) - Whether to stream responses
- `format` (string?) - Response format
- `format_obj` (Json.Object?) - JSON schema for structured output
- `think` (bool) - Whether to return thinking output
- `keep_alive` (string?) - Model keep-alive duration

**Properties** (Conversation):
- `messages` (ArrayList<Message>) - Conversation history
  - **Note**: Agent/handler prepares messages array directly - no need for intermediate `system_content` or `chat_content` properties

**Properties** (References):
- `connection` (Settings.Connection) - Connection for HTTP communication
  - **Note**: Call.Base takes Connection directly (not Client) - Client is just a convenience wrapper
- `agent` (BaseAgent?) - Optional reference to agent for direct method calls
  - **Note**: Chat calls agent methods directly (not via signals) - signals are for UI/Manager/loosely coupled components

**Properties** (Conversation-specific):
- `tools` (HashMap<string, Tool.BaseTool>) - Registered tools for this chat/conversation
  - **Note**: Tools are conversation-specific, not connection-specific
  - **Caller manages tools**: The caller (AgentHandler, Session, etc.) adds tools to Chat directly
  - Tools are NOT on Client - Client is just for HTTP communication
  - Each Chat can have different tools

**Properties** (State):
- `fid` (string) - Session ID
- `streaming_response` (Response.Chat?) - Current streaming state
- `cancellable` (Cancellable?) - Cancellation token

**Signals** (Asynchronous events - Chat does NOT emit signals):
- **Note**: Chat calls handler/agent methods directly (not signals)
- **Note**: For agent usage, Manager emits signals (UI connects to manager)
- **Note**: For non-agent usage, Client emits signals (UI connects to client)

**Methods**:
- `add_tool(Tool.BaseTool)` - Add a tool to this chat (caller manages tools)
- `send()` - Send chat request (uses client for HTTP, emits signals)
- `reply(string, Response.Chat)` - Continue conversation
- `tool_reply(Response.Chat)` - Execute tools and continue (uses `this.tools`, not `client.tools`)

### Usage Patterns

#### Pattern 1: Simple Operations (Trivial)
For simple operations that don't need per-request configuration:

```vala
var connection = new Settings.Connection() {
    url = "http://127.0.0.1:11434/api",
    timeout = 300  // Optional: set timeout (non-serialized, runtime property)
};

var client = new Client(connection);

// Simple operations - no Chat needed
var models = yield client.models();
var version = yield client.version();
var running = yield client.ps();

// Simple convenience methods (create Call objects internally)
var response = yield client.chat("Hello!");
var embeddings = yield client.embed("llama3.2", "text to embed");
var generated = yield client.generate("llama3.2", "prompt text");
```

#### Pattern 2: Main Usage (Chat with Configuration)
For chat requests with specific configuration:

```vala
var connection = new Settings.Connection() {
    url = "http://127.0.0.1:11434/api",
    timeout = 300  // Non-serialized, can be set at runtime
};

// Create Chat with request-specific configuration
// Note: Call.Chat takes Connection directly (not Client)
var options = new Call.Options() {
    temperature = 0.7,
    top_p = 0.9
};

var chat = new Call.Chat(connection, "llama3.2", options) {
    stream = true,
    think = false,
    keep_alive = "5m"
};

// Caller adds tools to Chat (not Client)
chat.add_tool(new Tools.ReadFile());
chat.add_tool(new Tools.RunCommand());

// Prepare messages (agent/handler does this)
chat.messages.add(new Message(chat, "user", "Hello!"));

// Send
var response = yield chat.send();
```

#### Pattern 3: With Connection Factory
Connection could provide a factory method:

```vala
var connection = new Settings.Connection() {
    url = "http://127.0.0.1:11434/api"
};

// Connection creates client (for convenience methods)
var client = connection.create_client();

// Or use Connection directly with Call
var chat = new Call.Chat(connection) {
    model = "llama3.2",
    stream = true
};
```

### Signal Flow

#### Design Principle: Signals Only for Asynchronous Events

Signals should only be used for truly asynchronous events that the caller cannot know about synchronously. The caller is responsible for updating state directly.

**What Gets Signals** (Asynchronous only):
- Streaming chunks arriving from HTTP (can't know synchronously)
- Tool status messages from background operations

**What Does NOT Get Signals** (Caller handles directly):
- Request sent - Caller knows when they call `send()`
- Message created - Caller creates messages, they know when
- Request started - Caller knows when they call the method

#### How Signals Connect

1. **Chat emits signals for asynchronous events**:
   - `stream_start()` - When streaming begins (first chunk received)
   - `stream_chunk(string, bool, Response.Chat)` - For each chunk received (content or thinking)
     - Tools can filter by checking the `bool is_thinking` parameter
   - `tool_message(Message)` - Tool status notifications
   - **Note**: Chat uses Connection (via Call.Base) for HTTP, but emits signals itself during execution

2. **Chat uses Connection for HTTP execution**:
   - Chat calls Call.Base methods which use Connection's session and URL
   - Chat does NOT connect to any signals (it emits them)
   - Chat orchestrates the conversation and emits signals as events occur
   - **Caller handles state updates**: When caller calls `chat.send()`, they can update UI/state directly

3. **Chat calls Agent/Handler methods directly** (no signals for agents):
   ```vala
   // Agent creates Handler (parent-child relationship)
   // Agent is persistent, Handler is ephemeral (created per request)
   public AgentHandler(BaseAgent agent, ChatRequest request, Session session) {
       this.agent = agent;  // Handler has reference to parent agent
       this.request = request;
       this.session = session;  // Handler has reference to parent session for callbacks
   }
   
   public async Response.Chat send(ChatRequest request) {
       // Handler creates Chat with agent reference
       var connection = get_connection_from_request(request);
       var chat = new Call.Chat(connection, request.model, options) {
           agent = this.agent  // Chat has reference to agent
       };
       
       // Chat calls agent/handler methods directly during execution
       // Example: chat.on_chunk(chunk) calls handler.on_chunk(chunk)
       // Example: chat.on_stream_start() calls handler.on_stream_start()
       // Handler then calls session.on_chunk(chunk) → session calls manager.on_chunk(chunk)
       // NO signals - direct method calls through parent chain
       
       // Send
       return yield chat.send();
   }
   ```

4. **UI connects to Manager signals** (Manager relays from agent infrastructure):
   ```vala
   // UI connects to Manager signals (Manager does NOT have reference to UI)
   // Manager relays from Handler → Session → Manager → UI
   // Handler calls session methods directly, session calls manager, manager emits signal
   
   manager.stream_chunk.connect((text, is_thinking, response) => {
       if (is_thinking) {
           // Handle thinking content separately if needed
       } else {
           // Update UI with regular content
       }
   });
   
   // Tools can filter for content-only:
   manager.stream_chunk.connect((text, is_thinking, response) => {
       if (!is_thinking) {
           // Process content chunks only
       }
   });
   
   // State updates handled directly by caller
   var response = yield handler.send(user_input);
   // Caller knows request was sent, can update UI directly
   ui.show_waiting_indicator();
   ```

5. **Caller handles state updates directly**:
   ```vala
   // UI should block send button before send() is called
   ui.disable_send_button();
   
   // Caller creates messages and knows when
   var user_msg = new Message(chat, "user", text);
   session.save_message(user_msg); // Direct call, no signal
   
   // Caller knows when request is sent
   // Note: send() begins execution after message is sent and returns after sending,
   // not waiting for response. Response comes via signals/callbacks.
   yield chat.send();
   // send() has returned - request has been sent, but response may still be streaming
   ui.show_waiting_indicator(); // Direct call, no signal
   ```

**Signal Chain** (Asynchronous events only):
```
For Agent usage (direct method calls):
HTTP Streaming Response 
  → Chat (calls handler methods directly)
    → Handler (calls session methods directly)
      → Session (calls manager methods directly)
        → Manager (emits signals for UI)
          → UI (connected to manager signals)

For non-agent usage (loosely coupled):
HTTP Streaming Response 
  → Client (emits signals for loosely coupled components)
    → UI (connected to client signals directly)
```

**Key Points**:
- **Chat calls handler/agent methods directly** - Agent infrastructure uses direct method calls (not signals)
- **Manager emits signals for UI** - Manager does NOT have reference to UI, UI connects to manager signals
- **Client emits signals for non-agent usage** - For loosely coupled components (direct client usage without agents)
- **Connection is passive** - Just configuration, no signals, used by Call.Base for HTTP
- **Client is just a convenience wrapper** - Can emit signals for non-agent usage, but agent infrastructure uses direct calls
- **Signals only for loosely coupled components** - Manager (for UI) and Client (for non-agent usage) use signals
- **Agent infrastructure uses direct method calls** - Handler → Session → Manager (no signals in this chain)
- Signals only for asynchronous events (streaming, tool notifications)
- Caller handles state updates directly (no signals for "I did X")

### Migration Path

The migration is broken down into detailed subplans:

- **[1.2.1. Remove Configuration from Client](./1.2.1-remove-config-from-client.md)** - Remove request-specific and conversation-specific properties from Client
- **[1.2.2. Remove Signals from Client](./1.2.2-remove-signals-from-client.md)** - Remove synchronous state update signals
- **[1.2.3. Update Call.Base to Take Connection](./1.2.3-update-call-base-connection.md)** - Make Call objects take Connection directly
- **[1.2.4. Update All Chat Creation](./1.2.4-update-all-chat-creation.md)** - Update all Chat creation points
- **[1.2.5. Update Callers to Handle State Directly](./1.2.5-update-callers-state.md)** - Remove signal dependencies for state updates
- **[1.2.6. Update Legacy Methods](./1.2.6-update-legacy-methods.md)** - Update Client convenience methods

Each subplan contains detailed implementation steps, files to modify, and testing checklists.

### Benefits of This Design

1. **Clear Separation**: Client = HTTP, Chat = Request config
2. **No Confusion**: Client doesn't hold request-specific settings
3. **Flexibility**: Each Chat can have different settings
4. **Simplicity**: Client is thin and focused
5. **Explicitness**: Chat creation requires explicit configuration
6. **Cleaner Signals**: Signals only for asynchronous events, caller handles state directly
7. **Less Coupling**: No signals for "I did X" - caller knows when they do things

## Client Overview

### Current Client Responsibilities

The `Client` class (`libollmchat/Client.vala`) is the main interface for interacting with Ollama API and OpenAI-compatible REST interfaces. It currently handles:

#### Configuration Properties
- **Connection Management**: `connection` (Settings.Connection), `config` (Settings.Config2)
- **Model Selection**: `model` (string) - model name to use for requests
- **Streaming Configuration**: 
  - `stream` (bool) - whether to stream responses
  - `format` (string?) - response format ("json" or JSON schema)
  - `think` (bool) - whether to return thinking output separately
  - `keep_alive` (string?) - model keep-alive duration
- **Runtime Options**: `options` (Call.Options) - runtime parameters (temperature, top_p, etc.)
- **Timeout**: `timeout` (uint) - HTTP request timeout in seconds

#### Tool Management
- **Tools HashMap**: `tools` (Gee.HashMap<string, Tool.BaseTool>) - available tools indexed by name
- **Tool Registration**: `add_tool(Tool.BaseTool)` - adds tool to the map and sets tool.client

#### Permission System
- **Permission Provider**: `permission_provider` (ChatPermission.Provider) - handles permission requests for tool execution

#### State Management
- **Streaming Response**: `streaming_response` (Response.Chat?) - current streaming state
- **Available Models**: `available_models` (Gee.HashMap<string, Response.Model>) - cached model information
- **HTTP Session**: `session` (Soup.Session?) - HTTP session for requests

#### Signal Emission
The Client emits several signals for event handling:
- `stream_chunk(string, bool, Response.Chat)` - streaming chunk received
- `stream_content(string, Response.Chat)` - streaming content (not thinking) received
- `tool_message(Message)` - tool status message
- `chat_send(Call.Chat)` - chat request sent
- `stream_start()` - streaming started
- `message_created(Message, ChatContentInterface?)` - message created in conversation

#### API Methods
- `chat(string, Cancellable?)` - Legacy chat method (backward compatibility)
- `chat_execute(Call.Chat)` - Sends pre-prepared Chat object (legacy method, may be removed)
- `models()` - Gets list of available models
- `ps()` - Gets list of running models
- `version(Cancellable?)` - Gets Ollama server version
- `show_model(string)` - Gets detailed model information
- `fetch_all_model_details()` - Fetches details for all models
- `embed(string, ...)` - Generates embeddings
- `embed_array(ArrayList<string>, ...)` - Generates embeddings for array
- `generate(string, string, Cancellable?)` - Generates response without conversation history

### Current Chat Creation Issues

#### Problem 1: "Realized" Properties
Chat currently has several properties that are "realized" (read-only getters that delegate to client):
```vala
public bool stream { 
    get { return this.client.stream; }
    set { } // Fake setter for serialization
}
```
These properties exist in Chat but don't store their own values:
- `stream` - reads from `client.stream`
- `format` - reads from `client.format`
- `think` - reads from `client.think`
- `keep_alive` - reads from `client.keep_alive`
- `tools` - reads from `client.tools` (should be real property on Chat, managed by caller)

**Problem**: Chat cannot have different values than Client, making it impossible to have per-chat configuration. Tools should be on Chat, not Client, and the caller should add tools directly to Chat.

#### Problem 2: Options Loading Logic
Chat constructor currently loads options from `client.config.model_options` if not provided:
```vala
if (options != null) {
    this.options = options;
} else {
    if (this.client.config.model_options.has_key(model)) {
        this.options = this.client.config.model_options.get(model);
    } else {
        this.options = new Call.Options();
    }
}
```

**Problem**: 
- Options are not copied from `client.options` (Client's default options)
- Falls back to config's model_options, which may not match Client's current options
- Creates empty Options if neither provided nor in config

#### Problem 3: Inconsistent Chat Creation
Chat instances are created in multiple places with different patterns:

1. **AgentHandler** (`libollmchat/Prompt/AgentHandler.vala:131`):
   ```vala
   var call = new OLLMchat.Call.Chat(this.client, this.client.model);
   ```
   - No options provided - relies on constructor fallback logic

2. **CodeAssistantHandler** (`liboccoder/Prompt/CodeAssistantHandler.vala:55`):
   ```vala
   var call = new OLLMchat.Call.Chat(this.client, this.client.model);
   ```
   - No options provided - relies on constructor fallback logic

3. **Client.chat()** (`libollmchat/Client.vala:320`):
   ```vala
   var call = new Call.Chat(this, this.model) {
       cancellable = cancellable
   };
   ```
   - No options provided - relies on constructor fallback logic

4. **Manager.new_client()** usage (`libollmchat/History/Manager.vala:271`):
   ```vala
   var session = new Session(this, new Call.Chat(client, client.model));
   ```
   - No options provided - relies on constructor fallback logic

5. **EmptySession.send_message()** (`libollmchat/History/EmptySession.vala:73`):
   ```vala
   var chat = new Call.Chat(new_client, new_client.model);
   ```
   - No options provided - relies on constructor fallback logic

6. **Config2.create_chat()** (`libollmchat/Settings/Config2.vala:559`):
   ```vala
   return new OLLMchat.Call.Chat(client, model_usage_obj.model, model_usage_obj.options);
   ```
   - Explicitly provides options from ModelUsage

7. **Analysis** (`libocvector/Indexing/Analysis.vala:322`):
   ```vala
   var chat = new OLLMchat.Call.Chat(analysis_client, analysis_usage.model, analysis_usage.options);
   ```
   - Explicitly provides options from usage

**Problem**: Most places don't provide options, relying on inconsistent fallback logic. Only Config2 and Analysis explicitly provide options.

### What Should Be Removed from Client

Based on the agent refactoring plan (1.10), the following should eventually be removed from Client:
- **Prompt Assistant** (already removed in current code) - prompt generation moved to agent layer
- **Tool execution logic** (already moved) - tools are managed at agent level

However, for this refactoring (1.2), we focus on:
- **Options fallback logic** - should be in Chat constructor, not Client
- **Config model_options lookup** - Chat should use Client.options as default, not config directly

### What Client Should Keep

Client should remain responsible for:
- Connection and configuration management
- Model selection and caching
- Tool registration and management (tools are still stored on Client)
- Permission provider management
- Signal emission for streaming and messages
- API method implementations
- HTTP session management

## Implementation Details

### Key Changes

1. **Make Chat Options a real object** 
   - Currently Chat Options is a "realized" object (reads from client.config.model_options)
   - Should be a proper object that copies from Client.options as default
   - Chat should have its own Options instance that can be modified independently

2. **Copy options from Client when creating Chat**
   - Chat constructor should copy `client.options.clone()` as default
   - If options are explicitly provided, use those instead
   - Remove fallback to `client.config.model_options` (config lookup should happen at Client creation time, not Chat creation)

3. **Make Chat properties real (not "realized")**
   - Convert `stream`, `format`, `think`, `keep_alive` from getters to real properties
   - Copy values from Client when creating Chat
   - Chat can then have different values than Client if needed

4. **Use Client values as defaults**
   - When creating Chat, copy all relevant properties from Client:
     - `options` → `options.clone()`
     - `stream` → `stream`
     - `format` → `format`
     - `think` → `think`
     - `keep_alive` → `keep_alive`
   - Tools are NOT copied from Client - caller adds tools directly to Chat
   - Each Chat can have different tools (conversation-specific)

### Benefits
- Better separation of concerns - Chat has its own configuration
- More consistent option handling - always copies from Client.options
- Easier to manage chat configuration - can override per-chat
- Clearer relationship between Client and Chat - Chat copies from Client, not config
- Enables per-chat customization - different chats can have different settings

### Files to Modify

#### Primary Changes
- `libollmchat/Call/Chat.vala` - Options handling and property conversion
  - Change constructor to copy from `client.options` instead of `client.config.model_options`
  - Convert "realized" properties to real properties
  - Copy values from Client in constructor

#### Review All Chat Creation Points
All files that create Chat instances (should work without changes, but verify):
- `libollmchat/Prompt/AgentHandler.vala` - Creates Chat without options
- `liboccoder/Prompt/CodeAssistantHandler.vala` - Creates Chat without options
- `libollmchat/Client.vala` - Legacy chat() method creates Chat
- `libollmchat/History/Manager.vala` - Creates Chat for Session
- `libollmchat/History/EmptySession.vala` - Creates Chat when converting to Session
- `libollmchat/History/SessionPlaceholder.vala` - Creates Chat when loading Session
- `libollmchat/Settings/Config2.vala` - Creates Chat with explicit options (should still work)
- `libocvector/Indexing/Analysis.vala` - Creates Chat with explicit options (should still work)

### Implementation Steps

1. **Update Chat Constructor**
   - Change options loading logic:
     - If options provided: use them
     - Otherwise: copy from `client.options.clone()`
   - Remove fallback to `client.config.model_options`
   - Copy other properties from Client: `stream`, `format`, `think`, `keep_alive`

2. **Convert "Realized" Properties to Real Properties**
   - Change `stream`, `format`, `think`, `keep_alive` from getters to real properties
   - Initialize them in constructor from Client values
   - Update serialization if needed (currently uses fake setters)

3. **Verify All Chat Creation Points**
   - Test that all places creating Chat work correctly
   - Ensure explicit options still work (Config2, Analysis)
   - Ensure default copying works (AgentHandler, etc.)

4. **Update Documentation**
   - Update Chat class documentation
   - Update constructor documentation
   - Document the copying behavior

### Implementation Notes

- **Options.clone()**: Already exists in `Call.Options` class, so we can use it
- **Serialization**: Chat already has custom serialization logic, may need updates for new properties
- **Backward Compatibility**: Existing code should continue to work, but behavior will be more consistent
- **Config Model Options**: The config's model_options are still used when creating Client (via Config2.create_client()), but Chat will use Client.options as default instead of looking up config again

### Testing Considerations

- Verify Chat copies options from Client correctly
- Verify explicit options still work (Config2.create_chat())
- Verify Chat properties can be modified independently of Client
- Verify serialization/deserialization still works
- Test all Chat creation points
