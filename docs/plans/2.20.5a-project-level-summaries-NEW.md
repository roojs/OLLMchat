# 2.20.5a. Project-Level Summaries (proper plan)

## Status

⏳ **PENDING**

## Coding Standards Checklist

Before implementing, verify this plan adheres to the coding standards in [.cursor/rules/CODING_STANDARDS.md](.cursor/rules/CODING_STANDARDS.md):

- **Nullable types**: Plan uses `PromptTemplate?` for static templates (loaded in static construct); otherwise avoids nullable. VectorMetadata and return values use non-null with default `description = ""`.
- **Null checks**: Plan avoids null checks; static templates are loaded in static construct and used after; `metadata_keymap.has_key()` then `.get()`.
- **String interpolation**: Plan does not use `@"..."`; uses concatenation and `string.joinv()`.
- **Temporary variables**: Plan avoids one-use temporaries; inlines where trivial (e.g. `user_message` used once for messages; `raw_response` used for return/save — kept for readability).
- **Brace placement**: Line breaks for namespace/class/methods; inline for control structures.
- **`this.` prefix**: Plan uses `this.` for instance members (`this.sql_db`, `this.request_analysis`).
- **GLib prefix**: Plan uses `GLib.Error`, `GLib.Path.get_basename`, `GLib.warning`, `GLib.critical` where applicable.
- **Property initialization**: Static templates initialized in static construct; no constructor-set defaults needed beyond `base(config)`.
- **Line length & breaking**: Long lines broken (e.g. SQL, `fill()` args, message lists).
- **StringBuilder usage**: Plan does not use `GLib.StringBuilder`; uses `string.joinv()` and `+` for concatenation.
- **ArrayList for strings**: Plan uses `string[]` and `string.joinv()`; uses `Gee.ArrayList` only for `VectorMetadata`/messages collections, not for building strings to join.
- **has_key() then get()**: Plan uses `metadata_keymap.has_key((int)id)` then `metadata_keymap.get((int)id)`; `build_file_ids.contains()` for set.

## Purpose

Generate project-level description (overview, languages, build system, docs, folder structure) and dependency list. Store in `vector_metadata`; merge into `{project_context}` for the system prompt.

## Requirements (summary)

- **vector_metadata**: `element_type = 'project'` (summary) and `element_type = 'dependencies'` (from build files); both `vector_id = 0`, `file_id` = project root id.
- **Category "build"**: LLM assigns file category when analyzing a file. Update **analysis-prompt-file.txt** so the LLM returns `CATEGORY: description` with CATEGORY one of `build`, `other`. Analysis.vala parses and sets `file_metadata.category`. Dependency extraction queries `vector_metadata` where `category = 'build'`.
- **Two LLM queries**: (a) Dependency extraction from build-file content → store as dependencies; (b) Project summary from files/folders list → store as project. Merge both when building `{project_context}`.
- **Flow**: index_folder → index_folders → index_project (dependency extraction then project summary if > 1 day old and files updated).

---

## 1. Category "build" — exact code

### 1.1 RequestCodebaseSearch.vala

**File**: `libocvector/Tool/RequestCodebaseSearch.vala`

```vala
private static string[] VALID_CATEGORIES = {
	"plan",
	"documentation",
	"rule",
	"configuration",
	"data",
	"license",
	"changelog",
	"other",
	"build"
};
```

Update `validate_category()` error string to include "build". When `category = "build"`, allow `element_type = 'file'` in the filter (not only document/section).

## 2. New prompt resources

### 2.1 analysis-prompt-project.txt (NEW)

**File**: `resources/ocvector/analysis-prompt-project.txt`

```text
You are a code analysis assistant. Your task is to generate a structured PROJECT SUMMARY for a codebase.

CRITICAL: Use only the information provided below. Do not infer or add information.

Input:
- Project path: {project_path}
- List of folders and files with their one-line descriptions:

{folders_and_files_list}

Output format — fill in each section. Keep each section concise (a few lines). Do not include dependencies or package lists here.

OVERVIEW:
<one short paragraph describing what the project is and its primary purpose>

LANGUAGES:
<comma-separated or bullet list of primary languages used>

BUILD_SYSTEM:
<brief description of build system, e.g. Meson, CMake, npm, cargo>

DOCUMENTATION_LOCATION:
<where docs live, e.g. docs/, README, .cursor/rules>

FOLDER_STRUCTURE:
<short description of main top-level folders and their roles>

Return ONLY the filled template above. No extra text, no markdown code fences.
```

### 2.2 analysis-prompt-dependencies.txt (NEW)

**File**: `resources/ocvector/analysis-prompt-dependencies.txt`

```text
You are a code analysis assistant. Your task is to extract build system and dependency information from the following build/manifest file content.

CRITICAL: Use only the content provided. Extract only what is explicitly stated or clearly implied.

Build file content:

{build_file_content}

Output format — fill in each section:

BUILD_SYSTEM:
<name and version if evident, e.g. Meson, npm, Cargo>

TOOLS_AND_COMMANDS:
<tools and commands used to build or run the application, one per line if multiple>

DEPENDENCIES:
<bullet list of dependencies (libraries, packages, modules) mentioned in the content>

Return ONLY the filled template above. No extra text, no markdown code fences.
```

---

## 3. ProjectAnalysis and dependency extraction

### 3.1 ProjectAnalysis.vala (NEW)

**File**: `libocvector/Indexing/ProjectAnalysis.vala`

```vala
namespace OLLMvector.Indexing
{
	public class ProjectAnalysis : VectorBase
	{
		private SQ.Database sql_db;
		private static PromptTemplate? project_template = null;
		private static PromptTemplate? dependencies_template = null;

		static construct
		{
			try {
				project_template = new PromptTemplate("analysis-prompt-project.txt");
				project_template.load();
				dependencies_template = new PromptTemplate("analysis-prompt-dependencies.txt");
				dependencies_template.load();
			} catch (GLib.Error e) {
				GLib.critical("Failed to load project/dependencies prompt templates: %s", e.message);
			}
		}

		public ProjectAnalysis(OLLMchat.Settings.Config2 config, SQ.Database sql_db)
		{
			base(config);
			this.sql_db = sql_db;
		}

		public async void extract_dependencies(OLLMfiles.Folder root_folder) throws GLib.Error
		{
			string[] file_ids = {};
			foreach (var pf in root_folder.project_files) {
				file_ids += pf.file.id.to_string();
			}
			if (file_ids.length == 0) {
				return;
			}
			var build_rows = new Gee.ArrayList<VectorMetadata>();
			yield VectorMetadata.query(this.sql_db).select_async(
				"WHERE file_id IN (" + string.joinv(",", file_ids) + ") AND category = 'build' AND element_type = 'file'",
				build_rows
			);
			if (build_rows.size == 0) {
				return;
			}
			var build_file_ids = new Gee.HashSet<int64>();
			foreach (var m in build_rows) {
				build_file_ids.add(m.file_id);
			}
			string build_content = "";
			foreach (var pf in root_folder.project_files) {
				if (!build_file_ids.contains(pf.file.id)) {
					continue;
				}
				string content = "";
				try {
					content = pf.file.get_contents(0);
				} catch (GLib.Error e) {
					GLib.warning("ProjectAnalysis: could not read build file %s: %s", pf.file.path, e.message);
					continue;
				}
				build_content += "\n--- FILE: " + pf.file.path + " ---\n" + content;
			}
			if (build_content.strip() == "") {
				return;
			}
			var user_message = dependencies_template.fill("build_file_content", build_content.strip());
			var messages = new Gee.ArrayList<OLLMchat.Message>();
			if (dependencies_template.system_message != "") {
				messages.add(new OLLMchat.Message("system", dependencies_template.system_message));
			}
			messages.add(new OLLMchat.Message("user", user_message));
			string raw_response = "";
			try {
				raw_response = yield this.request_analysis(messages);
			} catch (GLib.Error e) {
				GLib.warning("ProjectAnalysis: extract_dependencies LLM failed: %s", e.message);
				return;
			}
			var deps_meta = new VectorMetadata() {
				element_type = "dependencies",
				element_name = "dependencies",
				start_line = 0,
				end_line = 0,
				description = raw_response.strip(),
				file_id = root_folder.id,
				vector_id = 0,
				ast_path = ""
			};
			deps_meta.saveToDB(this.sql_db, false);
			this.sql_db.backupDB();
		}

		public async VectorMetadata analyze(OLLMfiles.Folder root_folder, Gee.HashMap<int, VectorMetadata> metadata_keymap) throws GLib.Error
		{
			string[] folder_lines = {};
			foreach (var folder in root_folder.project_files.folder_map.values) {
				var name = GLib.Path.get_basename(folder.path);
				if (!metadata_keymap.has_key((int)folder.id)) {
					folder_lines += "  - (folder) " + name;
					continue;
				}
				var vm = metadata_keymap.get((int)folder.id);
				if (vm.description == "") {
					folder_lines += "  - (folder) " + name;
					continue;
				}
				folder_lines += "  - (folder) " + name + ": " + vm.description;
			}
			string[] file_lines = {};
			foreach (var pf in root_folder.project_files) {
				var name = GLib.Path.get_basename(pf.file.path);
				if (!metadata_keymap.has_key((int)pf.file.id)) {
					file_lines += "  - (file) " + name;
					continue;
				}
				var vm = metadata_keymap.get((int)pf.file.id);
				if (vm.description == "") {
					file_lines += "  - (file) " + name;
					continue;
				}
				file_lines += "  - (file) " + name + ": " + vm.description;
			}
			string folders_and_files_list = string.joinv("\n", folder_lines) + "\n" + string.joinv("\n", file_lines);
			var user_message = project_template.fill(
				"project_path", root_folder.path != "" ? root_folder.path : "unknown",
				"folders_and_files_list", folders_and_files_list.strip()
			);
			var messages = new Gee.ArrayList<OLLMchat.Message>();
			if (project_template.system_message != "") {
				messages.add(new OLLMchat.Message("system", project_template.system_message));
			}
			messages.add(new OLLMchat.Message("user", user_message));
			string raw_response = "";
			try {
				raw_response = yield this.request_analysis(messages);
			} catch (GLib.Error e) {
				GLib.warning("ProjectAnalysis: analyze LLM failed: %s", e.message);
				return new VectorMetadata() {
					element_type = "project",
					element_name = GLib.Path.get_basename(root_folder.path),
					start_line = 0,
					end_line = 0,
					description = "",
					file_id = root_folder.id,
					vector_id = 0,
					ast_path = ""
				};
			}
			var project_meta = new VectorMetadata() {
				element_type = "project",
				element_name = GLib.Path.get_basename(root_folder.path),
				start_line = 0,
				end_line = 0,
				description = raw_response.strip(),
				file_id = root_folder.id,
				vector_id = 0,
				ast_path = ""
			};
			project_meta.saveToDB(this.sql_db, false);
			this.sql_db.backupDB();
			return project_meta;
		}
	}
}
```

### 3.2 Indexer.vala

**File**: `libocvector/Indexing/Indexer.vala`

Add method:

```vala
private async void index_project(OLLMfiles.Folder root_folder, bool force = false) throws GLib.Error
{
	var metadata_keymap = yield this.build_metadata_keymap_from_project(root_folder);
	var project_analysis = new ProjectAnalysis(this.config, this.sql_db);
	yield project_analysis.extract_dependencies(root_folder);
	yield project_analysis.analyze(root_folder, metadata_keymap);
}
```

Replace in `index_filebase()`:

```vala
if (filebase is OLLMfiles.Folder) {
	return yield this.index_folder((OLLMfiles.Folder)filebase, recurse, force);
}
```

with:

```vala
if (filebase is OLLMfiles.Folder) {
	var folder = (OLLMfiles.Folder)filebase;
	var files_indexed = yield this.index_folder(folder, recurse, force);
	yield this.index_folders(folder, force);
	yield this.index_project(folder, force);
	return files_indexed;
}
```

---

## 4. Build and resources

**File**: `libocvector/meson.build`

```meson
'Indexing/FolderAnalysis.vala',  # Folder analysis layer
'Indexing/ProjectAnalysis.vala',  # Project summary and dependency extraction
'Indexing/DocumentationVectorBuilder.vala',  # Documentation vector generation and FAISS storage
```

**File**: `resources/gresources.xml`

In `<gresource prefix="/ocvector">` add:

```xml
<file>analysis-prompt-project.txt</file>
<file>analysis-prompt-dependencies.txt</file>
```

---

## 5. {project_context} merge

At the call site where the system prompt is built:

```vala
var project_rows = new Gee.ArrayList<VectorMetadata>();
yield VectorMetadata.query(sql_db).select_async(
	"WHERE file_id = " + project_root.id.to_string() + " AND element_type IN ('project', 'dependencies') ORDER BY element_type",
	project_rows
);
string project_context = "";
foreach (var row in project_rows) {
	if (project_context != "") {
		project_context += "\n\n";
	}
	project_context += row.description;
}
// Substitute project_context for {project_context} in the prompt template
```

---

## Deliverables

- [ ] RequestCodebaseSearch: add "build" to VALID_CATEGORIES; update validate message; allow element_type 'file' when category = "build".
- [ ] analysis-prompt-file.txt: replace CRITICAL REQUIREMENTS and final line as in §1.2.
- [ ] Analysis.vala: parse CATEGORY: description; set file_category and file_description_parsed; add category to file VectorMetadata; use file_description_parsed in log.
- [ ] analysis-prompt-project.txt: create with content in §2.1.
- [ ] analysis-prompt-dependencies.txt: create with content in §2.2.
- [ ] ProjectAnalysis.vala: new class with extract_dependencies() and analyze(); store dependencies and project rows.
- [ ] Indexer: add index_project(); call it from index_filebase() after index_folders().
- [ ] meson.build: add ProjectAnalysis.vala; resources: add two new prompts.
- [ ] {project_context}: merge project + dependencies where system prompt is built.
- [ ] Test: project summary; dependency extraction; category "build" on file metadata.

## Related Plans

- 2.20-codebase-scanner-improvements.md
- 2.20.4-folder-level-summaries.md (prerequisite: index_folders, build_metadata_keymap_from_project)
- 2.10-codebase-search-tool.md
