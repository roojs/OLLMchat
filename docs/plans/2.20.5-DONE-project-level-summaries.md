# 2.20.5a. Project-Level Summaries (proper plan)

## Status

⏳ **PENDING** — plan not fully implemented.

---

### ✅ DONE

| Item | Status |
|------|--------|
| analysis-prompt-project.txt | ✅ Created |
| analysis-prompt-dependencies.txt | ✅ Created |
| ProjectAnalysis.vala | ✅ Created (extract_dependencies, analyze, file_to_vectormap) |
| meson.build | ✅ ProjectAnalysis.vala added |

---

### ⏳ NEEDS DOING

| Item | Status |
|------|--------|
| RequestCodebaseSearch | ⏳ Add "build" to VALID_CATEGORIES; allow element_type 'file' when category = "build" |
| analysis-prompt-file.txt | ⏳ Add CATEGORY (build/other) to output |
| Analysis.vala | ⏳ Parse CATEGORY; set category on file VectorMetadata |
| Indexer | ⏳ Add index_project(); call from index_filebase (design in [2.20.5-indexer-section.md](2.20.5-indexer-section.md)) |
| resources/gresources.xml | ⏳ Add analysis-prompt-project.txt, analysis-prompt-dependencies.txt |
| {project_context} merge | ⏳ Load project + dependencies rows where system prompt is built |
| Tests | ⏳ Project summary; dependency extraction; category "build" |

---

## Coding Standards Checklist

Before implementing, verify this plan adheres to the coding standards in [.cursor/rules/CODING_STANDARDS.md](.cursor/rules/CODING_STANDARDS.md):

- **Nullable types**: Plan uses `PromptTemplate?` for static templates (loaded in static construct); otherwise avoids nullable. VectorMetadata and return values use non-null with default `description = ""`.
- **Null checks**: Plan avoids null checks; static templates are loaded in static construct and used after; `metadata_keymap.has_key()` then `.get()`.
- **String interpolation**: Plan does not use `@"..."`; uses concatenation and `string.joinv()`.
- **Temporary variables**: Plan avoids one-use temporaries; inlines where trivial (e.g. `user_message` used once for messages; `raw_response` used for return/save — kept for readability).
- **Brace placement**: Line breaks for namespace/class/methods; inline for control structures.
- **`this.` prefix**: Plan uses `this.` for instance members (`this.sql_db`, `this.request_analysis`).
- **GLib prefix**: Plan uses `GLib.Error`, `GLib.Path.get_basename`, `GLib.warning`, `GLib.critical` where applicable.
- **Property initialization**: Static templates initialized in static construct; no constructor-set defaults needed beyond `base(config)`.
- **Line length & breaking**: Long lines broken (e.g. SQL, `fill()` args, message lists).
- **StringBuilder usage**: Plan does not use `GLib.StringBuilder`; uses `string.joinv()` and `+` for concatenation.
- **ArrayList for strings**: Plan uses `string[]` and `string.joinv()`; uses `Gee.ArrayList` only for `VectorMetadata`/messages collections, not for building strings to join.
- **has_key() then get()**: Plan uses `metadata_keymap.has_key((int)id)` then `metadata_keymap.get((int)id)`; `build_file_ids.contains()` for set.

## Purpose

Generate project-level description (overview, languages, build system, docs, folder structure) and dependency list. Store in `vector_metadata`; merge into `{project_context}` for the system prompt.

## Requirements (summary)

- **vector_metadata**: `element_type = 'project'` (summary) and `element_type = 'dependencies'` (from build files); both `vector_id = 0`, `file_id` = project root id.
- **Category "build"**: LLM assigns file category when analyzing a file. Update **analysis-prompt-file.txt** so the LLM returns `CATEGORY: description` with CATEGORY one of `build`, `other`. Analysis.vala parses and sets `file_metadata.category`. Dependency extraction queries `vector_metadata` where `category = 'build'`.
- **Two LLM queries**: (a) Dependency extraction from build-file content → store as dependencies; (b) Project summary from files/folders list → store as project. Merge both when building `{project_context}`.
- **Flow (proposed):** After file indexing (`index_folder`), run project-level analysis (dependency extraction then project summary). Exact entry point and helper methods **not yet specified** — to be designed and approved.

---

## 1. New prompt resources — ✅ DONE

### 1.1 analysis-prompt-project.txt (NEW) — ✅ DONE

**File**: `resources/ocvector/analysis-prompt-project.txt`

```text
You are a code analysis assistant. Your task is to generate a structured PROJECT SUMMARY for a codebase.

CRITICAL: Use only the information provided below. Do not infer or add information.

Input:
- Project path: {project_path}
- List of folders and files with their one-line descriptions:

{folders_and_files_list}

Output format — fill in each section. Keep each section concise (a few lines). Do not include dependencies or package lists here.

OVERVIEW:
<one short paragraph describing what the project is and its primary purpose>

LANGUAGES:
<comma-separated or bullet list of primary languages used>

DOCUMENTATION_LOCATION:
<where docs live, e.g. docs/, README, .cursor/rules>

FOLDER_STRUCTURE:
<short description of main top-level folders and their roles>

Return ONLY the filled template above. No extra text, no markdown code fences.
```

### 1.2 analysis-prompt-dependencies.txt (NEW) — ✅ DONE

**File**: `resources/ocvector/analysis-prompt-dependencies.txt`

```text
You are a code analysis assistant. Your task is to extract build system and dependency information from the following build/manifest file content.

CRITICAL: Use only the content provided. Extract only what is explicitly stated or clearly implied.

Build file content:

{build_file_content}

Output format — fill in each section:

BUILD_SYSTEM:
<name and version if evident, e.g. Meson, npm, Cargo>

TOOLS_AND_COMMANDS:
<tools and commands used to build or run the application, one per line if multiple>

DEPENDENCIES:
<bullet list of dependencies (libraries, packages, modules) mentioned in the content>

Return ONLY the filled template above. No extra text, no markdown code fences.
```

---

## 2. ProjectAnalysis and dependency extraction

### 2.1 ProjectAnalysis.vala — ✅ DONE (API update planned)

**File**: `libocvector/Indexing/ProjectAnalysis.vala`

**Planned API (not yet implemented):**

- **Constructor:** `ProjectAnalysis(config, sql_db, root_folder)` — take `root_folder` in ctor so the instance is bound to one project root; reuse same instance for `extract_dependencies()` and `analyze()` in a single run.
- **Property:** `metadata_keymap` (`Gee.HashMap<int, VectorMetadata>`) — caller may set before `analyze()` (e.g. from `FolderAnalysis.analyze_children`). If unset or empty, `analyze()` builds the keymap from DB (query `vector_metadata` for file/folder ids in the project).
- **Methods:** `extract_dependencies()` and `analyze()` take no arguments; both use `this.root_folder`; `analyze()` uses `this.metadata_keymap` or builds from DB.

**Current code** (to be refactored to the above):

```vala
namespace OLLMvector.Indexing
{
	public class ProjectAnalysis : VectorBase
	{
		private SQ.Database sql_db;
		// Planned: private OLLMfiles.Folder root_folder;
		// Planned: public Gee.HashMap<int, VectorMetadata> metadata_keymap { get; set; default = new Gee.HashMap<int, VectorMetadata>(); }
		private static PromptTemplate? project_template = null;
		private static PromptTemplate? dependencies_template = null;

		static construct
		{
			try {
				project_template = new PromptTemplate("analysis-prompt-project.txt");
				project_template.load();
				dependencies_template = new PromptTemplate("analysis-prompt-dependencies.txt");
				dependencies_template.load();
			} catch (GLib.Error e) {
				GLib.critical("Failed to load project/dependencies prompt templates: %s", e.message);
			}
		}

		// Planned: public ProjectAnalysis(config, sql_db, root_folder)
		public ProjectAnalysis(OLLMchat.Settings.Config2 config, SQ.Database sql_db)
		{
			base(config);
			this.sql_db = sql_db;
		}

		// Planned: public async void extract_dependencies() — uses this.root_folder
		public async void extract_dependencies(OLLMfiles.Folder root_folder) throws GLib.Error
		{
			string[] file_ids = {};
			foreach (var pf in root_folder.project_files) {
				file_ids += pf.file.id.to_string();
			}
			if (file_ids.length == 0) {
				return;
			}
			var build_rows = new Gee.ArrayList<VectorMetadata>();
			yield VectorMetadata.query(this.sql_db).select_async(
				"WHERE file_id IN (" + string.joinv(",", file_ids) + ") AND category = 'build' AND element_type = 'file'",
				build_rows
			);
			if (build_rows.size == 0) {
				return;
			}
			string build_content = "";
			foreach (var m in build_rows) {
				var file = root_folder.project_files.get_by_id(m.file_id);
				if (file == null) {
					continue;
				}
				string content = "";
				try {
					content = file.get_contents(0);
				} catch (GLib.Error e) {
					GLib.warning("ProjectAnalysis: could not read build file %s: %s", file.path, e.message);
					continue;
				}
				build_content += "\n--- FILE: " + file.path + " ---\n" + content;
			}
			if (build_content.strip() == "") {
				return;
			}
			var user_message = dependencies_template.fill(
				"build_file_content", build_content.strip()
			);
			var messages = new Gee.ArrayList<OLLMchat.Message>();
			messages.add(new OLLMchat.Message("system", dependencies_template.system_message));
			messages.add(new OLLMchat.Message("user", user_message));
			string raw_response = "";
			try {
				raw_response = yield this.request_analysis(messages);
			} catch (GLib.Error e) {
				GLib.warning("ProjectAnalysis: extract_dependencies LLM failed: %s", e.message);
				return;
			}
			var deps_meta = new VectorMetadata() {
				element_type = "dependencies",
				element_name = "dependencies",
				start_line = 0,
				end_line = 0,
				description = raw_response.strip(),
				file_id = root_folder.id,
				vector_id = 0,
				ast_path = ""
			};
			deps_meta.saveToDB(this.sql_db, false);
			this.sql_db.backupDB();
		}

		// Planned: build keymap from DB when metadata_keymap unset; otherwise use property (see API above)
		// Current: file_to_vectormap / analyze(root_folder) — to become analyze() using this.root_folder and this.metadata_keymap

		public async VectorMetadata analyze(OLLMfiles.Folder root_folder) throws GLib.Error
		{
			var metadata_keymap = yield this.file_to_vectormap(root_folder);
			string[] folder_lines = {};
			foreach (var folder in root_folder.project_files.folder_map.values) {
				var name = GLib.Path.get_basename(folder.path);
				if (!metadata_keymap.has_key((int)folder.id)) {
					folder_lines += "  - (folder) " + name;
					continue;
				}
				var vm = metadata_keymap.get((int)folder.id);
				if (vm.description == "") {
					folder_lines += "  - (folder) " + name;
					continue;
				}
				folder_lines += "  - (folder) " + name + ": " + vm.description;
			}
			string[] file_lines = {};
			foreach (var pf in root_folder.project_files) {
				var name = GLib.Path.get_basename(pf.file.path);
				if (!metadata_keymap.has_key((int)pf.file.id)) {
					file_lines += "  - (file) " + name;
					continue;
				}
				var vm = metadata_keymap.get((int)pf.file.id);
				if (vm.description == "") {
					file_lines += "  - (file) " + name;
					continue;
				}
				file_lines += "  - (file) " + name + ": " + vm.description;
			}
			string folders_and_files_list = string.joinv("\n", folder_lines) + "\n" + string.joinv("\n", file_lines);
			var user_message = project_template.fill(
				"project_path", root_folder.path != "" ? root_folder.path : "unknown",
				"folders_and_files_list", folders_and_files_list.strip()
			);
			var messages = new Gee.ArrayList<OLLMchat.Message>();
			messages.add(new OLLMchat.Message("system", project_template.system_message));
			messages.add(new OLLMchat.Message("user", user_message));
			string raw_response = "";
			try {
				raw_response = yield this.request_analysis(messages);
			} catch (GLib.Error e) {
				GLib.warning("ProjectAnalysis: analyze LLM failed: %s", e.message);
				return new VectorMetadata() {
					element_type = "project",
					element_name = GLib.Path.get_basename(root_folder.path),
					start_line = 0,
					end_line = 0,
					description = "",
					file_id = root_folder.id,
					vector_id = 0,
					ast_path = ""
				};
			}
			var project_meta = new VectorMetadata() {
				element_type = "project",
				element_name = GLib.Path.get_basename(root_folder.path),
				start_line = 0,
				end_line = 0,
				description = raw_response.strip(),
				file_id = root_folder.id,
				vector_id = 0,
				ast_path = ""
			};
			project_meta.saveToDB(this.sql_db, false);
			this.sql_db.backupDB();
			return project_meta;
		}
	}
}
```

### 2.2 Indexer.vala — entry point, integration — ⏳ NEEDS DOING

**File**: `libocvector/Indexing/Indexer.vala`

Indexer currently only calls `index_folder()` for folders. To run project-level analysis after file indexing, add the following. All code (helper, entry point, integration) is in **[2.20.5-indexer-section.md](2.20.5-indexer-section.md)** for plan review; implement only after approval.

- **Helper:** A way to build a keymap of existing `VectorMetadata` for the project’s files (and optionally folders), e.g. a method like `file_to_vectormap(root_folder)` — purpose, signature, and behavior TBD.
- **Entry point:** A method that runs dependency extraction and project summary using that keymap and `ProjectAnalysis` (e.g. `index_project(root_folder, force)` or equivalent) — signature, `force` semantics, and when it is called TBD.
- **Integration:** From `index_filebase()`, after `index_folder()`, call the new entry point. Exact code and return-value handling TBD.

Do **not** implement Indexer changes from draft code in this section until the above are written up and approved.

---

## 3. Build and resources — ✅ meson DONE; ⏳ gresources NEEDS DOING

**File**: `libocvector/meson.build`

```meson
'Indexing/FolderAnalysis.vala',  # Folder analysis layer
'Indexing/ProjectAnalysis.vala',  # Project summary and dependency extraction
'Indexing/DocumentationVectorBuilder.vala',  # Documentation vector generation and FAISS storage
```

**File**: `resources/gresources.xml`

In `<gresource prefix="/ocvector">` add:

```xml
<file>analysis-prompt-project.txt</file>
<file>analysis-prompt-dependencies.txt</file>
```

---

## 4. {project_context} merge — ⏳ NEEDS DOING

At the call site where the system prompt is built:

```vala
var project_rows = new Gee.ArrayList<VectorMetadata>();
yield VectorMetadata.query(sql_db).select_async(
	"WHERE file_id = " + project_root.id.to_string() + " AND element_type IN ('project', 'dependencies') ORDER BY element_type",
	project_rows
);
string project_context = "";
foreach (var row in project_rows) {
	if (project_context != "") {
		project_context += "\n\n";
	}
	project_context += row.description;
}
// Substitute project_context for {project_context} in the prompt template
```

---

## Deliverables

### ✅ DONE

- [x] ✅ **analysis-prompt-project.txt** — created with content in §1.1.
- [x] ✅ **analysis-prompt-dependencies.txt** — created with content in §1.2.
- [x] ✅ **ProjectAnalysis.vala** — new class: extract_dependencies(), analyze(), file_to_vectormap(); store dependencies and project rows.
- [x] ✅ **meson.build** — ProjectAnalysis.vala added.

### ⏳ NEEDS DOING

- [ ] ⏳ **RequestCodebaseSearch** — add "build" to VALID_CATEGORIES; update validate message; allow element_type 'file' when category = "build".
- [ ] ⏳ **analysis-prompt-file.txt** — replace CRITICAL REQUIREMENTS and final line; add CATEGORY (build/other) to output.
- [ ] ⏳ **Analysis.vala** — parse CATEGORY: description; set file_category and file_description_parsed; add category to file VectorMetadata; use file_description_parsed in log.
- [ ] ⏳ **Indexer** — add index_project(); call from index_filebase (design in [2.20.5-indexer-section.md](2.20.5-indexer-section.md)). Then implement.
- [ ] ⏳ **resources/gresources.xml** — add analysis-prompt-project.txt, analysis-prompt-dependencies.txt.
- [ ] ⏳ **{project_context}** — merge project + dependencies where system prompt is built.
- [ ] ⏳ **Test** — project summary; dependency extraction; category "build" on file metadata.

## Related Plans

- 2.20-codebase-scanner-improvements.md
- 2.20.4-folder-level-summaries.md (folder summaries reverted)
- 2.10-codebase-search-tool.md
