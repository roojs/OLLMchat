<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8"/>
    <title>OLLMvector &ndash; ollmchat &ndash; Vala Binding Reference</title>
    <link href="../style.css" rel="stylesheet" type="text/css"/><script src="../scripts.js" type="text/javascript">
    </script>
  </head>
  <body>
    <div class="site_header">OLLMvector &ndash; ollmchat Reference Manual</div>
    <div class="site_body">
      <div class="site_navigation">
        <ul class="navi_main">
          <li class="package_index"><a href="../index.html">Packages</a></li>
        </ul>
        <hr class="navi_hr"/>
        <ul class="navi_main">
          <li class="package"><a href="index.htm">ollmchat</a></li>
        </ul>
        <hr class="navi_hr"/>
        <ul class="navi_main">
          <li class="namespace">OLLMvector</li>
        </ul>
        <hr class="navi_hr"/>
        <ul class="navi_main">
          <li class="namespace"><a href="OLLMvector.Indexing.html">Indexing</a></li>
          <li class="namespace"><a href="OLLMvector.Search.html">Search</a></li>
          <li class="namespace"><a href="OLLMvector.Tool.html">Tool</a></li>
          <li class="class"><a href="OLLMvector.BackgroundScan.html">BackgroundScan</a></li>
          <li class="class"><a href="OLLMvector.Database.html">Database</a></li>
          <li class="class"><a href="OLLMvector.Index.html">Index</a></li>
          <li class="abstract_class"><a href="OLLMvector.VectorBase.html">VectorBase</a></li>
          <li class="class"><a href="OLLMvector.VectorMetadata.html">VectorMetadata</a></li>
          <li class="struct"><a href="OLLMvector.FloatArray.html">FloatArray</a></li>
          <li class="struct"><a href="OLLMvector.SearchResult.html">SearchResult</a></li>
          <li class="struct"><a href="OLLMvector.SearchResultWithDocument.html">SearchResultWithDocument</a></li>
        </ul>
      </div>
      <div class="site_content">
        <h1 class="main_title">OLLMvector</h1>
        <hr class="main_hr"/>
        <h2 class="main_title">Description:</h2>
        <div class="description">
          <p>Vector search and codebase indexing namespace.</p>
          <p>The OLLMvector namespace provides semantic codebase search functionality using vector embeddings and FAISS similarity search. It enables 
            finding code elements based on their semantic meaning rather than exact text matches.</p>
          <h2>Architecture </h2>
          <p>The library uses a three-layer indexing pipeline:</p>
          <ol type="1">
            <li>**Tree Layer**: Parses source code using tree-sitter to extract code elements
              <p>(classes, methods, functions, etc.) and creates VectorMetadata objects with</p>
              <p>line numbers and documentation ranges.</p></li>
          </ol>
          <p>2. **Analysis Layer**: Uses LLM to generate one-line descriptions for complex</p>
          <p>code elements. Simple elements (enums, basic properties) skip LLM analysis.</p>
          <p>3. **VectorBuilder Layer**: Converts code elements (with descriptions) into</p>
          <p>vector embeddings using embedding models, then stores them in FAISS and</p>
          <p>metadata in SQLite.</p>
          <p>The search process:</p>
          <ol type="1">
            <li>Convert search query to vector embedding
              <p>2. Perform FAISS similarity search to find similar vectors</p>
              <p>3. Lookup metadata (file, line range, element info) from SQLite</p>
              <p>4. Extract code snippets from files using buffer system</p>
              <p>5. Return formatted results with code citations</p></li>
          </ol>
          <h2>Usage Examples </h2>
          <h3>Setting Up the Database </h3>
          <p><pre class="main_source"><code><span class="main_comment">// Register model usage types in config</span><br/>OLLMvector.Database.register_config();<br/>OLLMvector.Indexing.Analysis.register_config();<br/><br/><span class="main_comment">// Setup default model usage if not already configured</span><br/>OLLMvector.Database.setup_embed_usage(config);<br/>OLLMvector.Indexing.Analysis.setup_analysis_usage(config);<br/><br/><span class="main_comment">// Check that required models are available</span><br/><span class="main_keyword">if</span> (!<span class="main_keyword">yield</span> OLLMvector.Database.check_required_models_available(config)) {<br/>    <span class="main_keyword">throw</span> <span class="main_keyword">new</span> Error(<span class="main_literal">"Required models not available"</span>);<br/>}<br/><br/><span class="main_comment">// Create database instance</span><br/><span class="main_keyword">var</span> vector_db = <span class="main_keyword">new</span> OLLMvector.Database(<br/>    embedding_client,<br/>    <span class="main_literal">"/path/to/vector.index"</span>,<br/>    <span class="main_literal">1024</span>  <span class="main_comment">// embedding dimension</span><br/>);</code></pre>
          </p>
          <h3>Indexing a File </h3>
          <p><pre class="main_source"><code><span class="main_comment">// Create indexer with required clients and databases</span><br/><span class="main_keyword">var</span> indexer = <span class="main_keyword">new</span> OLLMvector.Indexing.Indexer(<br/>    analysis_client,<br/>    embed_client,<br/>    vector_db,<br/>    sql_db,<br/>    project_manager<br/>);<br/><br/><span class="main_comment">// Index a single file</span><br/><span class="main_keyword">var</span> indexed = <span class="main_keyword">yield</span> indexer.index_file(file, force: <span class="main_literal">false</span>);<br/><br/><span class="main_comment">// Index a folder recursively</span><br/><span class="main_keyword">yield</span> indexer.index_folder(folder, recursive: <span class="main_literal">true</span>);</code></pre>
          </p>
          <h3>Performing a Search </h3>
          <p><pre class="main_source"><code><span class="main_comment">// Create search instance</span><br/><span class="main_keyword">var</span> search = <span class="main_keyword">new</span> OLLMvector.Search.Search(<br/>    vector_db,<br/>    sql_db,<br/>    config,<br/>    active_project,<br/>    <span class="main_literal">"find authentication logic"</span>,<br/>    <span class="main_literal">10</span>,  <span class="main_comment">// max_results</span><br/>    <span class="main_keyword">new</span> Gee.ArrayList&lt;<span class="main_basic_type">int</span>&gt;(),  <span class="main_comment">// filtered_vector_ids (empty = search all)</span><br/>    <span class="main_literal">null</span>  <span class="main_comment">// element_type_filter (optional)</span><br/>);<br/><br/><span class="main_comment">// Execute search</span><br/><span class="main_keyword">var</span> results = <span class="main_keyword">yield</span> search.execute();<br/><br/><span class="main_comment">// Access results</span><br/><span class="main_keyword">foreach</span> (<span class="main_keyword">var</span> result <span class="main_keyword">in</span> results) {<br/>    <span class="main_keyword">var</span> file = result.file();<br/>    <span class="main_keyword">var</span> snippet = result.code_snippet(max_lines: <span class="main_literal">20</span>);<br/>    print(<span class="main_literal">@"Found: </span><span class="main_escape">$(result.metadata.element_name)</span><span class="main_literal"> in </span><span class="main_escape">$(file.path)</span><span class="main_literal"></span><span class="main_escape">\n</span><span class="main_literal">"</span>);<br/>}</code></pre>
          </p>
          <h3>Using Background Scanning </h3>
          <p><pre class="main_source"><code><span class="main_comment">// Create background scanner (requires CodebaseSearchTool instance)</span><br/><span class="main_keyword">var</span> scanner = <span class="main_keyword">new</span> OLLMvector.BackgroundScan(<br/>    codebase_search_tool,<br/>    <span class="main_keyword">new</span> GitProvider()  <span class="main_comment">// Each thread needs its own instance for thread safety</span><br/>);<br/><br/><span class="main_comment">// Queue files for indexing (automatically processed in background)</span><br/>scanner.scanFile(file, project);<br/>scanner.scanProject(project);<br/><br/><span class="main_comment">// Monitor progress via signal</span><br/>scanner.scan_update.connect((queue_size, current_file) =&gt; {<br/>    print(<span class="main_literal">@"Queue: </span><span class="main_escape">$queue_size</span><span class="main_literal">, Current: </span><span class="main_escape">$current_file</span><span class="main_literal"></span><span class="main_escape">\n</span><span class="main_literal">"</span>);<br/>});</code></pre>
          </p>
          <h2>Best Practices </h2>
          <ol type="1">
            <li>Initialize Database First: Call register_config() and setup methods before creating Database instance
              <p>2. Check Models: Always verify required models are available before indexing</p>
              <p>3. Incremental Indexing: Use force=false to skip unchanged files (checks last_modified timestamp)</p>
              <p>4. Background Processing: Use BackgroundScan for automatic indexing of changed files</p>
              <p>5. Filter Results: Use element_type and language filters to narrow search results</p>
              <p>6. Thread Safety: Database operations are thread-safe (FAISS via mutex, SQLite in SERIALIZED mode)</p>
              <p>7. Error Handling: Always wrap indexing and search operations in try-catch blocks</p></li>
          </ol>
        </div>
        <h2 class="main_title">Content:</h2>
        <h3 class="main_title">Namespaces:</h3>
        <ul class="navi_inline">
          <li class="namespace"><a href="OLLMvector.Indexing.html">Indexing</a> - <span class="brief_description">Code indexing namespace.</span></li>
          <li class="namespace"><a href="OLLMvector.Search.html">Search</a> - <span class="brief_description">Vector search namespace.</span></li>
          <li class="namespace"><a href="OLLMvector.Tool.html">Tool</a> - <span class="brief_description">Tool integration namespace.</span></li>
        </ul>
        <h3 class="main_title">Classes:</h3>
        <ul class="navi_inline">
          <li class="class"><a href="OLLMvector.BackgroundScan.html">BackgroundScan</a> - <span class="brief_description">BackgroundScan manages a 
              background thread that continuously processes fileâ€‘indexing jobs. The thread is started on first use and lives for the lifetime of the
              application.</span></li>
          <li class="class"><a href="OLLMvector.Database.html">Database</a> - <span class="brief_description">Vector database with embedding 
              generation and FAISS storage.</span></li>
          <li class="class"><a href="OLLMvector.Index.html">Index</a> - <span class="brief_description">FAISS index wrapper for vector storage and 
              similarity search.</span></li>
          <li class="abstract_class"><a href="OLLMvector.VectorBase.html">VectorBase</a> - <span class="brief_description">Base class for vector 
              operations that need tool config access.</span></li>
          <li class="class"><a href="OLLMvector.VectorMetadata.html">VectorMetadata</a> - <span class="brief_description">Represents vector metadata 
              stored in SQL database.</span></li>
        </ul>
        <h3 class="main_title">Structs:</h3>
        <ul class="navi_inline">
          <li class="struct"><a href="OLLMvector.FloatArray.html">FloatArray</a> - <span class="brief_description">Container for batch vector 
              operations.</span></li>
          <li class="struct"><a href="OLLMvector.SearchResult.html">SearchResult</a> - <span class="brief_description">Represents a single search 
              result from FAISS similarity search.</span></li>
          <li class="struct"><a href="OLLMvector.SearchResultWithDocument.html">SearchResultWithDocument</a></li>
        </ul>
      </div>
    </div><br/>
    <div class="site_footer">Generated by <a href="https://docs.vala.dev"><kbd>valadoc</kbd></a>
    </div>
  </body>
</html>