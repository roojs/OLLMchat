<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8"/>
    <title>OLLMchat.Client &ndash; ollmchat &ndash; Vala Binding Reference</title>
    <link href="../style.css" rel="stylesheet" type="text/css"/><script src="../scripts.js" type="text/javascript">
    </script>
  </head>
  <body>
    <div class="site_header">OLLMchat.Client &ndash; ollmchat Reference Manual</div>
    <div class="site_body">
      <div class="site_navigation">
        <ul class="navi_main">
          <li class="package_index"><a href="../index.html">Packages</a></li>
        </ul>
        <hr class="navi_hr"/>
        <ul class="navi_main">
          <li class="package"><a href="index.htm">ollmchat</a></li>
        </ul>
        <hr class="navi_hr"/>
        <ul class="navi_main">
          <li class="namespace"><a href="OLLMchat.html">OLLMchat</a></li>
        </ul>
        <hr class="navi_hr"/>
        <ul class="navi_main">
          <li class="class">Client</li>
        </ul>
        <hr class="navi_hr"/>
        <ul class="navi_main">
          <li class="property"><a href="OLLMchat.Client.available_models.html">available_models</a></li>
          <li class="property"><a href="OLLMchat.Client.config.html">config</a></li>
          <li class="property"><a href="OLLMchat.Client.connection.html">connection</a></li>
          <li class="property"><a href="OLLMchat.Client.timeout.html">timeout</a></li>
          <li class="creation_method"><a href="OLLMchat.Client.Client.html">Client</a></li>
          <li class="method"><a href="OLLMchat.Client.chat.html">chat</a></li>
          <li class="method"><a href="OLLMchat.Client.chat_execute.html">chat_execute</a></li>
          <li class="method"><a href="OLLMchat.Client.embed.html">embed</a></li>
          <li class="method"><a href="OLLMchat.Client.embed_array.html">embed_array</a></li>
          <li class="method"><a href="OLLMchat.Client.fetch_all_model_details.html">fetch_all_model_details</a></li>
          <li class="method"><a href="OLLMchat.Client.generate.html">generate</a></li>
          <li class="method"><a href="OLLMchat.Client.models.html">models</a></li>
          <li class="method"><a href="OLLMchat.Client.ps.html">ps</a></li>
          <li class="method"><a href="OLLMchat.Client.show_model.html">show_model</a></li>
          <li class="method"><a href="OLLMchat.Client.version.html">version</a></li>
          <li class="signal"><a href="OLLMchat.Client.chat_send.html">chat_send</a></li>
          <li class="signal"><a href="OLLMchat.Client.message_created.html">message_created</a></li>
          <li class="signal"><a href="OLLMchat.Client.stream_chunk.html">stream_chunk</a></li>
          <li class="signal"><a href="OLLMchat.Client.stream_content.html">stream_content</a></li>
          <li class="signal"><a href="OLLMchat.Client.stream_start.html">stream_start</a></li>
          <li class="signal"><a href="OLLMchat.Client.tool_message.html">tool_message</a></li>
          <li class="field"><a href="OLLMchat.Client.session.html">session</a></li>
        </ul>
      </div>
      <div class="site_content">
        <h1 class="main_title">Client</h1>
        <hr class="main_hr"/>
        <h2 class="main_title">Object Hierarchy:</h2>
        <img class="main_diagram" usemap="#OLLMchat.Client" alt="Object hierarchy for Client" src="img/OLLMchat.Client.png"/>

      <map id="OLLMchat.Client" name="OLLMchat.Client">
<area shape="rect" id="node1" href="OLLMchat.Client.html" title="OLLMchat.Client" alt="" coords="5,101,159,149"/>
</map>

        <h2 class="main_title">Description:</h2>
        <div class="main_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">class</span> <b><span class="class">Client</span></b> : <span class="main_type"><span class="class">Object</span></span>
        </div>
        <div class="description">
          <p>Main client class for interacting with Ollama API and OpenAI-compatible REST interfaces.</p>
          <p>Provides methods for chat, model management, and tool integration. Handles HTTP requests, streaming responses, and function calling. 
            Manages tool registration and execution with permission checking.</p>
          <h2>Basic Usage </h2>
          <p><pre class="main_source"><code><span class="main_keyword">var</span> connection = <span class="main_keyword">new</span> Settings.Connection() {<br/>    url = <span class="main_literal">"http://127.0.0.1:11434/api"</span><br/>};<br/><span class="main_keyword">var</span> client = <span class="main_keyword">new</span> Client(connection);<br/><span class="main_keyword">var</span> chat = <span class="main_keyword">new</span> Call.Chat(client, <span class="main_literal">"llama3.2"</span>) {<br/>    stream = <span class="main_literal">true</span><br/>};<br/>chat.messages.add(<span class="main_keyword">new</span> Message(chat, <span class="main_literal">"user"</span>, <span class="main_literal">"Hello!"</span>));<br/><span class="main_keyword">var</span> response = <span class="main_keyword">yield</span> chat.exec_chat();</code></pre>
          </p>
          <h2>Tool Integration </h2>
          <p><pre class="main_source"><code><span class="main_comment">// Add tools to Chat before chatting</span><br/><span class="main_keyword">var</span> read_file = <span class="main_keyword">new</span> Tools.ReadFile(client);<br/><span class="main_keyword">var</span> chat = <span class="main_keyword">new</span> Call.Chat(client, <span class="main_literal">"llama3.2"</span>);<br/>chat.add_tool(read_file);<br/><br/><span class="main_comment">// Tools are automatically called when the model requests them</span><br/>chat.messages.add(<span class="main_keyword">new</span> Message(chat, <span class="main_literal">"user"</span>, <span class="main_literal">"Read README.md"</span>));<br/><span class="main_keyword">var</span> response = <span class="main_keyword">yield</span> chat.exec_chat();</code></pre>
          </p>
          <h2>Streaming </h2>
          <p><pre class="main_source"><code><span class="main_keyword">var</span> chat = <span class="main_keyword">new</span> Call.Chat(client, <span class="main_literal">"llama3.2"</span>) {<br/>    stream = <span class="main_literal">true</span><br/>};<br/>chat.message_created.connect((msg, content) =&gt; {<br/>    <span class="main_keyword">if</span> (msg.is_content &amp;&amp; msg.is_stream) {<br/>        <span class="main_comment">// Process incremental content</span><br/>        print(content.chat_content);<br/>    }<br/>});</code></pre>
          </p>
        </div><br/>
        <div class="namespace_note"><b>Namespace:</b> <a href="OLLMchat.html">OLLMchat</a>
        </div>
        <div class="package_note"><b>Package:</b> <a href="index.htm">ollmchat</a>
        </div>
        <h2 class="main_title">Content:</h2>
        <h3 class="main_title">Properties:</h3>
        <ul class="navi_inline">
          <li class="property"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_type"><span class="class">HashMap</span></span>&lt;<span class="main_basic_type"><span class="class">string</span></span>,<span class="main_type"><a href="OLLMchat.Response.Model.html" class="class">Model</a></span>&gt; <b><a href="OLLMchat.Client.available_models.html" class="property">available_models</a></b> { <span class="main_keyword">get</span>; }
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Available models loaded from the server, keyed by model name.</span>
            </div></li>
          <li class="property"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_type"><a href="OLLMchat.Settings.Config2.html" class="class">Config2</a></span>? <b><a href="OLLMchat.Client.config.html" class="property">config</a></b> { <span class="main_keyword">get</span>; <span class="main_keyword">set</span>; }
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Configuration settings (Config2 instance).</span>
            </div></li>
          <li class="property"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_type"><a href="OLLMchat.Settings.Connection.html" class="class">Connection</a></span> <b><a href="OLLMchat.Client.connection.html" class="property">connection</a></b> { <span class="main_keyword">get</span>; <span class="main_keyword">set</span>; }
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Connection configuration for this client.</span>
            </div></li>
          <li class="property"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_basic_type"><span class="struct">uint</span></span> <b><a href="OLLMchat.Client.timeout.html" class="property">timeout</a></b> { <span class="main_keyword">get</span>; <span class="main_keyword">set</span>; }
            </span>
            <div class="leaf_brief_description"><span class="brief_description">HTTP request timeout in seconds. Default is 300 seconds (5 minutes) to
                accommodate long-running LLM requests. Set to 0 for no timeout (not recommended).</span>
            </div></li>
        </ul>
        <h3 class="main_title">Creation methods:</h3>
        <ul class="navi_inline">
          <li class="creation_method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <b><a href="OLLMchat.Client.Client.html" class="creation_method">Client</a></b> (<span class="main_type"><a href="OLLMchat.Settings.Connection.html" class="class">Connection</a></span> connection)
            </span>
            <div class="leaf_brief_description">
            </div></li>
        </ul>
        <h3 class="main_title">Methods:</h3>
        <ul class="navi_inline">
          <li class="method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">async</span> <span class="main_type"><a href="OLLMchat.Response.Chat.html" class="class">Chat</a></span> <b><a href="OLLMchat.Client.chat.html" class="method">chat</a></b> (<span class="main_basic_type"><span class="class">string</span></span> text, <span class="main_type"><span class="class">Cancellable</span></span>? cancellable = <span class="main_literal">null</span>) <span class="main_keyword">throws</span> <span class="main_type"><span class="class">Error</span></span>
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Legacy chat method for backward compatibility.</span>
            </div></li>
          <li class="method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">async</span> <span class="main_type"><a href="OLLMchat.Response.Chat.html" class="class">Chat</a></span> <b><a href="OLLMchat.Client.chat_execute.html" class="method">chat_execute</a></b> (<span class="main_type"><a href="OLLMchat.Call.Chat.html" class="class">Chat</a></span> call) <span class="main_keyword">throws</span> <span class="main_type"><span class="class">Error</span></span>
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Executes a pre-prepared Chat object.</span>
            </div></li>
          <li class="method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">async</span> <span class="main_type"><a href="OLLMchat.Response.Embed.html" class="class">Embed</a></span> <b><a href="OLLMchat.Client.embed.html" class="method">embed</a></b> (<span class="main_basic_type"><span class="class">string</span></span> input, <span class="main_basic_type"><span class="struct">int</span></span> dimensions = <span class="main_literal">-1</span>, <span class="main_basic_type"><span class="struct">bool</span></span> truncate = <span class="main_literal">false</span>, <span class="main_type"><span class="class">Cancellable</span></span>? cancellable = <span class="main_literal">null</span>) <span class="main_keyword">throws</span> <span class="main_type"><span class="class">Error</span></span>
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Generates embeddings for the input text.</span>
            </div></li>
          <li class="method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">async</span> <span class="main_type"><a href="OLLMchat.Response.Embed.html" class="class">Embed</a></span> <b><a href="OLLMchat.Client.embed_array.html" class="method">embed_array</a></b> (<span class="main_type"><span class="class">ArrayList</span></span>&lt;<span class="main_basic_type"><span class="class">string</span></span>&gt; input_array, <span class="main_basic_type"><span class="struct">int</span></span> dimensions = <span class="main_literal">-1</span>, <span class="main_basic_type"><span class="struct">bool</span></span> truncate = <span class="main_literal">false</span>, <span class="main_type"><span class="class">Cancellable</span></span>? cancellable = <span class="main_literal">null</span>) <span class="main_keyword">throws</span> <span class="main_type"><span class="class">Error</span></span>
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Generates embeddings for an array of input texts.</span>
            </div></li>
          <li class="method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">async</span> <span class="main_keyword">void</span> <b><a href="OLLMchat.Client.fetch_all_model_details.html" class="method">fetch_all_model_details</a></b> () <span class="main_keyword">throws</span> <span class="main_type"><span class="class">Error</span></span>
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Fetches detailed information for all available models and populates 
                available_models.</span>
            </div></li>
          <li class="method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">async</span> <span class="main_type"><a href="OLLMchat.Response.Generate.html" class="class">Generate</a></span> <b><a href="OLLMchat.Client.generate.html" class="method">generate</a></b> (<span class="main_basic_type"><span class="class">string</span></span> prompt, <span class="main_basic_type"><span class="class">string</span></span> system = <span class="main_literal">""</span>, <span class="main_type"><span class="class">Cancellable</span></span>? cancellable = <span class="main_literal">null</span>) <span class="main_keyword">throws</span> <span class="main_type"><span class="class">Error</span></span>
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Generates a response for the provided prompt.</span>
            </div></li>
          <li class="method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">async</span> <span class="main_type"><span class="class">ArrayList</span></span>&lt;<span class="main_type"><a href="OLLMchat.Response.Model.html" class="class">Model</a></span>&gt; <b><a href="OLLMchat.Client.models.html" class="method">models</a></b> () <span class="main_keyword">throws</span> <span class="main_type"><span class="class">Error</span></span>
            </span>
            <div class="leaf_brief_description">
            </div></li>
          <li class="method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">async</span> <span class="main_type"><span class="class">ArrayList</span></span>&lt;<span class="main_type"><a href="OLLMchat.Response.Model.html" class="class">Model</a></span>&gt; <b><a href="OLLMchat.Client.ps.html" class="method">ps</a></b> () <span class="main_keyword">throws</span> <span class="main_type"><span class="class">Error</span></span>
            </span>
            <div class="leaf_brief_description">
            </div></li>
          <li class="method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">async</span> <span class="main_type"><a href="OLLMchat.Response.Model.html" class="class">Model</a></span> <b><a href="OLLMchat.Client.show_model.html" class="method">show_model</a></b> (<span class="main_basic_type"><span class="class">string</span></span> model_name) <span class="main_keyword">throws</span> <span class="main_type"><span class="class">Error</span></span>
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Gets detailed information about a specific model including 
                capabilities and stores it in available_models.</span>
            </div></li>
          <li class="method"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">async</span> <span class="main_basic_type"><span class="class">string</span></span> <b><a href="OLLMchat.Client.version.html" class="method">version</a></b> (<span class="main_type"><span class="class">Cancellable</span></span>? cancellable = <span class="main_literal">null</span>) <span class="main_keyword">throws</span> <span class="main_type"><span class="class">Error</span></span>
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Gets the version of the Ollama server.</span>
            </div></li>
        </ul>
        <h3 class="main_title">Signals:</h3>
        <ul class="navi_inline">
          <li class="signal"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">signal</span> <span class="main_keyword">void</span> <b><a href="OLLMchat.Client.chat_send.html" class="signal">chat_send</a></b> (<span class="main_type"><a href="OLLMchat.Call.Chat.html" class="class">Chat</a></span> chat)
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Emitted when a chat request is sent to the server. This signal is 
                emitted when the request is about to be sent, including initial chat requests and automatic continuations after tool execution.</span>
            </div></li>
          <li class="signal"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">signal</span> <span class="main_keyword">void</span> <b><a href="OLLMchat.Client.message_created.html" class="signal">message_created</a></b> (<span class="main_type"><a href="OLLMchat.Message.html" class="class">Message</a></span> m, <span class="main_type"><a href="OLLMchat.ChatContentInterface.html" class="interface">ChatContentInterface</a></span>? content_interface)
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Emitted when a message is created in the conversation. This signal is 
                the primary driver for message creation events, used for both persistence (Manager) and UI display. Messages are created before prompt
                engine modification to preserve original user text.</span>
            </div></li>
          <li class="signal"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">signal</span> <span class="main_keyword">void</span> <b><a href="OLLMchat.Client.stream_chunk.html" class="signal">stream_chunk</a></b> (<span class="main_basic_type"><span class="class">string</span></span> new_text, <span class="main_basic_type"><span class="struct">bool</span></span> is_thinking, <span class="main_type"><a href="OLLMchat.Response.Chat.html" class="class">Chat</a></span> response)
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Emitted when a streaming chunk is received from the chat API.</span>
            </div></li>
          <li class="signal"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">signal</span> <span class="main_keyword">void</span> <b><a href="OLLMchat.Client.stream_content.html" class="signal">stream_content</a></b> (<span class="main_basic_type"><span class="class">string</span></span> new_text, <span class="main_type"><a href="OLLMchat.Response.Chat.html" class="class">Chat</a></span> response)
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Emitted when streaming content (not thinking) is received from the 
                chat API.</span>
            </div></li>
          <li class="signal"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">signal</span> <span class="main_keyword">void</span> <b><a href="OLLMchat.Client.stream_start.html" class="signal">stream_start</a></b> ()
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Emitted when the streaming response starts (first chunk received). 
                This signal is emitted when the first chunk of the response is processed, indicating that the server has started sending data back.
              </span>
            </div></li>
          <li class="signal"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_keyword">signal</span> <span class="main_keyword">void</span> <b><a href="OLLMchat.Client.tool_message.html" class="signal">tool_message</a></b> (<span class="main_type"><a href="OLLMchat.Message.html" class="class">Message</a></span> message)
            </span>
            <div class="leaf_brief_description"><span class="brief_description">Emitted when a tool sends a status message during execution.</span>
            </div></li>
        </ul>
        <h3 class="main_title">Fields:</h3>
        <ul class="navi_inline">
          <li class="field"><span class="leaf_code_definition"><span class="main_keyword">public</span> <span class="main_type"><span class="class">Session</span></span>? <b><a href="OLLMchat.Client.session.html" class="field">session</a></b>
            </span>
            <div class="leaf_brief_description">
            </div></li>
        </ul>
        <h3 class="main_title">Inherited Members:</h3>
        <div class="box">
          <div class="headline" onclick="toggle_box (this, 'box-content-112')">All known members inherited from class GLib.Object</div>
          <div class="content" id="box-content-112">
            <div class="column">
              <ul class="navi_inline">
                <li class="method">@get</li>
                <li class="static_method">@new</li>
                <li class="method">@ref</li>
                <li class="method">@set</li>
                <li class="method">add_toggle_ref</li>
                <li class="method">add_weak_pointer</li>
                <li class="method">bind_property</li>
                <li class="method">connect</li>
                <li class="virtual_method">constructed</li>
                <li class="method">disconnect</li>
                <li class="virtual_method">dispose</li>
                <li class="method">dup_data</li>
                <li class="method">dup_qdata</li>
                <li class="method">force_floating</li>
                <li class="method">freeze_notify</li>
                <li class="method">get_class</li>
                <li class="method">get_data</li>
              </ul>
            </div>
            <div class="column">
              <ul class="navi_inline">
                <li class="method">get_property</li>
                <li class="method">get_qdata</li>
                <li class="method">get_type</li>
                <li class="method">getv</li>
                <li class="static_method">interface_find_property</li>
                <li class="static_method">interface_install_property</li>
                <li class="static_method">interface_list_properties</li>
                <li class="method">is_floating</li>
                <li class="static_method">new_valist</li>
                <li class="static_method">new_with_properties</li>
                <li class="static_method">newv</li>
                <li class="signal">notify</li>
                <li class="method">notify_property</li>
                <li class="field">ref_count</li>
                <li class="method">ref_sink</li>
                <li class="method">remove_toggle_ref</li>
                <li class="method">remove_weak_pointer</li>
              </ul>
            </div>
            <div class="column">
              <ul class="navi_inline">
                <li class="method">replace_data</li>
                <li class="method">replace_qdata</li>
                <li class="method">set_data</li>
                <li class="method">set_data_full</li>
                <li class="method">set_property</li>
                <li class="method">set_qdata</li>
                <li class="method">set_qdata_full</li>
                <li class="method">set_valist</li>
                <li class="method">setv</li>
                <li class="method">steal_data</li>
                <li class="method">steal_qdata</li>
                <li class="method">thaw_notify</li>
                <li class="method">unref</li>
                <li class="method">watch_closure</li>
                <li class="method">weak_ref</li>
                <li class="method">weak_unref</li>
              </ul>
            </div>
          </div>
        </div>
      </div>
    </div><br/>
    <div class="site_footer">Generated by <a href="https://docs.vala.dev"><kbd>valadoc</kbd></a>
    </div>
  </body>
</html>